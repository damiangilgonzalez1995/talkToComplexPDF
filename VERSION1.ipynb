{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-llms-huggingface\n",
      "  Downloading llama_index_llms_huggingface-0.1.3-py3-none-any.whl (7.2 kB)\n",
      "Collecting torch<3.0.0,>=2.1.2\n",
      "  Downloading torch-2.2.1-cp310-cp310-win_amd64.whl (198.6 MB)\n",
      "     -------------------------------------- 198.6/198.6 MB 4.9 MB/s eta 0:00:00\n",
      "Collecting huggingface-hub<0.21.0,>=0.20.3\n",
      "  Using cached huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "Collecting transformers[torch]<5.0.0,>=4.37.0\n",
      "  Downloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
      "     ---------------------------------------- 8.5/8.5 MB 17.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from llama-index-llms-huggingface) (0.10.18.post1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from huggingface-hub<0.21.0,>=0.20.3->llama-index-llms-huggingface) (4.66.2)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from huggingface-hub<0.21.0,>=0.20.3->llama-index-llms-huggingface) (24.0)\n",
      "Requirement already satisfied: requests in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from huggingface-hub<0.21.0,>=0.20.3->llama-index-llms-huggingface) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from huggingface-hub<0.21.0,>=0.20.3->llama-index-llms-huggingface) (6.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from huggingface-hub<0.21.0,>=0.20.3->llama-index-llms-huggingface) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from huggingface-hub<0.21.0,>=0.20.3->llama-index-llms-huggingface) (4.10.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from huggingface-hub<0.21.0,>=0.20.3->llama-index-llms-huggingface) (2024.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (1.26.4)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (0.1.13)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (1.6.0)\n",
      "Requirement already satisfied: openai>=1.1.0 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (1.13.3)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (0.9.0)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (10.2.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (2.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (3.8.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (3.9.3)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (1.2.14)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (0.6.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (0.27.0)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (0.6.4)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (8.2.3)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (2.0.28)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (3.2.1)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (1.0.8)\n",
      "Collecting jinja2\n",
      "  Using cached Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "Requirement already satisfied: sympy in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.12)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.15.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (2023.12.25)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Using cached safetensors-0.4.2-cp310-none-win_amd64.whl (269 kB)\n",
      "Collecting accelerate>=0.21.0\n",
      "  Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
      "     -------------------------------------- 290.1/290.1 kB 3.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: psutil in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from accelerate>=0.21.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (5.9.8)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (4.0.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (6.0.5)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (1.4.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (23.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (1.3.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (1.16.0)\n",
      "Requirement already satisfied: pydantic>=1.10 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (2.6.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (4.3.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (1.0.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (1.3.1)\n",
      "Requirement already satisfied: idna in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (3.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (2024.2.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (0.14.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (1.3.2)\n",
      "Requirement already satisfied: click in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (8.1.7)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (1.9.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from requests->huggingface-hub<0.21.0,>=0.20.3->llama-index-llms-huggingface) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from requests->huggingface-hub<0.21.0,>=0.20.3->llama-index-llms-huggingface) (3.3.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<0.21.0,>=0.20.3->llama-index-llms-huggingface) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (3.21.1)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-2.1.5-cp310-cp310-win_amd64.whl (17 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from sympy->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (1.2.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (2.16.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (0.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\damia\\documents\\github\\talktocomplexpdf\\myenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-huggingface) (1.16.0)\n",
      "Installing collected packages: safetensors, MarkupSafe, jinja2, huggingface-hub, torch, transformers, accelerate, llama-index-llms-huggingface\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.21.4\n",
      "    Uninstalling huggingface-hub-0.21.4:\n",
      "      Successfully uninstalled huggingface-hub-0.21.4\n",
      "Successfully installed MarkupSafe-2.1.5 accelerate-0.28.0 huggingface-hub-0.20.3 jinja2-3.1.3 llama-index-llms-huggingface-0.1.3 safetensors-0.4.2 torch-2.2.1 transformers-4.38.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %pip install llama-index-llms-huggingface\n",
    "# !pip install -qU llama-index llama-parse\n",
    "pru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read API Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'API_LLAMA_CLOUD': 'llx-dE0nJGCXxiLOYOq3Ij8KReQhArt6jyKGHm22fxR2VxOIAAbS',\n",
       " 'API_OPENAI': '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'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "with open('config.yml', 'r') as file:\n",
    "    config_data = yaml.safe_load(file)\n",
    "\n",
    "config_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "# os.environ[\"LLAMA_CLOUD_API_KEY\"] = config_data[\"API_LLAMA_CLOUD\"]\n",
    "os.environ[\"OPENAI_API_KEY\"] = config_data[\"API_OPENAI\"]\n",
    "# os.environ[\"HF_TOKEN\"] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will want to do async runs in the next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will use LlamaParse to convert our PDF to Markdown format. \n",
    "\n",
    "- result_type - at time of writing this notebook the options are limited to \"text\" and \"markdown\". Markdown will be our choice as it will retain structured information quite nicely.\n",
    "- num_workers - this will let us set how many workers we'll need. Generally we'll want to set this to the number of files we're going to need to parse. (the maximum is 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_parse import LlamaParse\n",
    "\n",
    "parser = LlamaParse(\n",
    "    api_key=config_data[\"API_LLAMA_CLOUD\"],\n",
    "    result_type=\"markdown\",\n",
    "    verbose=True,\n",
    "    language=\"en\",\n",
    "    num_workers=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We convert our pdfs to markdown format, using the parser object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id d3bbbf7e-31c4-4346-abee-ac09ac487211\n",
      "Started parsing the file under job_id 6466b83a-d557-49d2-b7c4-7dd035b6efd6\n"
     ]
    }
   ],
   "source": [
    "documents = parser.load_data([\"data/nvidea.pdf\", \"data/ai-report.pdf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('# OFFICE OF Artificial Intelligence Educational Technology and the Future of '\n",
      " 'Teaching and Learning Insights and Recommendations May 2023\\n'\n",
      " '---\\n'\n",
      " '## Artificial Intelligence and the Future of Teaching and Learning\\n'\n",
      " '\\n'\n",
      " 'Miguel A. Cardona, Ed.D.\\n'\n",
      " 'Secretary, U.S. Department of Education\\n'\n",
      " '\\n'\n",
      " 'Roberto J. Rodríguez\\n'\n",
      " 'Assistant Secretary, Office of Planning, Evaluation, and Policy Development\\n'\n",
      " '\\n'\n",
      " 'Kristina Ishmael\\n'\n",
      " 'Deputy Director, Office of Educational Technology\\n'\n",
      " '\\n'\n",
      " 'May 2023\\n'\n",
      " '\\n'\n",
      " 'Examples Are Not Endorsements\\n'\n",
      " '\\n'\n",
      " 'This document contains examples and resource materials that are provided for '\n",
      " 'the user’s convenience. The inclusion of any material is not intended to '\n",
      " 'reflect its importance nor is it intended to endorse any views expressed or '\n",
      " 'products or services offered. These materials may contain the views and '\n",
      " 'recommendations of various subject matter experts as well as hypertext '\n",
      " 'links, contact addresses, and websites to information created and maintained '\n",
      " 'by other public and private organizations. The opinions expressed in any of '\n",
      " 'these materials do not necessarily reflect the positions or policies of the '\n",
      " 'U.S. Department of Education. The U.S. Department of Education does not '\n",
      " 'control or guarantee the accuracy, relevance, timeliness, or completeness of '\n",
      " 'any information from other sources that are included in these materials. '\n",
      " 'Other than statutory and regulatory requirements included in the document, '\n",
      " 'the contents of this guidance do not have the force and effect of law and '\n",
      " 'are not meant to bind the public.\\n'\n",
      " '\\n'\n",
      " 'Contracts and Procurement\\n'\n",
      " '\\n'\n",
      " 'This document is not intended to provide legal advice or approval of any '\n",
      " 'potential federal contractor’s business decision or strategy in relation to '\n",
      " 'any current or future federal procurement and/or contract. Further, this '\n",
      " 'document is not an invitation for bid, request for proposal, or other '\n",
      " 'solicitation.\\n'\n",
      " '\\n'\n",
      " 'Licensing and Availability\\n'\n",
      " '\\n'\n",
      " 'This report is in the public domain and available on the U.S. Department of '\n",
      " 'Education’s (Department’s) website at https://tech.ed.gov.\\n'\n",
      " '\\n'\n",
      " 'Requests for alternate format documents such as Braille or large print '\n",
      " 'should be submitted to the Alternate Format Center by calling 1-202-260-0852 '\n",
      " 'or by contacting the 504 coordinator via email at om_eeos@ed.gov.\\n'\n",
      " '\\n'\n",
      " 'Notice to Limited English Proficient Persons\\n'\n",
      " '\\n'\n",
      " 'If you have difficulty understanding English, you may request language '\n",
      " 'assistance services for Department information that is available to the '\n",
      " 'public. These language assistance services are available free of charge. If '\n",
      " 'you need more information about interpretation or translation services, '\n",
      " 'please call 1-800-USA-LEARN (1-800-872-5327) (TTY: 1-800-437-0833); email us '\n",
      " 'at Ed.Language.Assistance@ed.gov; or write to U.S. Department of Education, '\n",
      " 'Information Resource Center, LBJ Education Building, 400 Maryland Ave. SW, '\n",
      " 'Washington, DC 20202.\\n'\n",
      " '\\n'\n",
      " 'How to Cite\\n'\n",
      " '\\n'\n",
      " 'While permission to reprint this publication is not necessary, the suggested '\n",
      " 'citation is as follows:\\n'\n",
      " '\\n'\n",
      " 'U.S. Department of Education, Office of Educational Technology, Artificial '\n",
      " 'Intelligence and Future of Teaching and Learning: Insights and '\n",
      " 'Recommendations, Washington, DC, 2023.\\n'\n",
      " '\\n'\n",
      " 'This report is available at https://tech.ed.gov\\n'\n",
      " '---\\n'\n",
      " '|Content|Page Number|\\n'\n",
      " '|---|---|\\n'\n",
      " '|Introduction|1|\\n'\n",
      " '|Rising Interest in AI in Education|1|\\n'\n",
      " '|Three Reasons to Address AI in Education Now|2|\\n'\n",
      " '|Toward Policies for AI in Education|3|\\n'\n",
      " '|Building Ethical, Equitable Policies Together|6|\\n'\n",
      " '|Guiding Questions|6|\\n'\n",
      " '|Foundation 1: Center People (Parents, Educators, and Students)|6|\\n'\n",
      " '|Foundation 2: Advance Equity|7|\\n'\n",
      " '|Foundation 3: Ensure Safety, Ethics, and Effectiveness|8|\\n'\n",
      " '|Foundation 4: Promote Transparency|9|\\n'\n",
      " '|Overview of Document|10|\\n'\n",
      " '|What is AI?|11|\\n'\n",
      " '|Perspective: Human-Like Reasoning|12|\\n'\n",
      " '|Perspective: An Algorithm that Pursues a Goal|12|\\n'\n",
      " '|Perspective: Intelligence Augmentation|14|\\n'\n",
      " '|Definition of “Model”|14|\\n'\n",
      " '|Insight: AI Systems Enable New Forms of Interaction|15|\\n'\n",
      " '|Key Recommendation: Human in the Loop AI|16|\\n'\n",
      " '|Learning|18|\\n'\n",
      " '|Insight: AI Enables Adaptivity in Learning|18|\\n'\n",
      " '|Intelligent Tutoring Systems: An Example of AI Models|19|\\n'\n",
      " '|Important Directions for Expanding AI-Based Adaptivity|20|\\n'\n",
      " '|A Duality: Learning With and About AI|22|\\n'\n",
      " '|A Challenge: Systems Thinking About AI in Education|22|\\n'\n",
      " '|Open Questions About AI for Learning|23|\\n'\n",
      " '|Key Recommendation: Seek AI Models Aligned to a Vision for Learning|24|\\n'\n",
      " '|Teaching|25|\\n'\n",
      " '|Always Center Educators in Instructional Loops|25|\\n'\n",
      " '|Insight: Using AI to Improve Teaching Jobs|26|\\n'\n",
      " '|Preparing and Supporting Teachers in Planning and Reflecting|29|\\n'\n",
      " '|Designing, Selecting, and Evaluating AI Tools|30|\\n'\n",
      " '|Challenge: Balancing Human and Computer Decision-Making|30|\\n'\n",
      " '|Challenge: Making Teaching Jobs Easier While Avoiding Surveillance|31|\\n'\n",
      " '|Challenge: Responding to Students’ Strengths While Protecting Their '\n",
      " 'Privacy|32|\\n'\n",
      " '|Questions Worth Asking About AI for Teaching|34|\\n'\n",
      " '|Key Recommendation: Inspectable, Explainable, Overridable AI|34|\\n'\n",
      " '---\\n'\n",
      " '## Formative Assessment\\n'\n",
      " '\\n'\n",
      " '|Building on Best Practices|37|\\n'\n",
      " '|---|---|\\n'\n",
      " '|Implications for Teaching and Learning|38|\\n'\n",
      " '|Insight: AI Can Enhance Feedback Loops|39|\\n'\n",
      " '|An Example: Automated Essay Scoring|40|\\n'\n",
      " '|Key Opportunities for AI in Formative Assessment|41|\\n'\n",
      " '|Key Recommendation: Harness Assessment Expertise to Reduce Bias|42|\\n'\n",
      " '|Related Questions|43|\\n'\n",
      " '\\n'\n",
      " '## Research and Development\\n'\n",
      " '\\n'\n",
      " '|Insight: Research Can Strengthen the Role of Context in AI|44|\\n'\n",
      " '|---|---|\\n'\n",
      " '|Attention to the Long Tail of Learner Variability|46|\\n'\n",
      " '|Partnership in Design-Based Research|47|\\n'\n",
      " '|Re-thinking Teacher Professional Development|48|\\n'\n",
      " '|Connecting with Public Policy|49|\\n'\n",
      " '|Key Recommendation: Focus R&D on Addressing Context|50|\\n'\n",
      " '|Ongoing Questions for Researchers|50|\\n'\n",
      " '|Desired National R&D Objectives|51|\\n'\n",
      " '\\n'\n",
      " '## Recommendations\\n'\n",
      " '\\n'\n",
      " '|Insight: Aligning AI to Policy Objectives|52|\\n'\n",
      " '|---|---|\\n'\n",
      " '|Calling Education Leaders to Action|53|\\n'\n",
      " '|Recommendation #1: Emphasize Humans in the Loop|53|\\n'\n",
      " '|Recommendation #2: Align AI Models to a Shared Vision for Education|54|\\n'\n",
      " '|Recommendation #3: Design Using Modern Learning Principles|56|\\n'\n",
      " '|Recommendation #4: Prioritize Strengthening Trust|57|\\n'\n",
      " '|Recommendation #5: Inform and Involve Educators|57|\\n'\n",
      " '|Recommendation #6: Focus R&D on Addressing Context and Enhancing Trust and '\n",
      " 'Safety|59|\\n'\n",
      " '|Recommendation #7: Develop Education-Specific Guidelines and '\n",
      " 'Guardrails|60|\\n'\n",
      " '|Next Steps|60|\\n'\n",
      " '\\n'\n",
      " '## Common Acronyms and Abbreviations\\n'\n",
      " '\\n'\n",
      " '62\\n'\n",
      " '\\n'\n",
      " '## Acknowledgements\\n'\n",
      " '\\n'\n",
      " '63\\n'\n",
      " '\\n'\n",
      " '## References\\n'\n",
      " '\\n'\n",
      " '64\\n'\n",
      " '---\\n'\n",
      " '## Introduction\\n'\n",
      " '\\n'\n",
      " 'The U.S. Department of Education (Department) is committed to supporting the '\n",
      " 'use of technology to improve teaching and learning and to support innovation '\n",
      " 'throughout educational systems. This report addresses the clear need for '\n",
      " 'sharing knowledge and developing policies for “Artificial Intelligence,” a '\n",
      " 'rapidly advancing class of foundational capabilities which are increasingly '\n",
      " 'embedded in all types of educational technology systems and are also '\n",
      " 'available to the public. We will consider “educational technology” (edtech) '\n",
      " 'to include both (a) technologies specifically designed for educational use, '\n",
      " 'as well as (b) general technologies that are widely used in educational '\n",
      " 'settings. Recommendations in this report seek to engage teachers, '\n",
      " 'educational leaders, policy makers, researchers, and educational technology '\n",
      " 'innovators and providers as they work together on pressing policy issues '\n",
      " 'that arise as Artificial Intelligence (AI) is used in education.\\n'\n",
      " '\\n'\n",
      " 'AI can be defined as “automation based on associations.” When computers '\n",
      " 'automate reasoning based on associations in data (or associations deduced '\n",
      " 'from expert knowledge), two shifts fundamental to AI occur and shift '\n",
      " 'computing beyond conventional edtech: (1) from capturing data to detecting '\n",
      " 'patterns in data and (2) from providing access to instructional resources to '\n",
      " 'automating decisions about instruction and other educational processes. '\n",
      " 'Detecting patterns and automating decisions are leaps in the level of '\n",
      " 'responsibilities that can be delegated to a computer system. The process of '\n",
      " 'developing an AI system may lead to bias in how patterns are detected and '\n",
      " 'unfairness in how decisions are automated. Thus, educational systems must '\n",
      " 'govern their use of AI systems. This report describes opportunities for '\n",
      " 'using AI to improve education, recognizes challenges that will arise, and '\n",
      " 'develops recommendations to guide further policy development.\\n'\n",
      " '\\n'\n",
      " '## Rising Interest in AI in Education\\n'\n",
      " '\\n'\n",
      " 'Today, many priorities for improvements to teaching and learning are unmet. '\n",
      " 'Educators seek technology-enhanced approaches addressing these priorities '\n",
      " 'that would be safe, effective, and scalable. Naturally, educators wonder if '\n",
      " 'the rapid advances in technology in everyday lives could help. Like all of '\n",
      " 'us, educators use AI-powered services in their everyday lives, such as voice '\n",
      " 'assistants in their homes; tools that can correct grammar, complete '\n",
      " 'sentences, and write essays; and automated trip planning on their phones. '\n",
      " 'Many educators are actively exploring AI tools as they are newly released to '\n",
      " 'the public. Educators see opportunities to use AI-powered capabilities like '\n",
      " 'speech recognition to increase the support available to students with '\n",
      " 'disabilities, multilingual learners, and others who could benefit from '\n",
      " 'greater adaptivity and personalization in digital tools for learning. They '\n",
      " 'are exploring how AI can enable writing or improving lessons, as well as '\n",
      " 'their process for finding, choosing, and adapting material for use in their '\n",
      " 'lessons.\\n'\n",
      " '\\n'\n",
      " 'Educators are also aware of new risks. Useful, powerful functionality can '\n",
      " 'also be accompanied with new data privacy and security risks. Educators '\n",
      " 'recognize that AI can automatically produce output that is inappropriate or '\n",
      " 'wrong. They are wary that the associations or automations created by AI may '\n",
      " 'amplify unwanted biases. They have noted new ways in which students may\\n'\n",
      " '\\n'\n",
      " '1 Walton Family Foundation (March 1, 2023). Teachers and students embrace '\n",
      " 'ChatGPT for education. '\n",
      " 'https://www.waltonfamilyfoundation.org/learning/teachers-and-students-embrace-chatgpt-for-education\\n'\n",
      " '---\\n'\n",
      " 'During the listening sessions, constituents articulated three reasons to '\n",
      " 'address AI now:\\n'\n",
      " '\\n'\n",
      " '- First, AI may enable achieving educational priorities in better ways, at '\n",
      " 'scale, and with lower costs. Addressing varied unfinished learning of '\n",
      " 'students due to the pandemic is a policy priority, and AI may improve the '\n",
      " 'adaptivity of learning resources to students’ strengths and needs. Improving '\n",
      " 'teaching jobs is a priority, and via automated assistants or other tools, AI '\n",
      " 'may provide teachers greater support. AI may also enable teachers to extend '\n",
      " 'the support they offer to individual students when they run out of time. '\n",
      " 'Developing resources that are responsive to the knowledge and experiences '\n",
      " 'students bring to their learning—their community and cultural assets—is a '\n",
      " 'priority, and AI may enable greater customizability of curricular resources '\n",
      " 'to meet local needs.\\n'\n",
      " '\\n'\n",
      " '“I strongly believe in the need for stakeholders to understand the cyclical '\n",
      " 'effects of AI and education. By understanding how different activities '\n",
      " 'accrue, we have the ability to support virtuous cycles. Otherwise, we will '\n",
      " 'likely allow vicious cycles to perpetuate.”\\n'\n",
      " '\\n'\n",
      " '—Lydia Liu\\n'\n",
      " '---\\n'\n",
      " 'As seen in voice assistants, mapping tools, shopping recommendations, '\n",
      " 'essay-writing capabilities, and other familiar applications, AI may enhance '\n",
      " 'educational services. Second, urgency and importance arise through awareness '\n",
      " 'of system-level risks and anxiety about potential future risks. For example, '\n",
      " 'students may become subject to greater surveillance. Some teachers worry '\n",
      " 'that they may be replaced—to the contrary, the Department firmly rejects the '\n",
      " 'idea that AI could replace teachers. Examples of discrimination from '\n",
      " 'algorithmic bias are on the public’s mind, such as a voice recognition '\n",
      " 'system that doesn’t work as well with regional dialects, or an exam '\n",
      " 'monitoring system that may unfairly identify some groups of students for '\n",
      " 'disciplinary action. Some uses of AI may be infrastructural and invisible, '\n",
      " 'which creates concerns about transparency and trust. AI often arrives in new '\n",
      " 'applications with the aura of magic, but educators and procurement policies '\n",
      " 'require that edtech show efficacy. AI may provide information that appears '\n",
      " 'authentic, but actually is inaccurate or lacking a basis in reality. Of the '\n",
      " 'highest importance, AI brings new risks in addition to the well-known data '\n",
      " 'privacy and data security risks, such as the risk of scaling pattern '\n",
      " 'detectors and automations that result in “algorithmic discrimination” (e.g., '\n",
      " 'systematic unfairness in the learning opportunities or resources recommended '\n",
      " 'to some populations of students).\\n'\n",
      " '\\n'\n",
      " 'Third, urgency arises because of the scale of possible unintended or '\n",
      " 'unexpected consequences. When AI enables instructional decisions to be '\n",
      " 'automated at scale, educators may discover unwanted consequences. In a '\n",
      " 'simple example, if AI adapts by speeding curricular pace for some students '\n",
      " 'and by slowing the pace for other students (based on incomplete data, poor '\n",
      " 'theories, or biased assumptions about learning), achievement gaps could '\n",
      " 'widen. In some cases, the quality of available data may produce unexpected '\n",
      " 'results. For example, an AI-enabled teacher hiring system might be assumed '\n",
      " 'to be more objective than human-based résumé scoring. Yet, if the AI system '\n",
      " 'relies on poor quality historical data, it might de-prioritize candidates '\n",
      " 'who could bring both diversity and talent to a school’s teaching workforce.\\n'\n",
      " '\\n'\n",
      " 'In summary, it is imperative to address AI in education now to realize key '\n",
      " 'opportunities, prevent and mitigate emergent risks, and tackle unintended '\n",
      " 'consequences.\\n'\n",
      " '\\n'\n",
      " 'Toward Policies for AI in Education\\n'\n",
      " '\\n'\n",
      " 'The 2023 AI Index Report from the Stanford Institute for Human-Centered AI '\n",
      " 'has documented notable acceleration of investment in AI as well as an '\n",
      " 'increase of research on ethics, including issues of fairness and '\n",
      " 'transparency. Of course, research on topics like ethics is increasing '\n",
      " 'because problems are observed. Ethical problems will occur in education, '\n",
      " 'too. The report found a striking interest in 25 countries in the number of '\n",
      " 'legislative proposals that specifically include AI. In the United States, '\n",
      " 'multiple executive orders are focused on ensuring AI is trustworthy and '\n",
      " 'equitable, and the White House Office of Science and Technology Policy has '\n",
      " 'introduced a\\n'\n",
      " '\\n'\n",
      " '2 Maslej, N., Fattorini, L., Brynjolfsson E., Etchemendy, J., Ligett, K., '\n",
      " 'Lyons, T., Manyika, J., Ngo, H., Niebles, J.C., Parli, V., Shoham, Y., Wald, '\n",
      " 'R., Clark, J. and Perrault, R., (2023). The AI index 2023 annual report. '\n",
      " 'Stanford University: AI Index Steering Committee, Institute for '\n",
      " 'Human-Centered AI.\\n'\n",
      " '\\n'\n",
      " '3 Holmes, W. & Porayska-Pomsta, K. (Eds.) (2022). The ethics of artificial '\n",
      " 'intelligence in education. Routledge. ISBN 978-0367349721\\n'\n",
      " '---\\n'\n",
      " 'Blueprint for an AI Bill of Rights (Blueprint) that provides principles and '\n",
      " 'practices that help achieve this goal. These initiatives, along with other '\n",
      " 'AI-related policy activities occurring in both the executive and legislative '\n",
      " 'branches, will guide the use of AI throughout all sectors of society. In '\n",
      " 'Europe, the European Commission recently released Ethical guidelines on the '\n",
      " 'use of artificial intelligence (AI) and data in teaching and learning for '\n",
      " 'educators.\\n'\n",
      " '\\n'\n",
      " 'AI is moving fast and heralding societal changes that require a national '\n",
      " 'policy response. In addition to broad policies for all sectors of society, '\n",
      " 'education-specific policies are needed to address new opportunities and '\n",
      " 'challenges within existing frameworks that take into consideration federal '\n",
      " 'student privacy laws (such as the Family Educational Rights and Privacy Act, '\n",
      " 'or FERPA), as well as similar state related laws. AI also makes '\n",
      " 'recommendations and takes actions automatically in support of student '\n",
      " 'learning, and thus educators will need to consider how such recommendations '\n",
      " 'and actions can comply with laws such as the Individuals with Disabilities '\n",
      " 'Education Act (IDEA). We discuss specific policies in the concluding '\n",
      " 'section.\\n'\n",
      " '\\n'\n",
      " 'Figure 1: Research about AI is growing rapidly. Other indicators, such as '\n",
      " 'dollars invested and number of people employed, show similar trends.\\n'\n",
      " '\\n'\n",
      " '|Number of AI Publications by Field of Study (Excluding Other AI), '\n",
      " '2010|Cnart 2021 AIincor Raport|Fattar Reconniticn|\\n'\n",
      " '|---|---|---|\\n'\n",
      " '|Computer Vision|59,856|Pattern Recognition|\\n'\n",
      " '|Machine Learning|42,404|Machine Learning|\\n'\n",
      " '|Computational Linguistics|30,073|Computer Vision|\\n'\n",
      " '|Algorithms|21,467|Data Mining/Text Processing|\\n'\n",
      " '|Control Theory|15,757|Artificial Intelligence|\\n'\n",
      " '|Linguistics|2016|International Relations|\\n'\n",
      " '\\n'\n",
      " 'AI is advancing exponentially (see Figure 1), with powerful new AI features '\n",
      " 'for generating images and text becoming available to the public, and leading '\n",
      " 'to changes in how people create text and\\n'\n",
      " '\\n'\n",
      " 'White House Office of Science and Technology Policy (October 2022), '\n",
      " 'Blueprint for an AI bill of rights: Making automated systems work for the '\n",
      " 'American people. The White House Office of Science and Technology Policy.\\n'\n",
      " '\\n'\n",
      " 'European Commission, Directorate-General for Education, Youth, Sport and '\n",
      " 'Culture. (2022). Ethical guidelines on the use of artificial intelligence '\n",
      " '(AI) and data in teaching and learning for educators, Publications Office of '\n",
      " 'the European Union.\\n'\n",
      " '---\\n'\n",
      " 'images6. The advances in AI are not only happening in research labs but also '\n",
      " 'are making news in mainstream media and in educational-specific '\n",
      " 'publications. Researchers have articulated a range of concepts and '\n",
      " 'frameworks for ethical AI7, as well as for related concepts such as '\n",
      " 'equitable, responsible, and human-centered AI. Listening session '\n",
      " 'participants called for building on these concepts and frameworks but also '\n",
      " 'recognized the need to do more; participants noted a pressing need for '\n",
      " 'guardrails and guidelines that make educational use of AI advances safe, '\n",
      " 'especially given this accelerating pace of incorporation of AI into '\n",
      " 'mainstream technologies. As policy development takes time, policy makers and '\n",
      " 'educational constituents together need to start now to specify the '\n",
      " 'requirements, disclosures, regulations, and other structures that can shape '\n",
      " 'a positive and safe future for all constituents—especially students and '\n",
      " 'teachers. Policies are urgently needed to implement the following:\\n'\n",
      " '\\n'\n",
      " '|1.|leverage automation to advance learning outcomes while protecting human '\n",
      " 'decision making and judgment;|\\n'\n",
      " '|---|---|\\n'\n",
      " '|2.|interrogate the underlying data quality in AI models to ensure fair and '\n",
      " 'unbiased pattern recognition and decision making in educational '\n",
      " 'applications, based on accurate information appropriate to the pedagogical '\n",
      " 'situation;|\\n'\n",
      " '|3.|enable examination of how particular AI technologies, as part of larger '\n",
      " 'edtech or educational systems, may increase or undermine equity for '\n",
      " 'students; and|\\n'\n",
      " '|4.|take steps to safeguard and advance equity, including providing for '\n",
      " 'human checks and balances and limiting any AI systems and tools that '\n",
      " 'undermine equity.|\\n'\n",
      " '\\n'\n",
      " 'Sharples, M. & Pérez y Pérez, R. (2022). Story machines: How computers have '\n",
      " 'become creative writers. Routledge. ISBN 9780367751951\\n'\n",
      " '\\n'\n",
      " 'Akgun, S., Greenhow, C. (2022). Artificial intelligence in education: '\n",
      " 'Addressing ethical challenges in K-12 settings. AI Ethics, 2, 431–440. '\n",
      " 'https://doi.org/10.1007/s43681-021-00096-7\\n'\n",
      " '---\\n'\n",
      " 'Building Ethical, Equitable Policies Together\\n'\n",
      " '\\n'\n",
      " 'In this report, we aim to build on the listening sessions the Department '\n",
      " 'hosted to engage and inform all constituents involved in making educational '\n",
      " 'decisions so they can prepare for and make better decisions about the role '\n",
      " 'of AI in teaching and learning. AI is a complex and broad topic, and we are '\n",
      " 'not able to cover everything nor resolve issues that still require more '\n",
      " 'constituent engagement. This report is intended to be a starting point.\\n'\n",
      " '\\n'\n",
      " 'The opportunities and issues of AI in education are equally important in '\n",
      " 'K-12, higher education, and workforce learning. Due to scope limitations, '\n",
      " 'the examples in this report will focus on K-12 education. The implications '\n",
      " 'are similar at all levels of education, and the Department intends further '\n",
      " 'activities in 2023 to engage constituents beyond K-12 schools.\\n'\n",
      " '\\n'\n",
      " 'Guiding Questions\\n'\n",
      " '\\n'\n",
      " 'Understanding that AI increases automation and allows machines to do some '\n",
      " 'tasks that only people did in the past leads us to a pair of bold, '\n",
      " 'overarching questions:\\n'\n",
      " '\\n'\n",
      " '|1.|What is our collective vision of a desirable and achievable educational '\n",
      " 'system that leverages automation to advance learning while protecting and '\n",
      " 'centering human agency?|\\n'\n",
      " '|---|---|\\n'\n",
      " '|2.|How and on what timeline will we be ready with necessary guidelines and '\n",
      " 'guardrails, as well as convincing evidence of positive impacts, so that '\n",
      " 'constituents can ethically and equitably implement this vision widely?|\\n'\n",
      " '\\n'\n",
      " 'In the Learning, Teaching, and Assessment sections of this report, we '\n",
      " 'elaborate on elements of an educational vision grounded in what today’s '\n",
      " 'learners, teachers, and educational systems need, and we describe key '\n",
      " 'insights and next steps required. Below, we articulate four key foundations '\n",
      " 'for framing these themes. These foundations arise from what we know about '\n",
      " 'the effective use of educational technology to improve opportunity, equity, '\n",
      " 'and outcomes for students and also relate to the new Blueprint.\\n'\n",
      " '\\n'\n",
      " 'Foundation 1: Center People (Parents, Educators, and Students)\\n'\n",
      " '\\n'\n",
      " 'Education-focused AI policies at the federal, state, and district levels '\n",
      " 'will be needed to guide and empower local and individual decisions about '\n",
      " 'which technologies to adopt and use in schools and classrooms. Consider what '\n",
      " 'is happening in everyday lives. Many of us use AI-enabled products because '\n",
      " 'they are often better and more convenient. For example, few people want to '\n",
      " 'use paper maps anymore; people find that technology helps us plan the best '\n",
      " 'route to a destination more efficiently and conveniently. And yet, people '\n",
      " 'often do not realize how much privacy they are giving up when they accept '\n",
      " 'AI-enabled systems into their lives. AI will bring privacy and other risks '\n",
      " 'that are hard to address only via individual decision making; additional '\n",
      " 'protections will be needed.\\n'\n",
      " '---\\n'\n",
      " 'There should be clear limits on the ability to collect, use, transfer, and '\n",
      " 'maintain our personal data, including limits on targeted advertising. These '\n",
      " 'limits should put the burden on platforms to minimize how much information '\n",
      " 'they collect, rather than burdening Americans with reading fine print.\\n'\n",
      " '\\n'\n",
      " 'As protections are developed, we recommend that policies center people, not '\n",
      " 'machines. To this end, a first recommendation in this document (in the next '\n",
      " 'section) is an emphasis on AI with humans in the loop. Teachers, learners, '\n",
      " 'and others need to retain their agency to decide what patterns mean and to '\n",
      " 'choose courses of action. The idea of humans in the loop builds on the '\n",
      " 'concept of “Human Alternatives, Consideration, and Fallback” in the '\n",
      " 'Blueprint and ethical concepts used more broadly in evaluating AI, such as '\n",
      " 'preserving human dignity. A top policy priority must be establishing human '\n",
      " 'in the loop as a requirement in educational applications, despite contrary '\n",
      " 'pressures to use AI as an alternative to human decision making. Policies '\n",
      " 'should not hinder innovation and improvement, nor should they be burdensome '\n",
      " 'to implement. Society needs an education-focused AI policy that protects '\n",
      " 'civil rights and promotes democratic values in the building, deployment, and '\n",
      " 'governance of automated systems to be used across the many decentralized '\n",
      " 'levels of the American educational system.\\n'\n",
      " '\\n'\n",
      " '## Foundation 2: Advance Equity\\n'\n",
      " '\\n'\n",
      " '“AI brings educational technology to an inflection point. We can either '\n",
      " 'increase disparities or shrink them, depending on what we do now.” —Dr. '\n",
      " 'Russell Shilling\\n'\n",
      " '\\n'\n",
      " 'A recent Executive Order issued by President Biden sought to strengthen the '\n",
      " 'connection among racial equity, education and AI, stating that “members of '\n",
      " 'underserved communities—many of whom have endured generations of '\n",
      " 'discrimination and disinvestment—still confront significant barriers to '\n",
      " 'realizing the full promise of our great Nation, and the Federal Government '\n",
      " 'has a responsibility to remove these barriers” and that the Federal '\n",
      " 'Government shall both “pursue educational equity so that our Nation’s '\n",
      " 'schools put every student on a path to success” and also “root out bias in '\n",
      " 'the design and use of new technologies, such as artificial intelligence.” A '\n",
      " 'specific vision of equity, such as described in the Department’s recent '\n",
      " 'report, Advancing Digital Equity for All is essential to policy discussion '\n",
      " 'about AI in education. This report defines digital equity as\\n'\n",
      " '\\n'\n",
      " '8 The White House (September 8, 2022). Readout of White House listening '\n",
      " 'session on tech platform accountability. '\n",
      " 'https://www.whitehouse.gov/briefing-room/statements-releases/2022/09/08/readout-of-white-house-listening-session-on-tech-platform-accountability/ '\n",
      " '9 The White House (February 17, 2023). Executive order on further advancing '\n",
      " 'racial equity and support for underserved communities through the federal '\n",
      " 'government. '\n",
      " 'https://www.whitehouse.gov/briefing-room/presidential-actions/2023/02/16/executive-order-on-further-advancing-racial-equity '\n",
      " '10 U.S. Department of Education, Office of Educational Technology (2022). '\n",
      " 'Advancing digital equity for all: Community-based recommendations for '\n",
      " 'developing effective digital equity plans to close the digital divide and '\n",
      " 'enable technology-empowered learning. US Department of Education.\\n'\n",
      " '---\\n'\n",
      " '“the condition in which individuals and communities have the information '\n",
      " 'technology capacity\\n'\n",
      " 'that is needed for full participation in the society and economy of the '\n",
      " 'United States.” Issues related to racial equity and unfair bias were at the '\n",
      " 'heart of every listening session we held. In particular, we heard a '\n",
      " 'conversation that was increasingly attuned to issues of data quality and the '\n",
      " 'consequences of using poor or inappropriate data in AI systems for '\n",
      " 'education. Datasets are used to develop AI, and when they are '\n",
      " 'non-representative or contain undesired associations or patterns, resulting '\n",
      " 'AI models may act unfairly in how they detect patterns or automate '\n",
      " 'decisions. Systematic, unwanted unfairness in how a computer detects '\n",
      " 'patterns or automates decisions is called “algorithmic bias.” Algorithmic '\n",
      " 'bias could diminish equity at scale with unintended discrimination. As this '\n",
      " 'document discussed in the Formative Assessment section, this is not a new '\n",
      " 'conversation. For decades, constituents have rightly probed whether '\n",
      " 'assessments are unbiased and fair. Just as with assessments, whether an AI '\n",
      " 'model exhibits algorithmic bias or is judged to be fair and trustworthy is '\n",
      " 'critical as local school leaders make adoption decisions about using AI to '\n",
      " 'achieve their equity goals. We highlight the concept of “algorithmic '\n",
      " 'discrimination” in the Blueprint. Bias is intrinsic to how AI algorithms are '\n",
      " 'developed using historical data, and it can be difficult to anticipate all '\n",
      " 'impacts of biased data and algorithms during system design. The Department '\n",
      " 'holds that biases in AI algorithms must be addressed when they introduce or '\n",
      " 'sustain unjust discriminatory practices in education. For example, in '\n",
      " 'postsecondary education, algorithms that make enrollment decisions, identify '\n",
      " 'students for early intervention, or flag possible student cheating on exams '\n",
      " 'must be interrogated for evidence of unfair discriminatory bias—and not only '\n",
      " 'when systems are designed, but also later, as systems become widely used.\\n'\n",
      " '\\n'\n",
      " 'Foundation 3: Ensure Safety, Ethics, and Effectiveness A central safety '\n",
      " 'argument in the Department’s policies is the need for data privacy and '\n",
      " 'security in the systems used by teachers, students, and others in '\n",
      " 'educational institutions. The development and deployment of AI requires '\n",
      " 'access to detailed data. This data goes beyond conventional student records '\n",
      " '(roster and gradebook information) to detailed information about what '\n",
      " 'students do as they learn with technology and what teachers do as they use '\n",
      " 'technology to teach. AI’s dependence on data requires renewed and '\n",
      " 'strengthened attention to data privacy, security, and governance (as also '\n",
      " 'indicated in the Blueprint). As AI models are not generally developed in '\n",
      " 'consideration of educational usage or student privacy, the educational '\n",
      " 'application of these models may not be aligned with the educational '\n",
      " 'institution’s efforts to comply with federal student privacy laws, such as '\n",
      " 'FERPA, or state privacy laws.\\n'\n",
      " '---\\n'\n",
      " '## Figure 2: The Elementary and Secondary Education Act defines four levels '\n",
      " 'of evidence.\\n'\n",
      " '\\n'\n",
      " '|Strong|Randomized controlled trial|\\n'\n",
      " '|---|---|\\n'\n",
      " '|Moderate|Quasi-experiment|\\n'\n",
      " '|Promising|Correlational study|\\n'\n",
      " '| |Logic model informed by research|\\n'\n",
      " '| |Demonstrates a Rationale or evaluation|\\n'\n",
      " '\\n'\n",
      " 'Further, educational leaders are committed to basing their decisions about '\n",
      " 'the adoption of educational technology on evidence of effectiveness—a '\n",
      " 'central foundation of the Department’s policy. For example, the requirement '\n",
      " 'to base decisions on evidence also arises in the Elementary and Secondary '\n",
      " 'Education Act (ESEA), as amended, which introduced four tiers of evidence '\n",
      " '(see Figure 2). Our nation’s research agencies, including the Institute of '\n",
      " 'Education Sciences, are essential to producing the needed evidence. The '\n",
      " 'Blueprint calls for evidence of effectiveness, but the education sector is '\n",
      " 'ahead of that game: we need to insist that AI-enhanced edtech rises to meet '\n",
      " 'ESEA standards as well.\\n'\n",
      " '\\n'\n",
      " '## Foundation 4: Promote Transparency\\n'\n",
      " '\\n'\n",
      " 'The central role of complex AI models in a technology’s detection of '\n",
      " 'patterns and implementation of automation is an important way in which '\n",
      " 'AI-enabled applications, products, and services will be different from '\n",
      " 'conventional edtech. The Blueprint introduces the need for transparency '\n",
      " 'about AI models in terms of disclosure (“notice”) and explanation. In '\n",
      " 'education, decision makers will need more than notice—they will need to '\n",
      " 'understand how AI models work in a range of general educational use cases, '\n",
      " 'so they can better anticipate limitations, problems, and risks.\\n'\n",
      " '\\n'\n",
      " 'AI models in edtech will be approximations of reality and, thus, '\n",
      " 'constituents can always ask these questions: How precise are the AI models? '\n",
      " 'Do they accurately capture what is most important? How well do the '\n",
      " 'recommendations made by an AI model fit educational goals? What are the '\n",
      " 'broader implications of using AI models at scale in educational processes?\\n'\n",
      " '\\n'\n",
      " 'Building on what was heard from constituents, the sections of this report '\n",
      " 'develop the theme of evaluating the quality of AI systems and tools using '\n",
      " 'multiple dimensions as follows:\\n'\n",
      " '\\n'\n",
      " '- About AI: AI systems and tools must respect data privacy and security. '\n",
      " 'Humans must be in the loop.\\n'\n",
      " '- Learning: AI systems and tools must align to our collective vision for '\n",
      " 'high-quality learning, including equity.\\n'\n",
      " '- Teaching: AI systems and tools must be inspectable, explainable, and '\n",
      " 'provide human alternatives to AI-based suggestions; educators will need '\n",
      " 'support to exercise professional judgment and override AI models, when '\n",
      " 'necessary.\\n'\n",
      " '---\\n'\n",
      " 'Formative Assessment: AI systems and tools must minimize bias, promote '\n",
      " 'fairness, and avoid additional testing time and burden for students and '\n",
      " 'teachers.\\n'\n",
      " '\\n'\n",
      " 'Research and Development: AI systems and tools must account for the context '\n",
      " 'of teaching and learning and must work well in educational practice, given '\n",
      " 'variability in students, teachers, and settings.\\n'\n",
      " '\\n'\n",
      " 'Recommendations: Use of AI systems and tools must be safe and effective for '\n",
      " 'students. They must include algorithmic discrimination protections, protect '\n",
      " 'data privacy, provide notice and explanation, and provide a recourse to '\n",
      " 'humans when problems arise. The people most affected by the use of AI in '\n",
      " 'education must be part of the development of the AI model, system, or tool, '\n",
      " 'even if this slows the pace of adoption.\\n'\n",
      " '\\n'\n",
      " 'We return to the idea that these considerations fit together in a '\n",
      " 'comprehensive perspective on the quality of AI models in the Recommendations '\n",
      " 'section.\\n'\n",
      " '\\n'\n",
      " 'Overview of Document\\n'\n",
      " '\\n'\n",
      " 'We begin in the next section by elaborating a definition of AI, followed by '\n",
      " 'addressing learning, teaching, assessment, and research and development. '\n",
      " 'Organizing key insights by these topics keeps us focused on exploring '\n",
      " 'implications for improving educational opportunity and outcomes for students '\n",
      " 'throughout the report.\\n'\n",
      " '\\n'\n",
      " 'Within these topics, three important themes are explored:\\n'\n",
      " '\\n'\n",
      " '1. Opportunities and Risks. Policies should focus on the most valuable '\n",
      " 'educational advances while mitigating risks.\\n'\n",
      " '2. Trust and Trustworthiness. Trust and safeguarding are particularly '\n",
      " 'important in education because we have an obligation to keep students out of '\n",
      " 'harm’s way and safeguard their learning experiences.\\n'\n",
      " '3. Quality of AI Models. The process of developing and then applying a model '\n",
      " 'is at the heart of any AI system. Policies need to support evaluation of the '\n",
      " 'qualities of AI models and their alignment to goals for teaching and '\n",
      " 'learning during the processes of educational adoption and use.\\n'\n",
      " '\\n'\n",
      " '“AI in education can only grow at the speed of trust.”\\n'\n",
      " '\\n'\n",
      " '—Dr. Dale Allen\\n'\n",
      " '---\\n'\n",
      " '## What is AI?\\n'\n",
      " '\\n'\n",
      " 'Our preliminary definition of AI as automation based on associations '\n",
      " 'requires elaboration. Below we address three additional perspectives on what '\n",
      " 'constitutes AI. Educators will find these different perspectives arise in '\n",
      " 'the marketing of AI functionality and are important to understand when '\n",
      " 'evaluating edtech systems that incorporate AI. One useful glossary of AI for '\n",
      " 'Education terms is the CIRCLS Glossary of Artificial Intelligence Terms for '\n",
      " 'Educators.\\n'\n",
      " '\\n'\n",
      " 'AI is not one thing but an umbrella term for a growing set of modeling '\n",
      " 'capabilities, as visualized in Figure 3.\\n'\n",
      " '\\n'\n",
      " '|Components, types, and subfields of AI based on Regona et al (2022)|\\n'\n",
      " '|---|\\n'\n",
      " '|Unsupervised Learning|Deep Learning|Machine Learning Systems|Artificial '\n",
      " 'Superintelligence|\\n'\n",
      " '|Case-Based Reasoning|Knowledge-Based Systems|Artificial Intelligence '\n",
      " '(AI)|Computer Vision|\\n'\n",
      " '|Scene Reconstruction|Yottabyte Analysis|Robotics|Cognitive Computing|\\n'\n",
      " '|Optimization|Natural Language Processing|Automated Planning and '\n",
      " 'Scheduling|Evolutionary Algorithms|\\n'\n",
      " '\\n'\n",
      " 'Search for “AI Glossary Educators” to find other useful definitions.\\n'\n",
      " '\\n'\n",
      " 'Regona, Massimo & Yigitcanlar, Tan & Xia, Bo & Li, R.Y.M. (2022). '\n",
      " 'Opportunities and adoption challenges of AI in the construction industry: A '\n",
      " 'PRISMA review. Journal of Open Innovation Technology Market and Complexity, '\n",
      " '8(45). https://doi.org/10.3390/joitmc8010045\\n'\n",
      " '---\\n'\n",
      " '## Perspective: Human-Like Reasoning\\n'\n",
      " '\\n'\n",
      " '\"The theory and development of computer systems able to perform tasks '\n",
      " 'normally requiring human intelligence such as, visual perception, speech '\n",
      " 'recognition, learning, decision-making, and natural language processing.\"\\n'\n",
      " '\\n'\n",
      " 'Broad cultural awareness of AI may be traced to the landmark 1968 film '\n",
      " '\"2001: A Space Odyssey\"—in which the \"Heuristically-programmed ALgorithmic\" '\n",
      " 'computer, or \"HAL,\" converses with astronaut Frank. HAL helps Frank pilot '\n",
      " 'the journey through space, a job that Frank could not do on his own. '\n",
      " 'However, Frank eventually goes outside the spacecraft, HAL takes over '\n",
      " 'control, and this does not end well for Frank. HAL exhibits human-like '\n",
      " 'behaviors, such as reasoning, talking, and acting. Like all applications of '\n",
      " 'AI, HAL can help humans but also introduces unanticipated risks—especially '\n",
      " 'since AI reasons in different ways and with different limitations than '\n",
      " 'people do.\\n'\n",
      " '\\n'\n",
      " 'The idea of \"human-like\" is helpful because it can be a shorthand for the '\n",
      " 'idea that computers now have capabilities that are very different from the '\n",
      " 'capabilities of early edtech applications. Educational applications will be '\n",
      " 'able to converse with students and teachers, co-pilot how activities unfold '\n",
      " 'in classrooms, and take actions that impact students and teachers more '\n",
      " 'broadly. There will be both opportunities to do things much better than we '\n",
      " 'do today and risks that must be anticipated and addressed.\\n'\n",
      " '\\n'\n",
      " 'The \"human-like\" shorthand is not always useful, however, because AI '\n",
      " 'processes information differently from how people process information. When '\n",
      " 'we gloss over the differences between people and computers, we may frame '\n",
      " 'policies for AI in education that miss the mark.\\n'\n",
      " '\\n'\n",
      " '## Perspective: An Algorithm that Pursues a Goal\\n'\n",
      " '\\n'\n",
      " '\"Any computational method that is made to act independently towards a goal '\n",
      " 'based on inferences from theory or patterns in data.\"\\n'\n",
      " '\\n'\n",
      " 'This second definition emphasizes that AI systems and tools identify '\n",
      " 'patterns and choose actions to achieve a given goal. These pattern '\n",
      " 'recognition capabilities and automated recommendations will be used in ways '\n",
      " 'that impact the educational process, including student learning and teacher '\n",
      " \"instructional decision making. For example, today's personalized learning \"\n",
      " 'systems may recognize signs that a student is struggling and may recommend '\n",
      " 'an alternative instructional sequence. The scope of pattern recognition and '\n",
      " 'automated recommendations will expand.\\n'\n",
      " '\\n'\n",
      " '13 IEEE-USA Board of Directors. (February 10, 2017). Artificial intelligence '\n",
      " 'research, development and regulation. IEEE '\n",
      " 'http://globalpolicy.ieee.org/wp-content/uploads/2017/10/IEEE17003.pdf\\n'\n",
      " '\\n'\n",
      " '14 Friedman, L., Blair Black, N., Walker, E., & Roschelle, J. (November 8, '\n",
      " '2021) Safe AI in education needs you. Association of Computing Machinery '\n",
      " 'blog, '\n",
      " 'https://cacm.acm.org/blogs/blog-cacm/256657-safe-ai-in-education-needs-you/fulltext\\n'\n",
      " '---\\n'\n",
      " 'Correspondingly, humans must determine the types and degree of '\n",
      " 'responsibility we will grant to technology within educational processes, '\n",
      " 'which is not a new dilemma. For decades, the lines between the role of '\n",
      " 'teachers and computers have been discussed in education, for example, in '\n",
      " 'debates using terms such as “computer-aided instruction,” “blended '\n",
      " 'instruction,” and “personalized learning.” Yet, how are instructional '\n",
      " 'choices made in systems that include both humans and algorithms? Today, AI '\n",
      " 'systems and tools are already enabling the adaptation of instructional '\n",
      " 'sequences to student needs to give students feedback and hints, for example, '\n",
      " 'during mathematics problem solving or foreign language learning. This '\n",
      " 'discussion about the use of AI in classroom pedagogy and student learning '\n",
      " 'will be renewed and intensify as AI-enabled systems and tools advance in '\n",
      " 'capability and become more ubiquitous.\\n'\n",
      " '\\n'\n",
      " 'Let’s start with another simple example. When a teacher says, “Display a map '\n",
      " 'of ancient Greece on the classroom screen,” an AI system may choose among '\n",
      " 'hundreds of maps by noting the lesson objectives, what has worked well in '\n",
      " 'similar classrooms, or which maps have desirable features for student '\n",
      " 'learning. In this case, when an AI system suggests an instructional resource '\n",
      " 'or provides a choice among a few options, the instructor may save time and '\n",
      " 'may focus on more important goals. However, there are also forms of '\n",
      " 'AI-enabled automation that the classroom instructor may reject, for example, '\n",
      " 'enabling an AI system or tool to select the most appropriate and relevant '\n",
      " 'readings for students associated with a historical event. In this case, an '\n",
      " 'educator may choose not to utilize AI-enabled systems or tools given the '\n",
      " 'risk of AI creating false facts (“hallucinating”) or steering students '\n",
      " 'toward inaccurate depictions of historical events found on the internet. '\n",
      " 'Educators will be weighing benefits and risks like these daily.\\n'\n",
      " '\\n'\n",
      " 'Computers process theory and data differently than humans. AI’s success '\n",
      " 'depends on associations or relationships found in the data provided to an '\n",
      " 'algorithm during the AI model development process. Although some '\n",
      " 'associations may be useful, others may be biased or inappropriate. Finding '\n",
      " 'bad associations in data is a major risk, possibly leading to algorithmic '\n",
      " 'discrimination. Every guardian is familiar with the problem: A person or '\n",
      " 'computer may say, “Our data suggests your student should be placed in this '\n",
      " 'class,” and the guardian may well argue, “No, you are using the wrong data. '\n",
      " 'I know my child better, and they should instead be placed in another class.” '\n",
      " 'This problem is not limited exclusively to AI systems and tools, but the use '\n",
      " 'of AI models can amplify the problem when a computer uses data to make a '\n",
      " 'recommendation because it may appear to be more objective and authoritative, '\n",
      " 'even if it is not.\\n'\n",
      " '\\n'\n",
      " 'Although this perspective can be useful, it can be misleading. A human view '\n",
      " 'of agency, pursuing goals, and reasoning includes our human abilities to '\n",
      " 'make sense of multiple contexts. For example, a teacher may see three '\n",
      " 'students each make the same mathematical error but recognize that one '\n",
      " 'student has an Individualized Education Program to address vision issues, '\n",
      " 'another misunderstands a mathematical concept, and a third just experienced '\n",
      " 'a frustrating interaction on the playground; the same instructional decision '\n",
      " 'is therefore not appropriate. However, AI systems often lack data and '\n",
      " 'judgement to appropriately include context as they detect patterns and '\n",
      " 'automate decisions. Further, case studies show that technology has the '\n",
      " 'potential to quickly derail from safe to unsafe or from effective to '\n",
      " 'ineffective when the context shifts even slightly. For this and other '\n",
      " 'reasons, people must be involved in goal setting, pattern analysis, and '\n",
      " 'decision-making.\\n'\n",
      " '\\n'\n",
      " '15 Russell, S. (2019). Human compatible: Artificial intelligence and the '\n",
      " 'problem of control. Viking. ISBN 978-0-525-55861-3.\\n'\n",
      " '---\\n'\n",
      " '## Perspective: Intelligence Augmentation\\n'\n",
      " '\\n'\n",
      " '“Augmented intelligence is a design pattern for a human-centered partnership '\n",
      " 'model of people and artificial intelligence (AI) working together to enhance '\n",
      " 'cognitive performance, including learning, decision making, and new '\n",
      " 'experiences.”\\n'\n",
      " '\\n'\n",
      " 'Foundation #1 (above) keeps humans in the loop and positions AI systems and '\n",
      " 'tools to support human reasoning. “Intelligence Augmentation” (IA) centers '\n",
      " '“intelligence” and “decision making” in humans but recognizes that people '\n",
      " 'sometimes are overburdened and benefit from assistive tools. AI may help '\n",
      " 'teachers make better decisions because computers notice patterns that '\n",
      " 'teachers can miss. For example, when a teacher and student agree that the '\n",
      " 'student needs reminders, an AI system may provide reminders in whatever form '\n",
      " 'a student likes without adding to the teacher’s workload. Intelligence '\n",
      " 'Automation (IA) uses the same basic capabilities of AI, employing '\n",
      " 'associations in data to notice patterns, and, through automation, takes '\n",
      " 'actions based on those patterns. However, IA squarely focuses on helping '\n",
      " 'people in human activities of teaching and learning, whereas AI tends to '\n",
      " 'focus attention on what computers can do.\\n'\n",
      " '\\n'\n",
      " '## Definition of “Model”\\n'\n",
      " '\\n'\n",
      " 'The above perspectives open a door to making sense of AI. Yet, to assess AI '\n",
      " 'meaningfully, constituents must consider specific models and how they are '\n",
      " 'developed. In everyday usage, the term “model” has multiple definitions. We '\n",
      " 'clarify our intended meaning, which is a meaning similar to “mathematical '\n",
      " 'model,” below. (Conversely, note that “model” as used in “AI model” is '\n",
      " 'unlike the usage in “model school” or “instructional model” as AI model is '\n",
      " 'not a singular case created by experts to serve as an exemplar.)\\n'\n",
      " '\\n'\n",
      " 'AI models are like financial models: an approximation of reality that is '\n",
      " 'useful for identifying patterns, making predictions, or analyzing '\n",
      " 'alternative decisions. In a typical middle school math curriculum, students '\n",
      " 'use a mathematical model to analyze which of two cell phone plans is better. '\n",
      " 'Financial planners use this type of model to provide guidance on a '\n",
      " 'retirement portfolio. At its heart, AI is a highly advanced mathematical '\n",
      " 'toolkit for building and using models. Indeed, in well-known chatbots, '\n",
      " 'complex essays are written one word at a time. The underlying AI model '\n",
      " 'predicts which next words would likely follow the text written so far; AI '\n",
      " 'chatbots use a very large statistical model to add one likely word at a '\n",
      " 'time, thereby writing surprisingly coherent essays. When we ask about the '\n",
      " 'model at the heart of AI, we begin to get answers about “what aspects of '\n",
      " 'reality does the model approximate well?” and “how appropriate is it to the '\n",
      " 'decision to be made?” One could similarly ask about algorithms—the specific '\n",
      " 'decision-making processes that an AI model uses to go from inputs to '\n",
      " 'outputs. One could also ask about the quality of the data used to build the '\n",
      " 'model—for example, how representative is that data? Switching among three '\n",
      " 'terms—\\n'\n",
      " '\\n'\n",
      " '16 Gartner (n.d.) Gartner glossary: Augmented intelligence. Gartner. '\n",
      " 'https://www.gartner.com/en/information-technology/glossary/augmented-intelligence\\n'\n",
      " '\\n'\n",
      " '17 Englebart, D.C. (October 1962). Augmenting human intellect: A conceptual '\n",
      " 'framework. SRI Summary Report AFOSR-3223. '\n",
      " 'https://www.dougengelbart.org/pubs/augment-3906.html\\n'\n",
      " '---\\n'\n",
      " 'models, algorithms, and data—will become confusing. Because the terms are '\n",
      " 'closely related, we’ve chosen to focus on the concept of AI models. We want '\n",
      " \"to bring to the fore the idea that every AI model is incomplete, and it's \"\n",
      " 'important to know how well the AI model fits the reality we care about, '\n",
      " 'where the model will break down, and how.\\n'\n",
      " '\\n'\n",
      " 'Sometimes people avoid talking about the specifics of models to create a '\n",
      " 'mystique. Talking as though AI is unbounded in its potential capabilities '\n",
      " 'and a nearly perfect approximation to reality can convey an excitement about '\n",
      " 'the possibilities of the future. The future, however, can be oversold. '\n",
      " 'Similarly, sometimes people stop calling a model AI when its use becomes '\n",
      " 'commonplace, yet such systems are still AI models with all of the risks '\n",
      " 'discussed here. We need to know exactly when and where AI models fail to '\n",
      " 'align to visions for teaching and learning.\\n'\n",
      " '\\n'\n",
      " 'Insight: AI Systems Enable New Forms of Interaction AI models allow '\n",
      " 'computational processes to make recommendations or plans and also enable '\n",
      " 'them to support forms of interaction that are more natural, such as speaking '\n",
      " 'to an assistant. AI-enabled educational systems will be desirable in part '\n",
      " 'due to their ability to support more natural interactions during teaching '\n",
      " 'and learning. In classic edtech platforms, the ways in which teachers and '\n",
      " 'students interact with edtech are limited. Teachers and students may choose '\n",
      " 'items from a menu or in a multiple-choice question. They may type short '\n",
      " 'answers. They may drag objects on the screen or use touch gestures. The '\n",
      " 'computer provides outputs to students and teachers through text, graphics, '\n",
      " 'and multimedia. Although these forms of inputs and outputs are versatile, no '\n",
      " 'one would mistake this style of interaction with the way two people interact '\n",
      " 'with one another; it is specific to human-computer interaction. With AI, '\n",
      " 'interactions with computers are likely to become more like human-to-human '\n",
      " 'interactions (see Figure 4). A teacher may speak to an AI assistant, and it '\n",
      " 'may speak back. A student may make a drawing, and the computer may highlight '\n",
      " 'a portion of the drawing. A teacher or student may start to write something, '\n",
      " 'and the computer may finish their sentence—as when today’s email programs '\n",
      " 'can complete thoughts faster than we can type them.\\n'\n",
      " '\\n'\n",
      " 'Additionally, the possibilities for automated actions that can be executed '\n",
      " 'by AI tools are expanding. Current personalization tools may automatically '\n",
      " 'adjust the sequence, pace, hints, or trajectory through learning '\n",
      " 'experiences. Actions in the future might look like an AI system or tool that '\n",
      " 'helps a student with homework or a teaching assistant that reduces a '\n",
      " 'teacher’s workload by recommending lesson plans that fit a teacher’s needs '\n",
      " 'and are similar to lesson plans a teacher previously liked. Further, an '\n",
      " 'AI-enabled assistant may appear as an additional “partner” in a small group '\n",
      " 'of students who are working together on a collaborative assignment. An '\n",
      " 'AI-enabled tool may also help teachers with complex classroom routines. For '\n",
      " 'example, a\\n'\n",
      " '\\n'\n",
      " 'Shemshack, A., Spector, J.M. (2020) A systematic literature review of '\n",
      " 'personalized learning terms. Smart Learning Environments, 7(33). '\n",
      " 'https://doi.org/10.1186/s40561-020-00140-9\\n'\n",
      " '\\n'\n",
      " 'Roschelle, J., Feng, M., Murphy, R. & Mason, C.A. (2016). Online mathematics '\n",
      " 'homework increases student achievement. AERA Open, 2(4), 1-12. DOI: '\n",
      " '10.1177/2332858416673968\\n'\n",
      " '\\n'\n",
      " 'Celik, I., Dindar, M., Muukkonen, H. & Järvelä, S. (2022). The promises and '\n",
      " 'challenges of artificial intelligence for teachers: A systematic review of '\n",
      " 'research. TechTrends, 66, 616–630. '\n",
      " 'https://doi.org/10.1007/s11528-022-00715-y\\n'\n",
      " '\\n'\n",
      " 'Chen, C., Park, H.W. & Breazeal, C. (2020). Teaching and learning with '\n",
      " 'children: Impact of reciprocal peer learning with a social robot on '\n",
      " 'children’s learning and emotive engagement. Computers & Education, 150, '\n",
      " 'https://doi.org/10.1016/j.compedu.2020.103836\\n'\n",
      " '\\n'\n",
      " 'Holstein, K., McLaren, B.M., & Aleven, V. (2019). Co-designing a real-time '\n",
      " 'classroom orchestration tool to support teacher–AI complementarity. Journal '\n",
      " 'of Learning Analytics, 6(2). https://doi.org/10.18608/jla.2019.62.3\\n'\n",
      " '---\\n'\n",
      " 'tool may help teachers with orchestrating the movement of students from a '\n",
      " 'full class discussion into small groups and making sure each group has the '\n",
      " 'materials needed to start their work.\\n'\n",
      " '\\n'\n",
      " '| |Familiar Technology Capabilities|Future Technology Capabilities|\\n'\n",
      " '|---|---|---|\\n'\n",
      " '|Input|Typing Clicking and dragging Touching and gesturing|Speaking Drawing '\n",
      " 'Analyzing images and video|\\n'\n",
      " '|Processing|Displaying information and tasks Sequencing learning activities '\n",
      " 'Checking student work|Assisting students and teachers Planning and adapting '\n",
      " 'activities Revealing patterns in student work|\\n'\n",
      " '|Output|Text Graphics Multimedia Dashboards|Conversations Annotating and '\n",
      " 'highlighting Suggesting and recommending Organizing and guiding|\\n'\n",
      " '\\n'\n",
      " 'Key Recommendation: Human in the Loop AI\\n'\n",
      " '\\n'\n",
      " 'Many have experienced a moment where technology surprised them with an '\n",
      " 'uncanny ability to recommend what feels like a precisely personalized '\n",
      " 'product, song, or even phrase to complete a sentence in a word processor '\n",
      " 'such as the one being used to draft this document. Throughout this '\n",
      " 'supplement, we talk about specific, focused applications where AI systems '\n",
      " 'may bring value (or risks) into education. At no point do we intend to imply '\n",
      " 'that AI can replace a teacher, a guardian, or an educational leader as the '\n",
      " 'custodian of their students’ learning. We talk about the limitations of '\n",
      " 'models in AI and the conversations that educational constituents need to '\n",
      " 'have about what qualities they want AI models to have and how they should be '\n",
      " 'used.\\n'\n",
      " '\\n'\n",
      " '“We can use AI to study the diversity, the multiplicity of effective '\n",
      " 'learning approaches and think about the various models to help us get a '\n",
      " 'broader understanding of what effective, meaningful engagement might look '\n",
      " 'like across a variety of different contexts.”\\n'\n",
      " '\\n'\n",
      " '—Dr. Marcelo Aaron Bonilla Worsley\\n'\n",
      " '\\n'\n",
      " 'Roschelle, J., Dimitriadis, Y. & Hoppe, U. (2013). Classroom orchestration: '\n",
      " 'Synthesis. Computers & Education, 69, 512-526. '\n",
      " 'https://doi.org/10.1016/j.compedu.2013.04.010\\n'\n",
      " '---\\n'\n",
      " 'These limitations lead to our first recommendation: that we pursue a vision '\n",
      " 'of AI where humans are in the loop. That means that people are part of the '\n",
      " 'process of noticing patterns in an educational system and assigning meaning '\n",
      " 'to those patterns. It also means that teachers remain at the helm of major '\n",
      " 'instructional decisions. It means that formative assessments involve teacher '\n",
      " 'input and decision making, too. One loop is the cycle of recognizing '\n",
      " 'patterns in what students do and selecting next steps or resources that '\n",
      " 'could support their learning. Other loops involve teachers planning and '\n",
      " 'reflecting on lessons. Response to Intervention is another well-known type '\n",
      " 'of loop.\\n'\n",
      " '\\n'\n",
      " 'The idea of humans in the loop is part of our broader discussions happening '\n",
      " 'about AI and society, not just AI in education. Interested readers could '\n",
      " 'look for more on human-centered AI, responsible AI, value-sensitive AI, AI '\n",
      " 'for social good, and other similar terms that ally with humans in the loop, '\n",
      " 'such as “human-centered AI.”\\n'\n",
      " '\\n'\n",
      " 'Exercising judgement and control in the use of AI systems and tools is an '\n",
      " 'essential part of providing the best opportunity to learn for all '\n",
      " 'students—especially when educational decisions carry consequence. AI does '\n",
      " 'not have the broad qualities of contextual judgment that people do. '\n",
      " 'Therefore, people must remain responsible for the health and safety of our '\n",
      " 'children, for all students’ educational success and preparation for their '\n",
      " 'futures, and for creating a more equitable and just society.\\n'\n",
      " '---\\n'\n",
      " '## Learning\\n'\n",
      " '\\n'\n",
      " 'The Department’s long-standing edtech vision sees students as active '\n",
      " 'learners; students participate in discussions that advance their '\n",
      " 'understanding, use visualizations and simulations to explain concepts as '\n",
      " 'they relate to the real world, and leverage helpful scaffolding and timely '\n",
      " 'feedback as they learn. Constituents want technology to align to and build '\n",
      " 'on these and other research-based understandings of how people learn. '\n",
      " 'Educators can draw upon two books titled How People Learn and How People '\n",
      " 'Learn II by the National Academies of Sciences, Engineering, and Medicine '\n",
      " 'for a broad synthesis of what we know about learning.24 As we shape '\n",
      " 'AI-enhanced edtech around research-based principles, a key goal must be to '\n",
      " 'strengthen and support learning for those who have experienced unfavorable '\n",
      " 'circumstances for learning, such as caused by the COVID-19 pandemic or by '\n",
      " 'broader inequities. And we must keep a firm eye toward the forms of learning '\n",
      " 'that will most benefit learners in their future lives in communities and '\n",
      " 'workplaces. Examples of AI supporting learning principles in this section '\n",
      " 'include the following: AI-based tutoring for students as they solve math '\n",
      " 'problems (based on cognitive learning theories), adapting to learners with '\n",
      " 'special needs (based on the Universal Design for Learning framework and '\n",
      " 'related theories), and AI support for effective student teamwork (based on '\n",
      " 'theories in the field called “Computer Supported Collaborative Learning”).\\n'\n",
      " '\\n'\n",
      " '## Insight: AI Enables Adaptivity in Learning\\n'\n",
      " '\\n'\n",
      " 'Adaptivity has been recognized as a key way in which technology can improve '\n",
      " 'learning.25 AI can be a toolset for improving the adaptivity of edtech. AI '\n",
      " 'may improve a technology’s ability to meet students where they are, build on '\n",
      " 'their strengths, and grow their knowledge and skills. Because of AI’s powers '\n",
      " 'of work with natural forms of input and the foundational strengths of AI '\n",
      " 'models (as discussed in the What is AI? section), AI can be an especially '\n",
      " 'strong toolkit for expanding the adaptivity provided to students. And yet, '\n",
      " 'especially with AI, adaptivity is always more specific and limited than what '\n",
      " 'a broad phrase like “meet students where they are” might suggest. Core '\n",
      " 'limits arise from the nature of the model at the heart of any specific '\n",
      " 'AI-enabled system. Models are approximations of reality. When important '\n",
      " 'parts of human learning are left out of the model or less fully developed, '\n",
      " 'the resulting adaptivity will also be limited, and the resulting supports '\n",
      " 'for learning may be brittle or narrow. Consequently, this section on '\n",
      " 'Learning focuses on one key concept: Work toward AI models that fit the '\n",
      " 'fullness of visions for learning—and avoid limiting learning to what AI can '\n",
      " 'currently model well.\\n'\n",
      " '\\n'\n",
      " 'AI models are demonstrating greater skills because of advances in what are '\n",
      " 'called “large language models” or sometimes “foundational models.” These '\n",
      " 'very general models still have limits. For example, generative AI models '\n",
      " 'discussed in the mainstream news can quickly generate convincing essays '\n",
      " 'about a wide variety of topics while other models can draw credible images '\n",
      " 'based on just a few prompts. Despite the excitement about foundational '\n",
      " 'models, experts in our\\n'\n",
      " '\\n'\n",
      " '|Content|Page Number|\\n'\n",
      " '|---|---|\\n'\n",
      " '|National Research Council. 2000. How people learn: Brain, mind, experience, '\n",
      " 'and school. The National Academies Press.|https://doi.org/10.17226/9853|\\n'\n",
      " '|National Academies of Sciences, Engineering, and Medicine. 2018. How people '\n",
      " 'learn II: Learners, contexts, and cultures. The National Academies '\n",
      " 'Press.|https://doi.org/10.17226/24783|\\n'\n",
      " '|Aleven, V., McLaughlin, E. A., Glenn, R. A., & Koedinger, K. R. (2016). '\n",
      " 'Instruction based on adaptive learning technologies. In Mayer, R.E. & '\n",
      " 'Alexander, P.A., Handbook of research on learning and instruction, 522-560. '\n",
      " 'ISBN: 113883176X| |\\n'\n",
      " '---\\n'\n",
      " 'Listening sessions warned that AI models are narrower than visions for human '\n",
      " 'learning and that designing learning environments with these limits in mind '\n",
      " 'remains very important. The models are also brittle and can’t perform well '\n",
      " 'when contexts change. In addition, they don’t have the same “common sense” '\n",
      " 'judgment that people have, often responding in ways that are unnatural or '\n",
      " 'incorrect. Given the unexpected ways in which foundational models miss the '\n",
      " 'mark, keeping humans in the loop remains highly important.\\n'\n",
      " '\\n'\n",
      " 'Intelligent Tutoring Systems: An Example of AI Models\\n'\n",
      " '\\n'\n",
      " 'One long-standing type of AI-enabled technology is an Intelligent Tutoring '\n",
      " 'System (ITS). In an early success, scientists were able to build accurate '\n",
      " 'models of how human experts solve mathematical problems. The resulting model '\n",
      " 'was incorporated into a system that would observe student problem solving as '\n",
      " 'they worked on mathematical problems on a computer. Researchers who studied '\n",
      " 'human tutors found that feedback on specific steps (and not just right or '\n",
      " 'wrong solutions) is a likely key to why tutoring is so effective. For '\n",
      " 'example, when a student diverged from the expert model, the system gave '\n",
      " 'feedback to help the student get back on track.\\n'\n",
      " '\\n'\n",
      " 'Importantly, this feedback went beyond right or wrong, and instead, the '\n",
      " 'model was able to provide feedback on specific steps of a solution process. '\n",
      " 'A significant advancement of AI, therefore, can be its ability to provide '\n",
      " 'adaptivity at the step-by-step level and its ability to do so at scale with '\n",
      " 'modest cost.\\n'\n",
      " '\\n'\n",
      " 'As a research and development (R&D) field emerged to advance ITS, the work '\n",
      " 'has gone beyond mathematics problems to additional important issues beyond '\n",
      " 'step-by-step problem solving. In the early work, some limitations can be '\n",
      " 'observed. The kinds of problems that an ITS could support were logical or '\n",
      " 'mathematical, and they were closed tasks, with clear expectations for what a '\n",
      " 'solution and solution process should look like. Also, the “approximation of '\n",
      " 'reality” in early AI models related to cognition and not to other elements '\n",
      " 'of human learning, for example, social or motivational aspects. Over time, '\n",
      " 'these early limitations have been addressed in two ways: by expanding the AI '\n",
      " 'models and by involving humans in the loop, a perspective that is also '\n",
      " 'important now. Today, for example, if an ITS specializes in feedback as a '\n",
      " 'student practices, a human teacher could still be responsible for motivating '\n",
      " 'student engagement and self-regulation along with other aspects of '\n",
      " 'instruction. In other contemporary examples, the computer ITS might focus on '\n",
      " 'problem solving practice, while teachers work with students in small groups. '\n",
      " 'Further, students can be in the loop with AI, as is the case with “open '\n",
      " 'learner models”—a type of AI-enabled system that provides information to '\n",
      " 'support student self-monitoring and reflection.\\n'\n",
      " '---\\n'\n",
      " 'Although R&D along the lines of an ITS should not limit the view of what’s '\n",
      " 'possible, such an example is useful because so much research and evaluation '\n",
      " 'has been done on the ITS approach. Researchers have looked across all the '\n",
      " 'available high-quality studies in a meta-analysis and concluded that ITS '\n",
      " 'approaches are effective.31 Right now, many school systems are looking at '\n",
      " 'high-intensity human tutoring to help students with unfinished learning. '\n",
      " 'Human tutoring is very expensive, and it is hard to find enough high-quality '\n",
      " 'human tutors. With regard to large-scale needs, if it is possible for an ITS '\n",
      " 'to supplement what human tutors do, it might be possible to extend beyond '\n",
      " 'the amount of tutoring that people can provide to students.\\n'\n",
      " '\\n'\n",
      " 'Important Directions for Expanding AI-Based Adaptivity\\n'\n",
      " '\\n'\n",
      " 'Adaptivity is sometimes referred to as “personalization.” Although this is a '\n",
      " 'convenient term, many observers have noted how imprecise it is.32 For some '\n",
      " 'educators, personalization means giving learners “voice and choice,” and for '\n",
      " 'others it means that a learning management system recommends an individual '\n",
      " '“playlist” of activities to each student. Hidden in that imprecision is the '\n",
      " 'reality that many edtech products that personalize do so in limited ways. '\n",
      " 'Adjusting the difficulty and the order of lesson materials are among the two '\n",
      " 'most common ways that edtech products adapt. And yet, any teacher knows '\n",
      " 'there is more to supporting learning than adjusting the difficulty and '\n",
      " 'sequence of materials. For example, a good teacher can find ways to engage a '\n",
      " 'student by connecting to their own past experiences and can shape '\n",
      " 'explanations until they really connect in an “aha!” moment for that student. '\n",
      " 'When we say, “meet the learner where they are,” human teachers bring a much '\n",
      " 'more complete picture of each learner than most available edtech. The '\n",
      " 'teacher is also not likely to “over personalize” (by performing like an '\n",
      " 'algorithm that only presents material for which the learner has expressed '\n",
      " 'interest), thereby limiting the student’s exposure to new topics. The nature '\n",
      " 'of “teachable moments” that a human teacher can grasp is broader than the '\n",
      " 'teachable moments today’s AI models grasp.\\n'\n",
      " '\\n'\n",
      " 'In our listening sessions, we heard many ways in which the core models in an '\n",
      " 'AI system must be expanded. We discuss these below.\\n'\n",
      " '\\n'\n",
      " '|1.|From deficit-based to asset-oriented.|Listening session attendees noted '\n",
      " 'that the rhetoric around adaptivity has often been deficit-based; technology '\n",
      " 'tries to pinpoint what a student is lacking and then provides instruction to '\n",
      " \"fill that specific gap. Teachers also orient to students' strengths; they \"\n",
      " 'find competencies or “assets” a student has and use those to build up the '\n",
      " 'students’ knowledge. AI models cannot be fully equitable while failing to '\n",
      " 'recognize or build upon each student’s sources of competency. AI models that '\n",
      " 'are more asset-oriented would be an advance.|\\n'\n",
      " '|---|---|---|\\n'\n",
      " '|2.|From individual cognition to including social and other aspects of '\n",
      " 'learning.|The existing adaptivity rhetoric has also tended to focus on '\n",
      " 'individualized learning and mostly on cognitive elements of learning, with '\n",
      " 'motivational and other elements only brought in to support the cognitive '\n",
      " 'learning goals. Attendees observe that their vision for learning is broader '\n",
      " 'than cognition. Social learning is important, for example, especially|\\n'\n",
      " '\\n'\n",
      " '31 Kulik, J.A., & Fletcher, J.D. (2016). Effectiveness of intelligent '\n",
      " 'tutoring systems: A meta-analytic review. Review of Educational Research, '\n",
      " '86(1), 42–78; Ma, W., Adescope, O.O, Nesbit, J.C. & Liu, Q. (2014). '\n",
      " 'Intelligent tutoring systems and learning outcomes: A meta-analysis. Journal '\n",
      " 'of Educational Psychology, 106(4), 901–918. '\n",
      " 'http://dx.doi.org/10.1037/a0037123\\n'\n",
      " '\\n'\n",
      " '32 Plass, J.L., & Pawar, S. (2020). Toward a taxonomy of adaptivity for '\n",
      " 'learning. Journal of Research on Technology in Education, 52(3), 275–300. '\n",
      " 'https://doi.org/10.1080/15391523.2020.1719943\\n'\n",
      " '---\\n'\n",
      " 'for students to learn to reason, explain, and justify. For students who are '\n",
      " 'learning English, customized and adaptive support for improving language '\n",
      " 'skills while learning curricular content is clearly important. Developing '\n",
      " 'self-regulation skills is also important. A modern vision of learning is not '\n",
      " 'individualistic; it recognizes that students learn in groups and communities '\n",
      " 'too.\\n'\n",
      " '\\n'\n",
      " 'From neurotypical to neurodiverse learners. AI models could help in '\n",
      " 'including neurodiverse learners (students who access, process, and interact '\n",
      " 'with the world in less common ways than “neurotypical” students) who could '\n",
      " 'benefit from different learning paths and from forms of display and input '\n",
      " 'that fit their strengths. Constituents want AI models that can support '\n",
      " 'learning for neurodiverse learners and learners with disabilities. Thus, '\n",
      " 'they want AI models that can work with multiple paths to learning and '\n",
      " 'multiple modalities of interaction. Such models should be tested for '\n",
      " 'efficacy, to guard against the possibility that some students could be '\n",
      " 'assigned a “personalized” but inadequate learning resource. In addition, '\n",
      " 'some systems for neurodiverse students are presently underutilized, so '\n",
      " 'designs that support intended use will also be important.\\n'\n",
      " '\\n'\n",
      " 'From fixed tasks to active, open, and creative tasks. As mentioned above, AI '\n",
      " 'models are historically better at closed tasks like solving a math problem '\n",
      " 'or logical tasks like playing a game. In terms of life-wide and lifelong '\n",
      " 'opportunities, we value learning how to succeed at open-ended and creative '\n",
      " 'tasks that require extended engagement from the learner, and these are often '\n",
      " 'not purely mathematical or logical. We want students to learn to invent and '\n",
      " 'create innovative approaches. We want AI models that enable progress on '\n",
      " 'open, creative tasks.\\n'\n",
      " '\\n'\n",
      " 'From correct answers to additional goals. At the heart of many adaptivity '\n",
      " 'approaches now on the market, the model inside the technology counts '\n",
      " \"students' wrong answers and decides whether to speed up, slow down, or offer \"\n",
      " 'a different type of learning support. Yet, right and wrong answers are not '\n",
      " 'the only learning goals. We want students to learn how to self-regulate when '\n",
      " 'they experience difficulties in learning, for example, such as being able to '\n",
      " 'persist in working on a difficult problem or knowing how and when to ask for '\n",
      " 'help. We want learners to become skilled in teamwork and in leading teams. '\n",
      " 'As students grow, we want them to develop more agency and to be able to act '\n",
      " 'on their own to advance toward their own learning goals.\\n'\n",
      " '\\n'\n",
      " 'Listing every dimension of expansion that we heard in our listening sessions '\n",
      " 'is beyond the scope of this report. Some additional dimensions are presented '\n",
      " 'in the following sections on Teaching, Assessment, and Research. For '\n",
      " 'example, in Research, we discuss all the ways in which AI systems have '\n",
      " 'trouble with context—context that humans readily grasp and consider.\\n'\n",
      " '\\n'\n",
      " 'Overall, constituents in the listening sessions realized we need an '\n",
      " 'ambitious outlook on learning to respond to the future today’s learners '\n",
      " 'face. Constituents were concerned about ways in which AI might narrow '\n",
      " 'learning. For example, if the incorporation of AI into education slowed '\n",
      " 'attention to students’ skills on creative, open-ended tasks and their '\n",
      " 'ability to lead and collaborate in teams, then school districts may be less '\n",
      " 'able to realize their students’ progress in relation to a Portrait of a '\n",
      " 'Graduate who excels in communication and other skills valued in communities '\n",
      " 'and careers.\\n'\n",
      " '---\\n'\n",
      " 'Constituents reminded us that as we conceptualize what we want AI in edtech '\n",
      " 'to accomplish, we must start and constantly revisit a human-centered vision '\n",
      " 'of learning.\\n'\n",
      " '\\n'\n",
      " 'A Duality: Learning With and About AI\\n'\n",
      " '\\n'\n",
      " 'As AI is brought into schools, two broad perspectives about AI in education '\n",
      " 'arise: (1) AI in support of student learning; and (2) support for learning '\n",
      " 'about AI and related technologies. So far, we’ve discussed AI systems and '\n",
      " 'tools to support student learning and mastery of subjects like mathematics '\n",
      " 'and writing. Yet, it is also important that students learn about AI, '\n",
      " 'critically examine its presence in education and society, and determine its '\n",
      " 'role and value in their own lives and careers. We discuss risks across each '\n",
      " 'section in this report. Here, it is important for students to become more '\n",
      " 'aware of and savvy to the risks of AI—including risks of bias and '\n",
      " 'surveillance—as they appear in all elements of their lives. In the recent '\n",
      " 'past, schools have supported students’ understanding of cybersecurity, for '\n",
      " 'example. AI will bring new risks, and students need to learn about them.\\n'\n",
      " '\\n'\n",
      " 'We are encouraged by efforts we’ve seen underway that would give students '\n",
      " 'opportunities to learn about how AI works while also giving them '\n",
      " 'opportunities to discuss relevant topics like privacy and security. Other '\n",
      " 'learning goals are noted in the K-12 Computer Science Framework. We’ve seen '\n",
      " 'that students can begin learning about AI in elementary, middle, and high '\n",
      " 'school. They can use AI to design simulations and products that they find '\n",
      " 'exciting. And we’ve seen that students want to talk about the ethics of '\n",
      " 'products they experience in their everyday lives and have much to say about '\n",
      " 'the kinds of products they’d like to see or not see in school. (And later, '\n",
      " 'in the Research section, we note the desire for co-design processes that '\n",
      " 'involve students in creating the next generation of AI-enabled edtech). '\n",
      " 'Overall, it’s important to balance attention to using AI to support learning '\n",
      " 'and giving students opportunities to learn about AI.\\n'\n",
      " '\\n'\n",
      " 'A Challenge: Systems Thinking About AI in Education\\n'\n",
      " '\\n'\n",
      " 'As AI expands into the educational system, our listening session attendees '\n",
      " 'reminded us that it will be entering parts or locations of the system that '\n",
      " 'are presently dysfunctional. AI is certainly not a fix for broken systems, '\n",
      " 'and instead, must be used with even more care when the systems’ context is '\n",
      " 'unstable or uncertain.\\n'\n",
      " '\\n'\n",
      " '33 Forsyth, S., Dalton, B., Foster, E.H., Walsh, B., Smilack, J., & Yeh, T. '\n",
      " \"(2021, May). Imagine a more ethical AI: Using stories to develop teens' \"\n",
      " 'awareness and understanding of artificial intelligence and its societal '\n",
      " 'impacts. In 2021 Conference on Research in Equitable and Sustained '\n",
      " 'Participation in Engineering, Computing, and Technology (RESPECT). IEEE. '\n",
      " 'https://doi.org/10.1109/RESPECT51740.2021.9620549; Zhang, H., Lee, I., Ali, '\n",
      " 'S., DiPaola, D., Cheng, Y., & Breazeal, C. (2022). Integrating ethics and '\n",
      " 'career futures with technical learning to promote AI literacy for middle '\n",
      " 'school students: An exploratory study. International Journal of Artificial '\n",
      " 'Intelligence in Education, 1–35. https://doi.org/10.1007/s40593-022-00293-3\\n'\n",
      " '---\\n'\n",
      " '“First and foremost, they are getting deployed in educational contexts that '\n",
      " \"are already fragmented and broken and unequal. Technology doesn't \"\n",
      " 'discriminate—we do. So, as we think about the application of these new '\n",
      " 'systems, we have to really think about the contextual application of AI.” '\n",
      " '—Dr. Nicole Turner\\n'\n",
      " '\\n'\n",
      " 'As discussed previously, because AI systems and tools do not fully align '\n",
      " 'with goals for learning, we have to design educational settings to situate '\n",
      " 'AI in the right place, where educators and other adults can make effective '\n",
      " 'use of these tools for teaching and learning. Within the ITS example, we saw '\n",
      " 'that AI could make learning by practicing math problems more effective, and '\n",
      " 'a whole curricular approach might include roles for teachers that emphasize '\n",
      " 'mathematical practices like argumentation and modeling. Further, small-group '\n",
      " 'work is likely to remain important: Students might work in small groups to '\n",
      " 'use mathematics to predict or justify as they work on responding to a '\n",
      " 'realistic challenge. At the present, one “right place” for people, and not '\n",
      " 'AI, is understanding how learning can be culturally responsive and '\n",
      " 'culturally sustaining, as AI is not even close to being ready to connect '\n",
      " 'learning to the unique strengths in a student’s community and family.\\n'\n",
      " '\\n'\n",
      " 'Open Questions About AI for Learning\\n'\n",
      " '\\n'\n",
      " 'With advances occurring in the foundations for AI, opportunities to use AI '\n",
      " 'in support of learning are rapidly expanding. As we explore these '\n",
      " 'opportunities, the open questions below deserve ongoing attention:\\n'\n",
      " '\\n'\n",
      " 'To what extent is AI enabling adaptation to students’ strengps and not just '\n",
      " 'deficits? Is AI enabling improved support for learners wip disabilities and '\n",
      " 'English language learners?\\n'\n",
      " 'How are youp voices involved in choosing and using AI for learning?\\n'\n",
      " 'Is AI leading to narrower student activities (e.g., procedural map '\n",
      " 'problems), or pe fuller range of activities highlighted in pe National '\n",
      " 'Educational Technology Plan (NETP), which emphasizes features such as '\n",
      " 'personalized learning, project-based learning, learning from visualizations, '\n",
      " 'simulations, and virtual reality, as well as learning across school, '\n",
      " 'community, and familial settings?\\n'\n",
      " 'Is AI supporting pe whole learner, including social dimensions of learning '\n",
      " 'such as enabling students to be active participants in small group and '\n",
      " 'collaborative learning? For example, does AI contribute to aspects of '\n",
      " 'student collaboration we value like shared attention, mutual engagement, '\n",
      " 'peer help, self-regulation, and building on each oper’s contributions?\\n'\n",
      " 'When AI is used, are students’ privacy and data protected? Are students and '\n",
      " 'peir guardians informed about what happens wip peir data?\\n'\n",
      " 'How strong are pe processes or systems for monitoring student use of AI for '\n",
      " 'barriers, bias, or oper undesirable consequences of AI use by learners? How '\n",
      " 'are emergent issues addressed?\\n'\n",
      " 'Is high-quality research or evaluations about pe impacts of using pe AI '\n",
      " 'system for student learning available? Do we know not only wheper pe system '\n",
      " 'works but for whom and under what conditions?\\n'\n",
      " '---\\n'\n",
      " 'Key Recommendation: Seek AI Models Aligned to a Vision for Learning\\n'\n",
      " 'We’ve called attention to how advances in AI are important to adaptivity but '\n",
      " 'also to ways in which adaptivity is limited by the model’s inherent quality. '\n",
      " 'We noted that a prior wave of edtech used the term “personalized” in '\n",
      " 'differing ways, and it was often important to clarify what personalization '\n",
      " 'meant for a particular product or service. Thus, our key recommendation is '\n",
      " 'to tease out the strengths and limitations of AI models inside forthcoming '\n",
      " 'edtech products and to focus on AI models that align closely to desired '\n",
      " 'visions of learning. AI is now advancing rapidly, and we should '\n",
      " 'differentiate between products that have simple AI-like features inside and '\n",
      " 'products that have more sophisticated AI models.\\n'\n",
      " 'Looking at what’s happening in research and development, we can see '\n",
      " 'significant effort and push toward overcoming these limitations. We noted '\n",
      " 'that decision makers need to be careful about selecting AI models that might '\n",
      " 'narrow their vision for learning, as general artificial intelligence does '\n",
      " 'not exist. And because AI models will always be narrower than real world '\n",
      " 'experience, we need to proceed with systems thinking in which humans are in '\n",
      " 'the loop, with the strengths and weaknesses of the specific educational '\n",
      " 'system considered. We hold that the full system for learning is broader than '\n",
      " 'its AI component.\\n'\n",
      " '---\\n'\n",
      " '## Teaching\\n'\n",
      " '\\n'\n",
      " 'Teachers have long envisioned many things that technology could make '\n",
      " 'possible for teachers, their classrooms, and their students but not the '\n",
      " 'changes wrought by the recent pandemic. Today, nearly all teachers have '\n",
      " 'experienced uses of technologies for instruction that no one anticipated. '\n",
      " 'Some of those experiences were positive, and others were not. All of the '\n",
      " 'experiences provide an important context as we think further about teaching '\n",
      " 'and technology.\\n'\n",
      " '\\n'\n",
      " 'There is a critical need to focus on addressing the challenges teachers '\n",
      " 'experience. It must become easier for teachers to do the amazing work they '\n",
      " 'always do. We must also remember why people choose the teaching profession '\n",
      " 'and ensure they can do the work that matters. This section discusses '\n",
      " 'examples of AI supporting teachers and teaching including these concepts: AI '\n",
      " 'assistants to reduce routine teaching burdens; AI that provides teachers '\n",
      " 'with recommendations for their students’ needs and extends their work with '\n",
      " 'students; and AI that helps teachers to reflect, plan, and improve their '\n",
      " 'practice.\\n'\n",
      " '\\n'\n",
      " '“One opportunity I see with AI is being able to reduce the amount of '\n",
      " 'attention I have to give to administrative things and increase the amount of '\n",
      " 'attention I can give to my students with their learning needs in the '\n",
      " \"classroom. So that's the first one that I'd say that I'm super excited about \"\n",
      " 'the possibility of AI to support me as a teacher.\"\\n'\n",
      " '—Vidula Plante\\n'\n",
      " '\\n'\n",
      " '## Always Center Educators in Instructional Loops\\n'\n",
      " '\\n'\n",
      " 'To succeed with AI as an enhancement to learning and teaching, we need to '\n",
      " 'always center educators (ACE). Practically speaking, practicing “ACE in AI” '\n",
      " 'means keeping a humanistic view of teaching front and center. ACE leads the '\n",
      " 'Department to confidently respond “no” when asked “will AI replace '\n",
      " 'teachers?” ACE is not just about making teachers’ jobs easier but also '\n",
      " 'making it possible to do what most teachers want to do. That includes, for '\n",
      " 'example, understanding their students more deeply and having more time to '\n",
      " 'respond in creative ways to teachable moments.\\n'\n",
      " '\\n'\n",
      " 'To bring more precision to how and where we should center educators, we '\n",
      " 'return to our advocacy for human in the loop AI and ask, what are the loops '\n",
      " 'in which teachers should be centered? Figure 5 suggests three key loops '\n",
      " '(inspired by research on adaptivity loops):\\n'\n",
      " '\\n'\n",
      " '34 Aleven, V., McLaughlin, E.A., Glenn, R.A., & Koedinger, K.R. (2016). '\n",
      " 'Instruction based on adaptive learning technologies. In Mayer, R.E. & '\n",
      " 'Alexander, P.A., Handbook of research on learning and instruction, 522-560. '\n",
      " 'ISBN: 113883176X\\n'\n",
      " '---\\n'\n",
      " '## Insight: Using AI to Improve Teaching Jobs\\n'\n",
      " '\\n'\n",
      " 'The job of teaching is notoriously complex, with teachers making thousands '\n",
      " 'of decisions each day. Teachers participate in classroom processes, in '\n",
      " 'interactions with students beyond classrooms, in work with fellow teachers, '\n",
      " 'and in administrative functions. They also are part of their communities and '\n",
      " 'thus are expected to interact with families and caregivers.\\n'\n",
      " '\\n'\n",
      " 'Please note that in the next section, on Formative Assessment, we also '\n",
      " 'discuss teachers’ important role in feedback loops that support students and '\n",
      " 'enable school improvement. That section also includes a discussion of the '\n",
      " 'concepts of “bias” and “fairness,” which are important to teachers.\\n'\n",
      " '\\n'\n",
      " '### Figure 5: Three ways to center educators as we conceptualize human in '\n",
      " 'the loop AI\\n'\n",
      " '\\n'\n",
      " '|Doing|Teaching|Always|Preparing|\\n'\n",
      " '|---|---|---|---|\\n'\n",
      " '|Center|Educators|Focus|Teaching & Learning|\\n'\n",
      " '\\n'\n",
      " 'The loop in which teachers make moment-to-moment decisions as they do the '\n",
      " 'immediate work of teaching.\\n'\n",
      " '\\n'\n",
      " 'The loop in which teachers prepare for, plan, and reflect on teaching, which '\n",
      " 'includes professional development.\\n'\n",
      " '\\n'\n",
      " 'The loop in which teachers participate in decisions about the design of '\n",
      " 'AI-enabled technologies, participate in selecting the technologies, and '\n",
      " 'shape the evaluation of technologies—thus setting a context for not only '\n",
      " 'their own classroom but those of fellow teachers as well.\\n'\n",
      " '---\\n'\n",
      " 'If the teacher is able to efficiently predict and understand the range of '\n",
      " 'other answers given by students in the class, it becomes possible to think '\n",
      " 'creatively about the novel answer and figure how and why the student might '\n",
      " 'have generated it.35\\n'\n",
      " '\\n'\n",
      " 'We think about how much easier some everyday tasks have become. We can '\n",
      " 'request and receive alerts and notifications about events. Selecting music '\n",
      " 'that we want to hear used to be a multistep process (even with digital '\n",
      " 'music), and now we can speak the name of a song we want to hear, and it '\n",
      " 'plays. Likewise, mapping a journey used to require a cumbersome study of '\n",
      " 'maps, but now cell phones let us choose among several transportation options '\n",
      " 'to reach a destination. Why can’t teachers be supported to notice changing '\n",
      " 'student needs and provided with supports to enact a technology-rich lesson '\n",
      " 'plan? Why can’t they more easily plan their students’ learning journeys? '\n",
      " 'When things change in a classroom, as they always do, why don’t the tools of '\n",
      " 'the classroom make it easier for teachers to adapt to student strengths and '\n",
      " 'needs on the fly?\\n'\n",
      " '\\n'\n",
      " 'Figure 6: Teachers work about 50 hours a week, spending less than half the '\n",
      " 'time in direct interaction with students.\\n'\n",
      " '\\n'\n",
      " '|Activity composition of teacher working hours|Number of hours|\\n'\n",
      " '|---|---|\\n'\n",
      " '|Preparation|10.5|\\n'\n",
      " '|Evaluation and feedback|6.5|\\n'\n",
      " '|Professional development|3.0|\\n'\n",
      " '|Administration|5.0|\\n'\n",
      " '|Student instruction and engagement only|16.5|\\n'\n",
      " '|Student behavioral, social, and emotional-skill development|3.5|\\n'\n",
      " '|Student coaching and advisement|4.5|\\n'\n",
      " '\\n'\n",
      " 'Average for respondents: Canada, Singapore, United Kingdom, and United '\n",
      " 'States;\\n'\n",
      " 'Includes small \"other\" category\\n'\n",
      " 'Source: McKinsey Global Teacher and Student Survey\\n'\n",
      " '\\n'\n",
      " 'A report by McKinsey36 first suggested that AI’s initial benefit could be to '\n",
      " 'improve teaching jobs by reducing low-level burdens in administrative or '\n",
      " 'clerical work (Figure 6). The report also suggests that recovered time from '\n",
      " 'AI-enabled technology should be rededicated toward more\\n'\n",
      " '\\n'\n",
      " '35 Hammerness, K., Darling-Hammond, L., & Bransford, J. (2005). Preparing '\n",
      " 'teachers for a changing world: What teachers should learn and be able to do. '\n",
      " 'Jossey-Bass. ISBN: 0787996343\\n'\n",
      " '\\n'\n",
      " '36 Bryant, J., Heitz, C., Sanghvi, S., & Wagle, D. (2020, January 14). How '\n",
      " 'artificial intelligence will impact K-12 teachers. McKinsey. '\n",
      " 'https://www.mckinsey.com/industries/education/our-insights/how-artificial-intelligence-will-impact-k-12-teachers\\n'\n",
      " '---\\n'\n",
      " 'Effective instruction—particularly, outcomes such as reducing the average 11 '\n",
      " 'hours of weekly preparation down to only six. We highlight these '\n",
      " 'opportunities and two others below.\\n'\n",
      " '\\n'\n",
      " '|1.|Handling low-level details to ease teaching burdens and increase focus '\n",
      " 'on students. A good teacher must master all levels of details, big and '\n",
      " 'small. When working with a particular student, the teacher may wish to later '\n",
      " 'send that student a helpful learning resource. How will they remember to '\n",
      " 'send it? A voice assistant or other forms of an AI assistant could make it '\n",
      " 'easier to stay organized by categorizing simple voice notes for teachers to '\n",
      " 'follow up on after a classroom session ends. We are beginning to see '\n",
      " 'AI-enabled voice assistants in the market, and they could do many simple '\n",
      " 'tasks so that the teachers can stay focused on students. These tasks can '\n",
      " 'include record-keeping, starting and stopping activities, controlling '\n",
      " 'displays, speakers, and other technologies in the classroom, and providing '\n",
      " 'reminders. Many workers may eventually use assistants to make their jobs '\n",
      " 'easier, and teachers are the most deserving of efforts to ease their jobs '\n",
      " 'now.|\\n'\n",
      " '|---|---|\\n'\n",
      " \"|2.|Extending beyond the teacher's availability with their students but \"\n",
      " 'continuing to deliver on the teacher’s intent. Teachers almost always want '\n",
      " 'to do more with each student than they can, given the limited number of '\n",
      " 'hours before the next school day. A teacher may wish to sit with the student '\n",
      " 'as they practice 10 more math problems, giving them ongoing support and '\n",
      " 'feedback. If the teacher can sit with the student for only three problems, '\n",
      " 'perhaps they could delegate to an AI-enabled learning system to help with '\n",
      " 'the rest. Teachers cannot be at their best if on call at all hours to help '\n",
      " 'with homework, but perhaps they can indicate what types of supports, hints, '\n",
      " 'and feedback they want students to receive while studying after school '\n",
      " 'hours. An AI assistant can ensure that students have that support wherever '\n",
      " 'and whenever they do homework or practice skills on their own. Teachers may '\n",
      " 'wish to provide more extensive personal notes to families/caregivers, and '\n",
      " 'perhaps an AI assistant could help with drafts based on students’ recent '\n",
      " 'classroom work. Then, the teacher could review the AI-generated comments and '\n",
      " 'quickly edit where needed before returning it to the student for another '\n",
      " 'draft. AI tools might also help teachers with language translation so they '\n",
      " 'can work with all parents and caregivers of their students. AI tools might '\n",
      " 'also help teachers with awareness. For example, in the next section, '\n",
      " 'Formative Assessment, we note that teachers can’t always know what’s going '\n",
      " 'on for each student and in each small group of students; emerging products '\n",
      " 'might signal to the teacher when a student or teacher may need some more '\n",
      " 'personal attention.|\\n'\n",
      " '|3.|Making teacher professional development more productive and fruitful. '\n",
      " 'Emerging products already enable a teacher to record her classroom and allow '\n",
      " 'an AI algorithm to suggest highlights of the classroom discussion worth '\n",
      " 'reviewing with a professional development coach. AI can compute metrics, '\n",
      " 'such as whether students have been talking more or less, which are difficult '\n",
      " 'for a teacher to calculate during a lesson.|\\n'\n",
      " '\\n'\n",
      " '37 Chen, G., Clarke, S., & Resnick, L.B. (2015). Classroom Discourse '\n",
      " 'Analyzer (CDA): A discourse analytic tool for teachers. Technology, '\n",
      " 'Instruction, Cognition and Learning, 10(2), 85-105\\n'\n",
      " '\\n'\n",
      " '38 Jensen, E., Dale, M., Donnelly, P.J., Stone, C., Kelly, S., Godley, A. & '\n",
      " \"D'Mello, S.K. (2020). Toward automated feedback on teacher discourse to \"\n",
      " 'enhance teacher learning. In Proceedings of the 2020 CHI Conference on Human '\n",
      " \"Factors in Computing Systems (CHI '20). \"\n",
      " 'https://doi.org/10.1145/3313831.3376418\\n'\n",
      " '---\\n'\n",
      " 'Teachers who want to increase student engagement, these metrics can be a '\n",
      " 'valuable tool. Classroom simulation tools are also emerging and can enable '\n",
      " 'teachers to practice their skills in realistic situations. Simulators can '\n",
      " 'include examples of teaching from a real classroom while changing the faces '\n",
      " 'and voices of the participants so that teaching situations can be shared and '\n",
      " 'discussed among teachers without revealing identities.\\n'\n",
      " '\\n'\n",
      " 'Note the emphasis above on what listening-session panelist Sarah Hampton '\n",
      " 'said about the human touch. Teachers will feel that AI is helping them teach '\n",
      " 'with a focus on their human connection to their students when the necessary '\n",
      " '(but less meaningful) burdens of teaching are lessened. In Figure 7, below, '\n",
      " 'see concerns that teachers raised about AI during listening sessions.\\n'\n",
      " '\\n'\n",
      " 'Figure 7: Concerns raised during pe listening session about teaching wip AI\\n'\n",
      " 'Algoripmic transparency\\n'\n",
      " 'User control of data\\n'\n",
      " 'Engaging stakeholders who are diverse in all ways (race, sex, culture; '\n",
      " 'disability; and more)\\n'\n",
      " 'Evaluation for bias\\n'\n",
      " 'Diverse product development teams\\n'\n",
      " 'Defining what is meant by AI - such broad term\\n'\n",
      " '\\n'\n",
      " 'Preparing and Supporting Teachers in Planning and Reflecting Important Very '\n",
      " 'Important ACE also means preparing teachers to take advantage of '\n",
      " 'possibilities like those listed above and more. In the Research section, we '\n",
      " 'highlight how pre-service education still tends to compartmentalize and '\n",
      " 'inadequately address the topic of technology. That section suggests a need '\n",
      " 'to invest in research about how to deeply integrate technology in '\n",
      " 'pre-service teacher training programs. In-service teachers, too, will need '\n",
      " 'professional development to take advantage of opportunities that AI can '\n",
      " 'provide, like those presented in the Teaching section. Professional '\n",
      " 'development will need to be balanced not only to discuss opportunities but '\n",
      " 'also to inform teachers of new risks, while providing them with tools to '\n",
      " 'avoid the pitfalls of AI.\\n'\n",
      " '\\n'\n",
      " 'Ersozlu, Z., Ledger, S., Ersozlu, A., Mayne, F., & Wildy, H. (2021). '\n",
      " 'Mixed-reality learning environments in teacher education: An analysis of '\n",
      " 'TeachLivETM Research. SAGE Open, 11(3). '\n",
      " 'https://doi.org/10.1177/21582440211032155.\\n'\n",
      " '---\\n'\n",
      " '“Humans are well suited to discern the outcomes…because we are the ones that '\n",
      " 'have the capacity for moral reflection and empathy. So, in other words, I '\n",
      " 'want the AI to help me really quickly and easily see what my student needs '\n",
      " 'in their learning journey.” —Sarah Hampton\\n'\n",
      " '\\n'\n",
      " 'By nature, teaching requires significant time in planning as well to account '\n",
      " 'for the breadth of needs across their rosters—especially for inclusive '\n",
      " 'learning environments and students with IEPs and 504 plans. AI could help '\n",
      " 'teachers with recommendations that are tuned to their situation and their '\n",
      " 'ways of practicing teaching and support with adapting found materials to fit '\n",
      " 'their exact classroom needs. For students with an IEP, AI could help with '\n",
      " 'finding components to add to lesson plans to fully address standards and '\n",
      " 'expectations and to meet each student’s unique requirements. Even beyond '\n",
      " 'finding components, AI might help adapt standardized resources to better fit '\n",
      " 'specific needs—for example, providing a voice assistant that allows a '\n",
      " 'student with a visual difficulty to hear material and respond to it or '\n",
      " 'permitting a group of students to present their project using American Sign '\n",
      " 'Language (ASL) which could be audibly voiced for other students using an AI '\n",
      " 'ASL-to-Spoken-English translation capability. Indeed, coordinating IEPs is '\n",
      " 'time-consuming work that might benefit from supportive automation and '\n",
      " 'customized interactivity that can be provided by AI.\\n'\n",
      " '\\n'\n",
      " 'Reflection is important too. In the bustle of a classroom, it is sometimes '\n",
      " 'difficult to fully understand what a student is expressing or what '\n",
      " 'situations lead to certain positive or negative behaviors. Again, context is '\n",
      " 'paramount. In the moment, teachers may not be aware of external events that '\n",
      " 'could shape their understanding of how students are showing up in their '\n",
      " 'classrooms. Tools that notice patterns and suggest ways to share information '\n",
      " 'might help students and teachers communicate more fully about strengths and '\n",
      " 'needs.\\n'\n",
      " '\\n'\n",
      " 'Designing, Selecting, and Evaluating AI Tools\\n'\n",
      " '\\n'\n",
      " 'The broadest loop teachers should be part of is the loop that determines '\n",
      " 'what classroom tools do and which tools are available. Today, teachers '\n",
      " 'already play a role in designing and selecting technologies. Teachers can '\n",
      " 'weigh in on usability and feasibility. Teachers examine evidence of efficacy '\n",
      " 'and share their findings with other school leaders. Teachers already share '\n",
      " 'insights on what is needed to implement technology well.\\n'\n",
      " '\\n'\n",
      " 'While these concerns will continue, AI will raise new concerns too. For '\n",
      " 'example, the following Formative Assessment section raises concerns about '\n",
      " 'bias and fairness that can lead to algorithmic discrimination. Those '\n",
      " 'concerns go beyond data privacy and security; they raise attention to how '\n",
      " 'technologies may unfairly direct or limit some students’ opportunities to '\n",
      " 'learn. A key takeaway here is that teachers will need time and support so '\n",
      " 'they can stay abreast of both the well-known and the newer issues that are '\n",
      " 'arising and so they can fully participate in design, selection, and '\n",
      " 'evaluation processes that mitigate risks.\\n'\n",
      " '\\n'\n",
      " 'Challenge: Balancing Human and Computer Decision-Making\\n'\n",
      " '\\n'\n",
      " 'One major new challenge with AI-enabled tools for teachers is that AI can '\n",
      " 'enable autonomous activity by a computer, and thus when a teacher delegates '\n",
      " 'work to an AI-enabled tool, it may\\n'\n",
      " '---\\n'\n",
      " 'carry on with that work somewhat independently. Professor Inge Molenaar40 '\n",
      " 'has wondered about the challenges of control in a hybrid teaching scenario: '\n",
      " 'When should a teacher be in control? What can be delegated to a '\n",
      " 'computational system? How can a teacher monitor the AI system and override '\n",
      " 'its decisions or take back control as necessary?\\n'\n",
      " '\\n'\n",
      " '|Figure 8: The tension between human and AI decision making: Who is in '\n",
      " 'control?|\\n'\n",
      " '|---|\\n'\n",
      " '|Teacher in Control|Technology In Control|\\n'\n",
      " '\\n'\n",
      " 'Figure 8 expresses the tension around control. To the left, the teacher is '\n",
      " 'fully in control, and there is no use of AI in the classroom. To the right, '\n",
      " 'the technology is fully in control with no teacher involved—a scenario which '\n",
      " 'is rarely desirable. The middle ground is not one dimensional and involves '\n",
      " 'many choices. Molenaar analyzed products and suggests some possibilities:\\n'\n",
      " '\\n'\n",
      " '- The technology only offers information and recommendations to the '\n",
      " 'teacher.\\n'\n",
      " '- The teacher delegates specific types of tasks to the technology, for '\n",
      " 'example, giving feedback on a particular math assignment or sending out '\n",
      " 'reminders to students before an assignment is due.\\n'\n",
      " '- The teacher delegates more broadly to the technology, with clear protocols '\n",
      " 'for alerts, for monitoring, and for when the teacher takes back control.\\n'\n",
      " '\\n'\n",
      " 'These and other choices need to be debated openly. For example, we may want '\n",
      " 'to define instructional decisions that have different kinds of consequences '\n",
      " 'for a student and be very careful about delegating control over highly '\n",
      " 'consequential decisions (for example, placement in a next course of study or '\n",
      " 'disciplinary referrals). For human in the loop to become more fully '\n",
      " 'realized, AI technologies must allow teacher monitoring, have protocols to '\n",
      " 'signal a teacher when their judgment is needed, and allow for classroom, '\n",
      " 'school, or district overrides when they disagree with an instructional '\n",
      " 'choice for their students. We cannot forget that if a technology allows a '\n",
      " 'teacher choice—which it should—it will take significant time for a teacher '\n",
      " 'to think through and set up all the options, requiring greater time '\n",
      " 'initially.\\n'\n",
      " '\\n'\n",
      " 'Challenge: Making Teaching Jobs Easier While Avoiding Surveillance\\n'\n",
      " '\\n'\n",
      " 'We also recognize that the very technologies that make jobs easier might '\n",
      " 'also introduce new possibilities for surveillance (Figure 9). In a familiar '\n",
      " 'example, when we enable a voice assistant in the kitchen, it might help us '\n",
      " 'with simple household tasks like setting a cooking timer. And yet the same '\n",
      " 'voice assistant might hear things that we intended to be private. This kind '\n",
      " 'of dilemma will\\n'\n",
      " '\\n'\n",
      " '40 Molenaar, I. (2022). Towards hybrid human-AI learning technologies. '\n",
      " 'European Journal of Education, 00, 1–14. https://doi.org/10.1111/ejed.12527\\n'\n",
      " '---\\n'\n",
      " 'occur in classrooms and for teachers. When they enable an AI-assistant to '\n",
      " 'capture data about what they say, what teaching resources they search for, '\n",
      " 'or other behaviors, the data could be used to personalize resources and '\n",
      " 'recommendations for the teacher. Yet the same data might also be used to '\n",
      " 'monitor the teacher, and that monitoring might have consequences for the '\n",
      " 'teacher. Achieving trustworthy AI that makes teachers’ jobs better will be '\n",
      " 'nearly impossible if teachers experience increased surveillance.\\n'\n",
      " '\\n'\n",
      " 'A related tension is that asking teachers to be “in the loop” could create '\n",
      " 'more work for teachers if not done well, and thus, being in the loop might '\n",
      " 'be in tension with making teaching jobs easier. Also related is the tension '\n",
      " 'between not trusting AI enough (to obtain assistance) or trusting it too '\n",
      " 'much (and incurring surveillance or loss of privacy). For example, '\n",
      " 'researchers have documented that people will follow instructions from a '\n",
      " 'robot during a simulated fire emergency even when (a) they are told the '\n",
      " 'robot is broken and (b) the advice is obviously wrong. We anticipate '\n",
      " 'teachers will need training and support to understand how and when they will '\n",
      " 'need to exercise human judgement.\\n'\n",
      " '\\n'\n",
      " '|Figure 9: Highly customized assistance vs. increased teacher surveillance|\\n'\n",
      " '|---|\\n'\n",
      " '|Highly customized assistance|Increased teacher surveillance|\\n'\n",
      " '\\n'\n",
      " 'Challenge: Responding to Students’ Strengths While Protecting Their Privacy '\n",
      " 'Educators seek to tackle inequities in learning, no matter how they manifest '\n",
      " 'locally (e.g. in access to educational opportunities, resources, or '\n",
      " 'supports). In culturally responsive and culturally sustaining approaches, '\n",
      " 'educators design materials to build on the “assets”—individual, community, '\n",
      " 'and cultural strengths that students bring to learning. Along with '\n",
      " 'considering assets, of course, educators must meet students where they are, '\n",
      " 'including both strengths and needs. AI could assist in this process by '\n",
      " 'helping teachers with customizing curricular resources, for example. But to '\n",
      " 'do so, the data inputted in an AI-enabled system would have to provide more '\n",
      " 'information about the students. This information could be, but need not be, '\n",
      " 'demographic details. It could also be information about students’ '\n",
      " 'preferences, outside interests, relationships.\\n'\n",
      " '\\n'\n",
      " '41 Wagner, A.R., Borenstein, J. & Howard, A. (September 2018). Overtrust in '\n",
      " 'the robotics age. Communications of the ACM, 61(9),22-24. '\n",
      " 'https://doi.org/10.1145/3241365\\n'\n",
      " '\\n'\n",
      " 'Gay, G. (2018). Culturally responsive teaching: Theory, research, and '\n",
      " 'practice. Teachers College Press. ISBN: 978-0807758762\\n'\n",
      " '\\n'\n",
      " 'Paris, D., & Alim, H.S. (Eds.). (2017). Culturally sustaining pedagogies: '\n",
      " 'Teaching and learning for justice in a changing world. Teachers College '\n",
      " 'Press. ISBN: 978-0807758342\\n'\n",
      " '---\\n'\n",
      " 'or experiences. What happens to this data, how it is deleted, and who sees '\n",
      " 'it is of huge concern to educators. As educators contemplate using '\n",
      " 'AI-enabled technologies to assist in tackling educational inequities, they '\n",
      " 'must consider whether the information about students shared with or stored '\n",
      " 'in an AI-enabled system is subject to federal or state privacy laws, such as '\n",
      " 'FERPA. Further, educators must consider whether interactions between '\n",
      " 'students and AI systems create records that must be protected by law, such '\n",
      " 'as when a chatbot or automated tutor generates conversational or written '\n",
      " 'guidance to a student. Decisions made by AI technologies, along with '\n",
      " 'explanations of those decisions that are generated by algorithms may also be '\n",
      " 'records that must be protected by law. Therein, a third tension emerges, '\n",
      " 'between more fully representing students and protecting their privacy.\\n'\n",
      " '\\n'\n",
      " 'Further, representation would be just a start toward a solution. As '\n",
      " 'discussed earlier in this report, AI can introduce algorithmic '\n",
      " 'discrimination through bias in the data, code, or models within AI-enhanced '\n",
      " 'edtech. Engineers develop the pattern detection in AI models using existing '\n",
      " 'data, and the data they use may not be representative or may contain '\n",
      " 'associations that run counter to policy goals. Further, engineers shape the '\n",
      " 'automations that AI implements when it recognizes patterns, and the '\n",
      " 'automations may not meet the needs of each student group with a diverse '\n",
      " 'population. The developers of AI are typically less diverse than the '\n",
      " 'populations they serve, and as a consequence, they may not anticipate the '\n",
      " 'ways in which pattern detection and automation may harm a community, group, '\n",
      " 'or individual.\\n'\n",
      " '\\n'\n",
      " 'AI could help teachers to customize and personalize materials for their '\n",
      " 'students, leveraging the teacher’s understanding of student needs and '\n",
      " 'strengths. It is time-consuming to customize curricular resources, and '\n",
      " 'teachers are already exploring how AI chatbots can help them design '\n",
      " 'additional resources for their students. An elementary school teacher could '\n",
      " 'gain powerful supports for changing the visuals in a storybook to engage '\n",
      " 'their students or for adapting language that poorly fits local manners of '\n",
      " 'speaking or even for modifying plots to incorporate other dimensions of a '\n",
      " 'teacher’s lesson. In the Learning section, we noted that AI could help '\n",
      " 'identify learner strengths. For example, a mathematics teacher may not be '\n",
      " 'aware of ways in which a student is making great sense of graphs and tables '\n",
      " 'about motions when they are in another teacher’s physics classroom and might '\n",
      " 'not realize that using similar graphs about\\n'\n",
      " '\\n'\n",
      " 'Zacamy, J. & Roschelle, J. (2022). Navigating the tensions: How could '\n",
      " 'equity-relevant research also be agile, open, and scalable? Digital Promise. '\n",
      " 'http://hdl.handle.net/20.500.12265/159; Baker, R.S., Esbenshade, L., Vitale, '\n",
      " 'J., & Karumbaiah, S. (2022). Using demographic data as predictor variables: '\n",
      " 'A questionable choice. https://doi.org/10.35542/osf.io/y4wvj\\n'\n",
      " '---\\n'\n",
      " 'motion could help with their linear function lesson. AI might help teachers '\n",
      " 'when they seek to reflect student strengths by creating or adapting '\n",
      " 'instructional resources. Yet, the broad equity challenges of avoiding '\n",
      " 'algorithmic discrimination while increasing community and cultural '\n",
      " 'responsiveness must be approached within the four foundations we earlier '\n",
      " 'outlined: human in the loop, equity, safety and effectiveness, and '\n",
      " 'evaluation of AI models. We cannot expect AI models to respect cultural '\n",
      " 'responsiveness. The Department is particularly concerned that equity is '\n",
      " 'something that engaged educators and other responsive adults are in the best '\n",
      " 'position to address and something that is never solely addressable as a '\n",
      " 'computational problem.\\n'\n",
      " '\\n'\n",
      " 'Questions Worth Asking About AI for Teaching\\n'\n",
      " '\\n'\n",
      " '- Is AI improving the quality of an educator’s day-to-day work? Are teachers '\n",
      " 'experiencing less burden and more ability to focus and effectively teach '\n",
      " 'their students?\\n'\n",
      " '- As AI reduces one type of teaching burden, are we preventing new '\n",
      " 'responsibilities or additional workloads being shifted and assigned to '\n",
      " 'teachers in a manner that negates the potential benefits of AI?\\n'\n",
      " '- Is classroom AI use providing teachers with more detailed insights into '\n",
      " 'their students and their strengths while protecting their privacy?\\n'\n",
      " '- Do teachers have oversight of AI systems used with their learners? Are '\n",
      " 'they exercising control in the use of AI-enabled tools and systems '\n",
      " 'appropriately or inappropriately yielding decision-making to these systems '\n",
      " 'and tools?\\n'\n",
      " '- When AI systems are being used to support teachers or to enhance '\n",
      " 'instruction, are the protections against surveillance adequate?\\n'\n",
      " '- To what extent are teachers able to exercise voice and decision-making to '\n",
      " 'improve equity, reduce bias, and increase cultural responsiveness in the use '\n",
      " 'of AI-enabled tools and systems?\\n'\n",
      " '\\n'\n",
      " 'Key Recommendation: Inspectable, Explainable, Overridable AI\\n'\n",
      " '\\n'\n",
      " 'In the Introduction, we discuss the notion that when AI is incorporated into '\n",
      " 'a system, the core of the AI is a model. In the Learning section, we discuss '\n",
      " 'that we need to be careful that models align to the learning we envision '\n",
      " '(e.g., that they aren’t too narrow). Now, based on the needs of teachers (as '\n",
      " 'well as students and their families/caregivers), we add another layer to our '\n",
      " 'criteria for good AI models: the need for explainability. Some AI models can '\n",
      " 'recognize patterns in the world and do the right action, but they cannot '\n",
      " 'explain why (e.g., how they arrived at the).\\n'\n",
      " '\\n'\n",
      " 'Reference: Khosravi, H., Shum, S.B., Chen, G, Conati, C., Tsai,Y-S., Kay, '\n",
      " 'J., Knight, S., Martinez-Maldonado, R., Sadiq, S., Gašević, D. (2022). '\n",
      " 'Explainable artificial intelligence in education. Computers and Education: '\n",
      " 'Artificial Intelligence, 3. https://doi.org/10.1016/j.caeai.2022.100074\\n'\n",
      " '---\\n'\n",
      " 'Connection between the pattern and the action). This lack of explainability '\n",
      " 'will not suffice for teaching; teachers will need to know how an AI model '\n",
      " 'analyzed the work of one of their students and why the AI model recommended '\n",
      " 'a particular tutorial, resource, or next step to the student. Thus, '\n",
      " 'explainability of an AI system’s decision is key to a teacher’s ability to '\n",
      " 'judge that automated decision. Such explainability helps teachers to develop '\n",
      " 'appropriate levels of trust and distrust in AI, particularly to know where '\n",
      " 'the AI model tends to make poor decisions. Explainability is also key to a '\n",
      " 'teacher’s ability to monitor when an AI system may be unfairly acting on the '\n",
      " 'wrong information (and thus may be biased. We discuss bias and fairness more '\n",
      " 'in the Assessment section next). Surrounding the idea of explainability is '\n",
      " 'the need for teachers to be able to inspect what an AI model is doing. For '\n",
      " 'example, what kinds of instructional recommendations are being made and to '\n",
      " 'which students? Which students are being assigned remedial work in a never '\n",
      " 'ended loop? Which are making progress? Dashboards in current products '\n",
      " 'present some of this information, but with AI, teachers may want to further '\n",
      " 'explore which decisions are being made and for whom and know of the '\n",
      " 'student-specific factors that an AI model had available (and possibly which '\n",
      " 'factors were influential) when reaching a particular decision. For example, '\n",
      " 'some of today’s adaptive classroom products use limited recommendation '\n",
      " 'models that only consider student success on the last three mathematics '\n",
      " 'problems and do not consider other variables that a teacher would know to '\n",
      " 'consider, such as whether a student has an IEP Plan or other needs. Our call '\n",
      " 'for attending to equity considerations as we evaluate AI models requires '\n",
      " 'information about how discriminatory bias may arise in particular AI systems '\n",
      " 'and what developers have done to address it. This can only be achieved with '\n",
      " 'transparency for how the tools use datasets to achieve outcomes and what '\n",
      " 'data they have available or that a teacher could include in her judgement '\n",
      " 'but are not available to the system (IEP status is offered as an example '\n",
      " 'above). Teachers will also need the ability to view and make their own '\n",
      " 'judgement about automated decisions, such as decisions about which set of '\n",
      " 'mathematics problems a student should work on next. They need to be able to '\n",
      " 'intervene and override decisions when they disagree with the logic behind an '\n",
      " 'instructional recommendation. Teachers need protection against adverse '\n",
      " 'ramifications when they assert human judgement over an AI system’s '\n",
      " 'decision.\\n'\n",
      " '\\n'\n",
      " 'Ruiz, P. & Fusco, J. (2022). Teachers partnering with artificial '\n",
      " 'intelligence: Augmentation and automation. Digital Promise. '\n",
      " 'https://digitalpromise.org/2022/07/06/teachers-partnering-with-artificial-intelligence-augmentation-and-automation/ '\n",
      " '35\\n'\n",
      " '---\\n'\n",
      " '“These systems sometimes are seen as a black box kind of a situation where '\n",
      " 'predictions are made based on lots of data. But what we need is to have a '\n",
      " 'clear view—to clearly show how those recommendations or those interactions '\n",
      " 'are made and what evidence is used or what data is used to be able to make '\n",
      " 'those recommendations so teachers and everyone involved know about why that '\n",
      " 'kind of system is providing that type of information. So, having open '\n",
      " 'learning environments or inspectable learner models or applications where '\n",
      " 'the stakeholders can understand how these systems make decisions or '\n",
      " 'recommendations is going to be an important aspect in the future of teaching '\n",
      " 'and learning.”\\n'\n",
      " '\\n'\n",
      " '—Diego Zapata-Rivera\\n'\n",
      " '\\n'\n",
      " '36\\n'\n",
      " '---\\n'\n",
      " '## Formative Assessment\\n'\n",
      " '\\n'\n",
      " 'Formative assessment is traditionally a key use of edtech because feedback '\n",
      " 'loops are vital to improving teaching and learning. As we have emphasized '\n",
      " 'throughout this report, a top priority with AI is to keep humans in the loop '\n",
      " 'and in control, which includes focusing on the people engaged with formative '\n",
      " 'assessments: students, teachers, school leaders, families/caregivers, and '\n",
      " 'others who support learners. In the definition below, please note the '\n",
      " 'overlap between definitions of AI and formative assessment; both have to do '\n",
      " 'with detecting patterns and choosing a future course of action (that adapts '\n",
      " 'to learner strengths and needs).\\n'\n",
      " '\\n'\n",
      " 'Assessment refers to all those activities undertaken by teachers, and by the '\n",
      " 'students in assessing themselves, which provide information to be used as '\n",
      " 'feedback to modify the teaching and learning activities in which they are '\n",
      " 'engaged. Such assessment becomes “formative assessment” when the evidence is '\n",
      " 'actually used to adapt the teaching to meet the needs.\\n'\n",
      " '\\n'\n",
      " '## Building on Best Practices\\n'\n",
      " '\\n'\n",
      " 'A number of dimensions hold potential for shaping the future of formative '\n",
      " 'assessments, and many have ready extensions to the field of AI-enabled '\n",
      " 'systems and tools. For example, the 2017 NETP discussed how technology can '\n",
      " 'lead to improved formative assessments along seven dimensions, listed '\n",
      " 'below:\\n'\n",
      " '\\n'\n",
      " '|1. Enabling Enhanced Question Types:|to give students more ways to show '\n",
      " 'what they know and can do.|\\n'\n",
      " '|---|---|\\n'\n",
      " '|2. Measurement of Complex Competencies:|to better elicit growth in '\n",
      " 'important skills that go beyond typical subject matter standards, for '\n",
      " 'example, in measuring practices, social skills like teamwork, '\n",
      " 'self-regulation, and work-relevant skills (e.g., making presentations or '\n",
      " 'leading teams).|\\n'\n",
      " '|3. Providing Real-Time Feedback:|to maintain and increase student '\n",
      " 'engagement and to support effective learning, providing timely and helpful '\n",
      " 'responses and suggestions to each learner.|\\n'\n",
      " '|4. Increasing Accessibility:|to include neurodiverse learners and to engage '\n",
      " 'learners’ best communication capabilities as they share what they know and '\n",
      " 'can do.|\\n'\n",
      " '\\n'\n",
      " 'References:\\n'\n",
      " '\\n'\n",
      " '47. Shute, V.J. (2008). Focus on formative feedback. Review of Educational '\n",
      " 'Research, 78(1), 153–189. Link\\n'\n",
      " '\\n'\n",
      " '48. Black, P. & Wiliam, D. (1998). Inside the black box: Raising standards '\n",
      " 'through classroom assessment. Phi Delta Kappan, 92(1), 81-90. Link\\n'\n",
      " '---\\n'\n",
      " '##### Adapting to Learner Ability and Knowledge:\\n'\n",
      " '\\n'\n",
      " 'to make assessments more precise and efficient.\\n'\n",
      " '\\n'\n",
      " '##### Embedded Assessment in the Learning Process:\\n'\n",
      " '\\n'\n",
      " 'to emphasize an assessment’s role in improving teaching and learning (this '\n",
      " 'report does not focus on assessment for accountability purposes).\\n'\n",
      " '\\n'\n",
      " '##### Assess for Ongoing Learning:\\n'\n",
      " '\\n'\n",
      " 'to reveal progress over time and not just predetermined milestones.\\n'\n",
      " '\\n'\n",
      " 'AI models and AI-enabled systems may have potential to strengthen formative '\n",
      " 'assessments. In one example, a question type that invites students to draw a '\n",
      " 'graph or create a model can be analyzed with AI algorithms, and similar '\n",
      " 'student models might be grouped for the teacher to interpret. Enhanced '\n",
      " 'formative assessment may enable teachers to better respond to students’ '\n",
      " 'understanding of a concept like “rate of change” in a complex, real-world '\n",
      " 'situation. AI can also give learners feedback on complex skills, such as '\n",
      " 'learning American Sign Language or speaking a foreign language and in other '\n",
      " 'practice situations where no person is available to provide immediate '\n",
      " 'feedback.\\n'\n",
      " '\\n'\n",
      " 'Generally, an AI assistant may be able to reduce the load for teachers '\n",
      " 'related to grading simpler aspects of student responses, allowing the '\n",
      " 'teacher to focus their specialized judgment on important qualities of a '\n",
      " 'whole essay or a complex project. We also may be able to better provide '\n",
      " 'feedback with accessibility. For example, an AI-enabled learning technology '\n",
      " 'may be able to interact verbally with a student about their response to an '\n",
      " 'essay prompt, asking questions that guide the student to clarify their '\n",
      " 'argument without requiring the student to read a screen or type at a '\n",
      " 'keyboard. In the examples shared earlier in the Learning section, we also '\n",
      " 'see that AI can be embedded in the learning process, providing feedback to '\n",
      " 'students as they work to solve a problem, rather than only later after the '\n",
      " 'student has reached a wrong answer. When formative assessment is more '\n",
      " 'embedded, it can better support learning, and timely feedback is critical.\\n'\n",
      " '\\n'\n",
      " 'Although there are many points of connection like these between AI and '\n",
      " 'formative assessments, our listening sessions also revealed attendees’ '\n",
      " 'desire to tackle some existing shortcomings in the field of formative '\n",
      " 'assessment; namely, the time-consuming and sometime onerous nature of taking '\n",
      " 'tests, quizzes, or other assessments and the lack of perceived value in the '\n",
      " 'feedback loop by teachers and students.\\n'\n",
      " '\\n'\n",
      " '#### Implications for Teaching and Learning\\n'\n",
      " '\\n'\n",
      " 'Real-time instructional feedback can be beneficial when it helps learners '\n",
      " 'and teachers to improve. But common experience too often leaves students and '\n",
      " 'teachers with unpleasant feelings toward assessment and thus poses a '\n",
      " 'provocative conflict between the potential benefits\\n'\n",
      " '\\n'\n",
      " 'References:\\n'\n",
      " '\\n'\n",
      " '49 Zhai, X., He, P., Krajcik, J. (2022). Applying machine learning to '\n",
      " 'automatically assess scientific models. Journal of Research in Science '\n",
      " 'Teaching. https://doi.org/10.1002/tea.21773\\n'\n",
      " '50 Shao, Q., Sniffen, A., Blanchet, J., Hillis, M.E., Shi, X., Haris, T.K., '\n",
      " '& Balkcom, D. (2020). Teaching american sign language in mixed reality. '\n",
      " 'Proceedings of pe ACM on Interactive, Mobile, Wearable and Ubiquitous '\n",
      " 'Technologies, 4(4), 1-27. https://doi.org/10.1145/3432211\\n'\n",
      " '51 Godwin-Jones, R. (2021). Big data and language learning: Opportunities '\n",
      " 'and challenges. Language Learning & Technology, 25(1), 4–19. '\n",
      " 'http://hdl.handle.net/10125/44747\\n'\n",
      " '52 Wiggins, G. (2015). Seven keys to effective feedback. ACSD. '\n",
      " 'https://www.ascd.org/el/articles/seven-keys-to-effective-feedback\\n'\n",
      " '---\\n'\n",
      " 'of data collected through formative assessments and the practical '\n",
      " 'implications of administering additional assessments in classrooms and '\n",
      " 'schools. Some AI-enabled systems and tools seek to address this potential '\n",
      " 'conflict. For example, one AI-enabled reading tutor listens to students as '\n",
      " 'they read aloud and provides on-the-spot feedback to improve their reading. '\n",
      " 'Students reportedly enjoyed reading aloud, and the approach was effective. '\n",
      " 'Researchers have also embedded formative assessments in games so that '\n",
      " 'students can show how well they understand Newtonian physics as they play '\n",
      " 'increasingly difficult levels of a game. If a student can more easily ask '\n",
      " 'for and receive help when they feel frustrated or confused, reducing those '\n",
      " 'feelings can feel encouraging. Student feelings of safety, confidence, and '\n",
      " 'trust in the feedback generated by these AI-enabled systems and tools are '\n",
      " 'essential to showcase their learning. That focus on learning growth and '\n",
      " 'gains is optimal (absent negative consequences or a high-stakes '\n",
      " 'environment).\\n'\n",
      " '\\n'\n",
      " 'AI-enhanced formative assessments may have the potential to save teachers’ '\n",
      " 'time (e.g., time spent on grading), allowing the instructor to spend more '\n",
      " 'time engaged in helping students. AI-enhanced assessments may also benefit '\n",
      " 'teachers if they provide detailed insights about student strengths or needs '\n",
      " 'that may not be visible and if they support instructional adaptation or '\n",
      " 'improvement by suggesting a small set of evidence-based recommendations for '\n",
      " 'helping students master content. Such assessments may also be helpful '\n",
      " 'outside of the classroom if it can provide feedback when the teacher is not '\n",
      " 'available, for example, in completing homework or practicing a concept '\n",
      " 'during study hall. As we discussed in the Teaching section, an essential '\n",
      " 'aspect of deploying AI-based formative assessment must be centering teachers '\n",
      " 'in system design.\\n'\n",
      " '\\n'\n",
      " 'Insight: AI Can Enhance Feedback Loops The term “formative assessment” does '\n",
      " 'not singularly mean a test or a measurement. Assessment becomes formative '\n",
      " 'when it results in useful reflections and changes to the course of teaching, '\n",
      " 'learning, or both. The term “feedback loops” emphasizes that measurement is '\n",
      " 'only part of the process. Feedback loops that lead to instructional '\n",
      " 'improvement—including adaptations in teaching and learning—yield the '\n",
      " 'strongest outcomes for students. We also use “feedback loops” as a plural '\n",
      " 'term because there are many types and levels of loops that are important. '\n",
      " 'Students can benefit from feedback when they work individually, as a member '\n",
      " 'of a small group, or in a classroom discussion. Feedback loops are valuable '\n",
      " '“in the moment”—for example, as a student practices a skill. Further, '\n",
      " 'feedback loops are valuable when they cover larger spans of effort and '\n",
      " 'reflections, such as at the end of presenting a project or term paper. In '\n",
      " 'addition, feedback loops can assist teachers, for example, helping them '\n",
      " 'notice\\n'\n",
      " '\\n'\n",
      " 'Mostow, J., Aist, G., Burkhead, P., Corbett, A., Cuneo, A., Eitelman, S., '\n",
      " 'Huang, C., Junker, B., Sklar, M.B., & Tobin, B. (2003). Evaluation of an '\n",
      " 'automated reading tutor that listens: Comparison to human tutoring and '\n",
      " 'classroom instruction. Journal of Educational Computing Research, 29(1), '\n",
      " '61–117. Shute, V.J., Ventura, M., & Kim, Y.J. (2013). Assessment and '\n",
      " \"learning of qualitative physics in Newton's Playground. The Journal of \"\n",
      " 'Educational Research, 106(6), 423–430. Shute, V J. (2008). Focus on '\n",
      " 'formative feedback. Review of Educational Research, 78(1), 153–189. Black, '\n",
      " 'P., & Wiliam, D. (2009). Developing the theory of formative assessment. '\n",
      " 'Educational Assessment, Evaluation and Accountability, 21(1), 5-31.\\n'\n",
      " '---\\n'\n",
      " 'their own patterns of responding to students’ ideas. Moreover, feedback '\n",
      " 'loops are critical to the continuous improvement of products and the '\n",
      " 'implementation of programs. Due to the importance of feedback loops, '\n",
      " 'formative assessment could be a leading area for schools’ explorations of '\n",
      " 'powerful uses of AI in teaching and learning. Educators can build upon '\n",
      " 'alignments between their long-standing visions for formative assessment and '\n",
      " 'the emerging capabilities that AI holds. Further, the professional '\n",
      " 'assessment community brings a toolkit for asking and answering questions '\n",
      " 'about topics like bias and fairness. The psychometric toolkit of methods is '\n",
      " 'a strong start toward the questions that must be asked and answered because '\n",
      " 'it already contains ways to measure bias and fairness and, more generally, '\n",
      " 'to benchmark the quality of formative assessments. But as our discussion '\n",
      " 'reveals, AI can only make feedback loops better if we keep a firm eye on the '\n",
      " 'weaknesses of AI and how AI introduces new concerns.\\n'\n",
      " '\\n'\n",
      " 'An Example: Automated Essay Scoring\\n'\n",
      " '\\n'\n",
      " 'One instructive example is Automated Essay Scoring (AES). To become strong '\n",
      " 'writers, which is a valuable life skill, students need regular and specific '\n",
      " 'feedback. However, reviewing and providing feedback on essays is very time '\n",
      " 'consuming for humans. Hence, Ellis Page provided a first vision for computer '\n",
      " 'programs that could review and provide feedback on student essays in 196657, '\n",
      " 'and much effort has gone into AES technologies in the intervening 56 years. '\n",
      " 'Many research review articles are available to summarize the progress, which '\n",
      " 'has been impressive. Further, some of today’s applications of AES '\n",
      " 'technologies will be familiar to readers, such as Grammarly, Turnitin, and '\n",
      " 'the various essay analysis engines used by publishers and assessment '\n",
      " 'companies. Also note that while the traditional AES functionality emphasizes '\n",
      " 'scoring or rating essays, newer AI-enabled products focus more on providing '\n",
      " 'students with constructive criticism and developing their skills as writers. '\n",
      " 'Writing is a life skill that is important to the pursuit of college and '\n",
      " 'career ambitions, and developing writers require comprehensive feedback. If '\n",
      " 'developers could inexpensively augment human feedback to developing writers '\n",
      " 'with AI feedback, it’s possible that support for learning to write could '\n",
      " 'become more equitable.\\n'\n",
      " '\\n'\n",
      " 'And yet, AES is an instructive example because researchers have analyzed '\n",
      " 'limitations, too. AES technologies in AI can analyze some features of '\n",
      " 'student essays but can also be misled by the length of an essay, by a '\n",
      " 'student who places appropriate keywords in sentences that don’t make sense, '\n",
      " 'and other flaws that a human reader would easily notice. In a telling quote, '\n",
      " 'one team that reviewed the state of the art wrote this:\\n'\n",
      " '\\n'\n",
      " 'The authors further note that while human and AI judgements of essays may '\n",
      " 'correlate, people and computers are not noticing the same things in student '\n",
      " 'writing. Due to these limitations, we must continue to emphasize a human in '\n",
      " 'the loop foundation for AI-enhanced formative assessment. AI may support but '\n",
      " 'not replace high-quality, human-led processes and practices of formative '\n",
      " 'assessment in schools.\\n'\n",
      " '\\n'\n",
      " 'References:\\n'\n",
      " '\\n'\n",
      " 'Page, E.B. (1966). The imminence of grading essays by computer. Phi Delta '\n",
      " 'Kappan, 47(5), 238–243\\n'\n",
      " 'Ke, Z., & Ng, V. (2019). Automated essay scoring: A survey of pe state of pe '\n",
      " 'art. In Proceedings of pe Twenty-Eighp International Joint Conference on '\n",
      " 'Artificial Intelligence, 6300–6308. Link\\n'\n",
      " 'Doewes, A. & Pechenizkiy, M. (2021). On pe limitations of human-computer '\n",
      " 'agreement in automated essay scoring. In Proceedings of pe 14p International '\n",
      " 'Conference on Educational Data Mining (EDM21). Link\\n'\n",
      " '---\\n'\n",
      " '“Nevertheless, the time when AES systems will be able to operate on a par '\n",
      " 'with human judges, with similar levels of connoisseurship for such features '\n",
      " 'as meaning, emotion, originality, creativity, fluency, sense of audience and '\n",
      " 'so on, arguably remains a long way off.” —Gardner, O’Leary, and Yuan\\n'\n",
      " '\\n'\n",
      " 'Key Opportunities for AI in Formative Assessment Based on the listening '\n",
      " 'sessions we held, we see three key areas of opportunity in supporting '\n",
      " 'formative assessment using AI systems and models. First, we recommend a '\n",
      " 'strong focus on measuring what matters and particularly those things that '\n",
      " 'have not been easily measured before and that many constituents would like '\n",
      " 'to include in feedback loops. The example above, AES, was chosen because '\n",
      " 'writing remains a valuable academic, workplace, and life skill. Looking at '\n",
      " 'community goals through the lens of their visions for their high school '\n",
      " 'graduates, we see that families/caregivers, students, and community leaders '\n",
      " 'want to nurture graduates who solve problems adaptively, who communicate and '\n",
      " 'collaborate well, who persevere and self-regulate when they experience '\n",
      " 'challenges. “What matters” today reaches beyond a sole focus on the core '\n",
      " 'academic content measured by large-scale summative assessments, to support '\n",
      " 'students and teachers with actionable feedback that nurtures the broader '\n",
      " 'skills students need to succeed and thrive. Further, within core academic '\n",
      " 'content, AI may help us to provide feedback on the more realistic and '\n",
      " 'complex aspects of doing math, for example, or investigating scientific '\n",
      " 'phenomena, understanding history, or discussing literature.\\n'\n",
      " '\\n'\n",
      " 'Second, we’d like to see a strong focus on improving help-seeking and '\n",
      " 'help-giving. Asking for and giving help is crucial to learning and '\n",
      " 'practicing a growth-mindset and central to the notion of human feedback '\n",
      " 'loops. Students may not always know when they need help. In one example, '\n",
      " 'computer algorithms can detect a student who is “wheel spinning” (working '\n",
      " 'hard on mastering content but not making progress). A student who is working '\n",
      " 'hard may not feel like they need help, and the teacher may not be aware that '\n",
      " 'the student is struggling if he or she appears to be “on task.” AI may also '\n",
      " 'be helpful by highlighting for students and teachers what forms of '\n",
      " 'assistance have been most useful to the student in the recent past so that '\n",
      " 'an educator can expand access to specific assistance that works for that '\n",
      " 'individual student. Finally, educators may learn things from AI-enabled '\n",
      " 'systems and tools that give feedback and hints during the completion of\\n'\n",
      " '\\n'\n",
      " 'References:\\n'\n",
      " '\\n'\n",
      " \"60. Gardner, J., O'Leary, M. & Yuan, L. (2021). Artificial intelligence in \"\n",
      " 'educational assessment: \"Breakthrough? Or buncombe and ballyhoo?\" Journal of '\n",
      " 'Computer Assisted Learning, 37(5), 1207–1216. '\n",
      " 'https://doi.org/10.1111/jcal.12577\\n'\n",
      " '\\n'\n",
      " '61. Merrill, S. (2020). In schools, are we measuring what matters? Edutopia. '\n",
      " 'https://www.edutopia.org/article/schools-are-we-measuring-what-matters\\n'\n",
      " '\\n'\n",
      " '62. Roll, I., Aleven, V., McLaren, B.M., Koedinger, K.R. (2011). Improving '\n",
      " 'students’ help-seeking skills using metacognitive feedback in an intelligent '\n",
      " 'tutoring system, Learning and Instruction, 21(2), 267–280. '\n",
      " 'https://doi.org/10.1016/j.learninstruc.2010.07.004\\n'\n",
      " '\\n'\n",
      " '63. Webb, N.M., & Farivar, S. (1994). Promoting helping behavior in '\n",
      " 'cooperative small groups in middle school mathematics. American Educational '\n",
      " 'Research Journal, 31(2), 369–395. https://doi.org/10.3102/00028312031002369\\n'\n",
      " '\\n'\n",
      " '64. Kai, S., Almeda, M.V., Baker, R. S., Heffernan, C., & Heffernan, N. '\n",
      " '(2018). Decision tree modeling of wheel-spinning and productive persistence '\n",
      " 'in skill builders. Journal of Educational Data Mining, 10(1), 36–71. '\n",
      " 'https://doi.org/10.5281/zenodo.3344810\\n'\n",
      " '---\\n'\n",
      " 'homework, utilizing that feedback to later reinforce concepts in direct '\n",
      " 'instruction and strengthen the one-on-one support provided to students. '\n",
      " 'AI-enabled systems and tools can provide teachers with additional '\n",
      " 'information about the students’ recent work, so their instructor has a '\n",
      " 'greater contextual sense as they begin to provide help.\\n'\n",
      " '\\n'\n",
      " 'Third, we advocate for teachers and students to be strongly involved in '\n",
      " 'designing feedback loops as developers produce AI-enhanced formative '\n",
      " 'assessments so they can directly voice what would make assessments less '\n",
      " 'onerous and more convenient and valuable to them. Earlier in the Teaching '\n",
      " 'section, we emphasized how important it is to involve teachers in designing, '\n",
      " 'selecting, and evaluating AI-enhanced technologies. Students need to be '\n",
      " 'centered, too. They are experiencing AI in their everyday lives, and they '\n",
      " 'have strong opinions on what is valuable and safe. There are local and '\n",
      " 'cultural variations in how people provide and receive feedback, so adjusting '\n",
      " 'feedback to align with community norms is important.\\n'\n",
      " '\\n'\n",
      " 'Key Recommendation: Harness Assessment Expertise to Reduce Bias Bias and '\n",
      " 'fairness are important issues in assessment design and administration, and '\n",
      " 'they hold relevance for the area of AI-enabled assessment. In traditional '\n",
      " 'assessment, a test item might be biased if unnecessary details are included '\n",
      " 'that differentially advantage some students (e.g., a story-based item that '\n",
      " 'references a sport that only boys play regularly may be less helpful to '\n",
      " 'girls). As discussed earlier, with AI, we now must worry about algorithmic '\n",
      " 'discrimination which can arise due to the manner in which AI algorithms are '\n",
      " 'developed and improved from large datasets of parameters and values that may '\n",
      " 'not represent all cohorts of learners. Algorithmic discrimination is not '\n",
      " 'just about the measurement side of formative assessment; it is also about '\n",
      " 'the feedback loop and the instructional interventions and supports that may '\n",
      " 'be undertaken in response to data collected by formative assessments. There '\n",
      " 'is a question both about access to such interventions and the quality or '\n",
      " 'appropriateness of such interventions or supports. When an algorithm '\n",
      " 'suggests hints, next steps, or resources to a student, we have to check '\n",
      " 'whether the help-giving is unfair because one group systematically does not '\n",
      " 'get useful help which is discriminatory. Fairness goes beyond bias as well. '\n",
      " 'In AI-enabled formative assessment, both the opportunity to learn through '\n",
      " 'feedback loops, as well as the quality of learning in and outside of such '\n",
      " 'loops, should be addressed. Issues of bias and fairness have arisen in '\n",
      " 'traditional assessments, and the field of psychometrics has already '\n",
      " 'developed valuable tools to challenge and address these issues. Assessment '\n",
      " 'as a field may have a head start on tackling bias and fairness for AI in '\n",
      " 'education. And yet the issues expand with AI, so the work is not done. '\n",
      " 'Strong and deliberate attention to bias and fairness is needed as future '\n",
      " 'formative assessments are developed.\\n'\n",
      " '\\n'\n",
      " 'References:\\n'\n",
      " '\\n'\n",
      " '|65|Walker, E., Rummel, N. & Koedinger, K.R. (2015). Adaptive intelligent '\n",
      " 'support to improve peer tutoring in algebra. International Journal of '\n",
      " 'Artificial Intelligence in Education, 24, 33–61 '\n",
      " 'https://doi.org/10.1007/s40593-013-0001-9|\\n'\n",
      " '|---|---|\\n'\n",
      " '|66|Swiecki, Z., Khosravi, H., Chen, G., Martinez-Maldonado, R., Lodge, '\n",
      " 'J.M., Milligan, S., Selwyn, B. & Gašević,D. (2022). Assessment in the age of '\n",
      " 'artificial intelligence. Computers and Education: Artificial Intelligence, '\n",
      " '3. https://doi.org/10.1016/j.caeai.2022.100075|\\n'\n",
      " '|67|Reynolds, C.R., & Suzuki, L.A. (2012). Bias in psychological assessment: '\n",
      " 'An empirical review and recommendations. Handbook of Psychology, Second '\n",
      " 'Edition. https://doi.org/10.1002/9781118133880.hop210004|\\n'\n",
      " '|68|Kaplan, R.M., & Saccuzzo, D.P. (2017). Psychological testing: '\n",
      " 'Principles, applications, and issues. Cengage Learning.|\\n'\n",
      " '---\\n'\n",
      " '## Related Questions\\n'\n",
      " '\\n'\n",
      " 'Is formative assessment bringing benefits to pe student learning experience '\n",
      " 'and to pe efficacy of classroom instruction?\\n'\n",
      " 'Are humans being centered in AI-enabled formative assessment and feedback '\n",
      " 'loops?\\n'\n",
      " 'Are we providing empowering professional development to teachers so pey can '\n",
      " 'leverage feedback loops and safeguard against concerns?\\n'\n",
      " 'To what extent are pe developers and implementers of AI-enabled systems and '\n",
      " 'tools tackling new sources of algoripmic bias and continuing to make '\n",
      " 'assessment fairer?\\n'\n",
      " 'Are governance policies regarding who owns, controls, and can view or use '\n",
      " 'AI-enabled formative assessment data appropriate and adequate?\\n'\n",
      " 'Do we have sufficient guardrails against misuse of formative assessment data '\n",
      " 'or automatically generated interpretations of student achievement and '\n",
      " 'learning, such as on dashboards?\\n'\n",
      " 'Is trust in an AI-enabled assessment system, feedback loops, and data '\n",
      " 'generated by such assessments growing or diminishing?\\n'\n",
      " '---\\n'\n",
      " '## Research and Development Policy\\n'\n",
      " '\\n'\n",
      " 'Relies upon research-based knowledge; likewise, improving practice depends '\n",
      " 'on feedback loops that analyze empirical evidence. Consequently, the 2010 '\n",
      " 'NETP specified a series of “grand challenges” which were “R&D problems that '\n",
      " 'might be funded and coordinated at a national level.” One 2010 NETP grand '\n",
      " 'challenge was to create personalized learning systems that continuously '\n",
      " 'improve as they are used:\\n'\n",
      " '\\n'\n",
      " 'Design and validate an integrated system pat provides real-time access to '\n",
      " 'learning experiences tuned to pe levels of difficulty and assistance pat '\n",
      " 'optimize learning for all learners and pat incorporates self-improving '\n",
      " 'features pat enable it to become increasingly effective prough interaction '\n",
      " 'wip learners.\\n'\n",
      " '\\n'\n",
      " 'Since 2010, much R&D has addressed this challenge. Conferences about '\n",
      " 'learning analytics, educational data mining, and learning at scale have '\n",
      " 'blossomed. Developers have created platforms that use algorithms and the '\n",
      " 'analysis of big data to tune learning experiences. The challenge has not '\n",
      " 'been fully achieved, and further work on this challenge is still relevant '\n",
      " 'today.\\n'\n",
      " '\\n'\n",
      " '## Insight: Research Can Strengthen the Role of Context in AI\\n'\n",
      " '\\n'\n",
      " 'Despite the relevance of 2010’s grand challenges, it has become apparent '\n",
      " 'that the R&D community is now looking to expand their attention. The 2010 '\n",
      " 'challenges were stated as technical problems. Today’s researchers want to '\n",
      " 'more deeply investigate context, and today’s tech companies want to develop '\n",
      " 'platforms that are responsive to the learners’ characteristics and '\n",
      " 'situations more broadly—not just in terms of narrow cognitive attributes. We '\n",
      " 'see a push to transform R&D to address context sensitivity. We look forward '\n",
      " 'to new meanings of “adaptive” that broaden outward from what the term has '\n",
      " 'meant in the past decade. For example, “adaptive” should not always be a '\n",
      " 'synonym of “individualized” because people are social learners. Researchers '\n",
      " 'therefore are broadening “adaptivity” to include support for what students '\n",
      " 'do as they learn in groups, a form of learning that is prevalent in schools '\n",
      " 'across the U.S.\\n'\n",
      " '\\n'\n",
      " 'The focus on context is not an accident. Context is a traditional challenge '\n",
      " 'in AI. Thus, researchers and developers are wise to prioritizing context. '\n",
      " 'Unless we invest more in AI that is context-sensitive, it is quite likely '\n",
      " 'that AI will break and fail to achieve educational goals. Agreeing to '\n",
      " 'prioritize context won’t be easy. As illustrated above in Figure 12, there '\n",
      " 'will be a tension between depth of context and pace of technological '\n",
      " 'advances in AI R&D. On the one hand, AI is sometimes presented as a race to '\n",
      " 'be the first to advance new techniques or scale new applications—innovation '\n",
      " 'is sometimes portrayed as rapidly going to scale with a minimally viable '\n",
      " 'product, failing fast, and only after failure, dealing with context. On the '\n",
      " 'other hand, researchers and developers see that achieving good innovations '\n",
      " 'with AI in education will clearly\\n'\n",
      " '---\\n'\n",
      " 'require bringing more context into the process early and often. For example, '\n",
      " 'researchers highlight that humans must be continually adjusting the goals '\n",
      " 'for technology and have noted that when we set forth goals, we often don’t '\n",
      " 'yet fully understand context; and as we learn about context, the goals must '\n",
      " 'change. This suggests that context must be prioritized early and habitually '\n",
      " 'in R&D; we don’t want to win a race to the wrong finish line.\\n'\n",
      " '\\n'\n",
      " '|Figure 12: The tension between depth of context and pace of technological '\n",
      " 'advances in AI|\\n'\n",
      " '|---|\\n'\n",
      " '|Attention|Context|Face Innovation|\\n'\n",
      " '\\n'\n",
      " 'Further, intensifying focus on context in this work will change the nature '\n",
      " 'of the R&D. There won’t be just one type of change in R&D because context '\n",
      " 'has multiple meanings. Attendees in our listening sessions described four '\n",
      " 'types of context necessary for the future.\\n'\n",
      " '\\n'\n",
      " 'We list these four types of context below and then expand on each one in its '\n",
      " 'own section. These four types emerged as topics of provocations to think '\n",
      " 'differently about R&D but certainly do not exhaust the important ways of '\n",
      " 'investigating context.\\n'\n",
      " '\\n'\n",
      " '1. Focus on the Long Tail: How could we use big data and AI to pay more '\n",
      " 'attention to the “long tail” of edtech use—going beyond a few “most typical” '\n",
      " 'ways of using emerging technology and instead solving for digital equity and '\n",
      " 'inclusion?\\n'\n",
      " '2. Partnership in Design-Based Research: How can we change who is involved '\n",
      " 'and influential in designing the future of AI in education to more centrally '\n",
      " 'include students, teachers, and other educational constituents?\\n'\n",
      " '3. Connect with Public Policy: How can work on AI in education build on '\n",
      " 'general advances in AI ethics, safety, and regulation and contribute '\n",
      " 'additional advances specific to educational policy?\\n'\n",
      " '4. Rethink Teacher Professional Development: How can we solve for new '\n",
      " 'systems of teacher professional development (both pre-service and '\n",
      " 'in-service) that align to the increasingly core role of technology in the '\n",
      " 'teaching profession?\\n'\n",
      " '\\n'\n",
      " 'Reference: Russell, S. (2019). Human compatible: Artificial intelligence and '\n",
      " 'the problem of control. Penguin. ISBN: 9780525558637\\n'\n",
      " '---\\n'\n",
      " \"“We can't necessarily always apply traditional research methodologies to \"\n",
      " 'this topic because educational technology changes so quickly.”\\n'\n",
      " '—Kristina Ishmael, Office of Educational Technology\\n'\n",
      " '\\n'\n",
      " 'Attention to the Long Tail of Learner Variability\\n'\n",
      " 'At the core of R&D of AI in education, innovators will be building models '\n",
      " 'that fit available data.\\n'\n",
      " 'The increasing scale and prevalence of technologies means that the data is '\n",
      " 'coming from and\\n'\n",
      " 'including a wide range of different contexts and varied ways that people in '\n",
      " 'those contexts engage\\n'\n",
      " 'in teaching and learning. Researchers in our listening sessions drew '\n",
      " 'attention to the promise of\\n'\n",
      " 'AI for addressing “context” by reference to the long tail of learner '\n",
      " 'variability.\\n'\n",
      " '\\n'\n",
      " 'Figure 13: The long tail of learner variability\\n'\n",
      " '79\\n'\n",
      " '2\\n'\n",
      " \"Diversity of Learners' Strengths and Needs\\n\"\n",
      " 'As depicted in Figure 13, learners vary in their strengths and needs. The '\n",
      " 'most frequently\\n'\n",
      " 'occurring mix of strength and needs (also known as “teaching to the middle”) '\n",
      " 'is depicted\\n'\n",
      " 'leftmost, with less frequently occurring mixes spreading to the right. '\n",
      " 'Rising upward, the figure\\n'\n",
      " 'depicts the number of learners who benefit from a particular learning '\n",
      " 'design, pathway, or\\n'\n",
      " 'approach. We argue that AI can bring opportunities to address a wider '\n",
      " 'spectrum of strengths and\\n'\n",
      " 'needs but only if developers and innovators focus on the long tail and not '\n",
      " 'only “teaching to the\\n'\n",
      " 'middle.”\\n'\n",
      " '\\n'\n",
      " 'For the sake of argument, the figure indicates three zones. In a first zone, '\n",
      " 'curricular resources are\\n'\n",
      " 'mostly standardized, with perhaps a dimension or two of adaptivity. For '\n",
      " 'example, many existing\\n'\n",
      " 'products adapt based on the correctness of student answers and may also '\n",
      " 'provide options to read\\n'\n",
      " 'or hear text in a second language. However, the core of the instructional '\n",
      " 'approach is highly\\n'\n",
      " 'standardized. In a second zone, there is greater balance between how much '\n",
      " 'standardization and\\n'\n",
      " 'how much adaptivity students can access. Universal Design for Learning (UDL) '\n",
      " 'is one set of\\n'\n",
      " 'recommendations for providing learning opportunities in multiple formats and '\n",
      " 'for\\n'\n",
      " '---\\n'\n",
      " 'accommodating different learning progressions. UDL can enable accommodating '\n",
      " 'more ways in which learners vary, and as teachers know, there are many more '\n",
      " 'important ways to adapt to students than found in today’s edtech products. '\n",
      " 'Students are neurodiverse. They bring different assets from their '\n",
      " 'experiences at home, in their communities, and in their cultures. They have '\n",
      " 'different interests and motivations. And they learn in varied '\n",
      " 'settings—classrooms and schools differ, and at-home students learn in '\n",
      " 'informal settings in ways that could complement school learning. These are '\n",
      " 'all important dimensions of “context.” Zone 3 indicates highly adaptive '\n",
      " 'learning, where standardization is less successful and where we need to '\n",
      " 'discover a wider variety of approaches to engage learners and sustain '\n",
      " 'powerful learning. Researchers in our listening sessions noted the promise '\n",
      " 'of Zone 3 because AI’s ability to recognize patterns in data can extend '\n",
      " \"beyond the most common patterns and because AI's ability to generate \"\n",
      " 'customized content can extend beyond what people can reasonably generate on '\n",
      " 'their own. Notice that although the Zone 1 bar appears to be the tallest, '\n",
      " 'and thus tends to attract initial attention, there are more students in '\n",
      " 'Zones 2 and 3, the regions where AI can provide more help. Thus, it’s '\n",
      " 'important to ask where AI researchers and developers are directing their '\n",
      " 'attention. When we say a model “fits,” are we saying it fits the most common '\n",
      " 'and typical uses by teachers and learners? This sort of R&D is easier to do. '\n",
      " 'However, machine learning and AI also can tailor a model to the less common '\n",
      " 'and more culturally specific contexts, too. Therefore, how can constituents '\n",
      " 'cultivate interdisciplinary expertise to direct attention among researchers '\n",
      " 'and developers to focus on the long tail? If we do, the quality of what we '\n",
      " 'do for those represented in that tail can be more adaptive and more '\n",
      " 'context-sensitive. And to be most effective, it will require the integration '\n",
      " 'of contextual, content, and technical expertise. Within the long-tail '\n",
      " 'challenge, the community is wondering how we can get to research insights '\n",
      " 'that are both general and specific enough. When research produces very '\n",
      " 'general abstractions about learning, it often doesn’t give developers enough '\n",
      " 'guidance on exactly how to adjust their learning environments. Conversely, '\n",
      " 'when research produces a specific adaptive algorithm that works on one '\n",
      " 'educational platform, it often remains hard to apply to additional '\n",
      " 'platforms; research can be too detailed as well. The research community is '\n",
      " 'also thinking about new partnerships that could bring more data and more '\n",
      " 'diverse perspectives to the table, the topic of the next section. Focusing '\n",
      " 'on the long tail of learner variability is particularly important to '\n",
      " 'addressing a long-standing key research question: “Do new AI-enhanced '\n",
      " 'approaches work to improve learning, and for whom and under what '\n",
      " 'conditions?” Partnership in Design-Based Research Of course, teachers must '\n",
      " 'be included in rethinking their own professional development. This thought '\n",
      " 'leads to another priority aspect of context: partnership in design-based '\n",
      " 'research. With regard to inclusive design, attendees in our listening '\n",
      " 'sessions brought up a variety of co-design\\n'\n",
      " '\\n'\n",
      " 'Rose, D. (2000). Universal design for learning. Journal of Special Education '\n",
      " 'Technology, 15(4), 47-51. https://doi.org/10.1177/016264340001500407\\n'\n",
      " '\\n'\n",
      " 'Roschelle, J., Penuel, W., & Shechtman, N. (2006). Co-design of innovations '\n",
      " 'with teachers: definition and dynamics. In Proceedings of the 7th '\n",
      " 'International Conference on Learning Sciences, Bloomington, IN. '\n",
      " 'https://doi.dx.org/10.22318/icls2006.606\\n'\n",
      " '---\\n'\n",
      " 'and other participatory processes and goals that can be used in R&D. By '\n",
      " 'co-design, they mean sharing power with non-researchers and non-developers '\n",
      " 'through all the phases of design and development, which would result in more '\n",
      " 'influence by teachers, students, and other constituents in the shape of '\n",
      " 'AI-enabled edtech. The shift toward co-design was palpable throughout our '\n",
      " 'listening sessions, but as researchers and developers have not standardized '\n",
      " 'on one particular co-design method, we share some representative examples.\\n'\n",
      " '\\n'\n",
      " '- Youth can powerfully participate in design when researcher methods include '\n",
      " 'participant co-design. Such research can investigate how to improve edtech '\n",
      " 'while educating students. A listening session attendee asked about '\n",
      " 'developing students’ awareness of what data are being collected and how data '\n",
      " 'are being used by developers.\\n'\n",
      " '- There is a near future need to go beyond representation so that '\n",
      " 'co-designed solutions consider more generous contexts for broader '\n",
      " 'possibilities, according to attendees.\\n'\n",
      " '- The shift of power dynamics is another research-worthy interest of the '\n",
      " 'panel and attendees to understand the balance between a teacher’s agency and '\n",
      " 'a machine’s suggestions.\\n'\n",
      " '- Likewise, such longitudinal research will require both the infrastructure '\n",
      " 'and institutional support to fund necessary experimentation and requisite '\n",
      " 'failures to elicit positive results and safe innovation.\\n'\n",
      " '- There is a desire for rapid cycle evaluations with inclusive feedback '\n",
      " 'loops that return to the educators themselves as essential relative to '\n",
      " 'traditional research approaches.\\n'\n",
      " '- Many researchers also mentioned a focus on explainable AI as essential to '\n",
      " 'enable participation in the design and evaluation of emerging AI approaches '\n",
      " 'in education.\\n'\n",
      " '\\n'\n",
      " 'The conversations raised this question: how can co-design provide an '\n",
      " 'empowering form of participation in design and thus achieve digital '\n",
      " 'inclusion goals? Such digital inclusion can span many layers of design, '\n",
      " 'including diverse representation in design of policies around data, design '\n",
      " 'of adaptivity, and other user experiences in AI systems, design of plans for '\n",
      " 'cultivating AI literacy for users of new platforms, and lastly, the design '\n",
      " 'of plans to evaluate systems.\\n'\n",
      " '\\n'\n",
      " 'Re-thinking Teacher Professional Development\\n'\n",
      " '\\n'\n",
      " 'With regard to teachers as professionals, both researchers and other '\n",
      " 'educators attending our listening sessions were highly concerned about the '\n",
      " 'disconnect between how teachers are prepared versus how they are expected to '\n",
      " 'work with emerging technology. When we discuss learning, teachers are '\n",
      " 'central actors, and thus the contexts in which they are prepared is '\n",
      " 'centrally important to their ability to do great work in current and '\n",
      " 'emerging technological environments.\\n'\n",
      " '\\n'\n",
      " 'Teacher professional development, professional learning, and leadership (PD '\n",
      " 'or PL) for emerging technologies was seen as an area needing intense '\n",
      " 're-thinking, and research could lead the way. Today, few who prepare to '\n",
      " 'become a teacher in an established pre-service program learn about the '\n",
      " 'effective use of educational technology in schools and classrooms; those who '\n",
      " 'do\\n'\n",
      " '\\n'\n",
      " 'Center for Integrative Research in Computing and Learning Sciences (CIRCLS). '\n",
      " '(2022, Feb.). From Broadening to Empowering: Reflecting on the CIRCLS’21 '\n",
      " 'Convening. https://circls.org/circls21report\\n'\n",
      " '---\\n'\n",
      " 'have the opportunity to investigate technology rarely think about the '\n",
      " 'structures that shape its use in the classroom and in educational '\n",
      " 'leadership. Consequently, a troubling dichotomy arises between a small set '\n",
      " 'of investigators who specifically consider educational technology in their '\n",
      " 'research on teaching and a broader group of educators who see educational '\n",
      " 'technology as a generic instructional resource. The challenge is high '\n",
      " 'because teacher professional development will remain highly varied by local '\n",
      " 'contexts. Yet insufficient attention to teachers as leaders in the use and '\n",
      " 'further development of effective educational technology is widespread in '\n",
      " 'teacher professional development research.\\n'\n",
      " '\\n'\n",
      " 'One response can be in terms of investigating how to nurture greater AI '\n",
      " 'literacy for all teachers. AI literacy is not only important to protect '\n",
      " 'educators and students from possible dangers but also valuable to support '\n",
      " 'teachers to harness the good and do so in innovative ways. A panelist '\n",
      " 'reminded the group that this work implies how we prepare educators with a '\n",
      " 'baseline AI literacy and understanding. More transparency and authentic '\n",
      " 'dialogue can foster trust, which was mentioned by a researcher as a chief '\n",
      " 'concern for all teachers and students.\\n'\n",
      " '\\n'\n",
      " 'This is not to suggest that AI literacy is a complete or even a simple fix. '\n",
      " 'Researchers want to ask fundamental questions about what it means for '\n",
      " 'teachers to be professionals, especially as emerging technologies gain '\n",
      " 'ground in schools and classrooms—our teachers’ professional workplaces. '\n",
      " 'Researchers want to broadly reconceptualize teacher professionalism and to '\n",
      " 'stop treating technology as an add-on element of professional development.\\n'\n",
      " '\\n'\n",
      " '## Connecting with Public Policy\\n'\n",
      " '\\n'\n",
      " 'Defining human-centered AI for education requires the embrace of a '\n",
      " 'human-centered principle and foundation for developing and formulating '\n",
      " 'policies that govern the application and use of AI more generally throughout '\n",
      " 'society. For example, power dynamics that arise between companies and '\n",
      " 'consumers in society around issues like data ownership will also arise in '\n",
      " 'the education-specific ecosystem. Further, the public discourse in which '\n",
      " 'people are discussing ethics, bias, responsibility, and many other necessary '\n",
      " 'concepts will be happening simultaneously in public policy and in '\n",
      " 'educational ecosystems.\\n'\n",
      " '\\n'\n",
      " 'One clear implication in our listening sessions was that efforts to improve '\n",
      " 'AI literacy in education could be important and helpful to society more '\n",
      " 'generally. For example, one panelist said that an overarching goal of '\n",
      " 'improving AI literacy is necessary if they are to contribute to how those '\n",
      " 'technologies are designed. Another researcher was interested in how edtech '\n",
      " 'can provide environments where students can experience having difficult '\n",
      " 'discussions across perspectives, an issue which is endemic to present '\n",
      " 'society. A third researcher noted the insufficiencies of prior efforts to '\n",
      " 'contend with algorithmic bias, ethics, and inclusion due to a classroom’s '\n",
      " 'complex social dynamics.\\n'\n",
      " '\\n'\n",
      " 'Researchers want to take a lead in going beyond checkbox approaches to take '\n",
      " 'these issues seriously. And they also acknowledge that engaging with policy '\n",
      " 'is often a new form of context for edtech and AI researchers, many of whom '\n",
      " 'don’t have long experiences in policy arenas. Likewise, developers often do '\n",
      " 'have experience with some policy issues, such as data privacy and security, '\n",
      " 'but are now needing to become part of new conversations about ethics, bias.\\n'\n",
      " '---\\n'\n",
      " 'Transparency, and more, a problem that the EdSAFE AI Alliance is addressing '\n",
      " 'through multi-sector working groups and policy advocacy.\\n'\n",
      " '\\n'\n",
      " 'Key Recommendation: Focus R&D on Addressing Context\\n'\n",
      " '\\n'\n",
      " 'Attendees who have participated in listening sessions leading up to this '\n",
      " 'report were exceptionally clear that their view of future R&D involved a '\n",
      " 'shift from narrow technical questions to richer contextual questions. This '\n",
      " 'expansive shift toward context, as detailed below, is the foundational '\n",
      " 'orientation that the listening session attendees saw as being necessary to '\n",
      " 'advancing R&D.\\n'\n",
      " '\\n'\n",
      " 'Attendees included these as dimensions of context:\\n'\n",
      " '\\n'\n",
      " '- learner variability, e.g., in disabilities, languages spoken, and other '\n",
      " 'relevant characteristics;\\n'\n",
      " '- interactions with peers, teachers, and others in the learning settings;\\n'\n",
      " '- relationships across home, school, and community settings, including '\n",
      " 'cultural assets;\\n'\n",
      " '- instructional resources available while learning;\\n'\n",
      " '- teacher preparation; and\\n'\n",
      " '- policies and systems that structure teaching and learning.\\n'\n",
      " '\\n'\n",
      " 'To more fully represent the context of teaching and learning, including '\n",
      " 'these and other dimensions of text, researchers will have to work in '\n",
      " 'partnership with others to understand which aspects of context are most '\n",
      " 'relevant to teaching and learning and how they can be usefully incorporated '\n",
      " 'into AI models.\\n'\n",
      " '\\n'\n",
      " 'Ongoing Questions for Researchers\\n'\n",
      " '\\n'\n",
      " 'As mentioned earlier, people are good at context; AI—not so much. R&D '\n",
      " 'investment in context-rich edtech thus could serve multiple national '\n",
      " 'interests because finding ways to do a better job with context would be a '\n",
      " 'fundamental advancement in AI. Indeed, questions like these reverberate '\n",
      " 'across all applications of AI in society, and education is a centrally good '\n",
      " 'context for investigating them:\\n'\n",
      " '\\n'\n",
      " '- Are AI systems moving beyond the tall portions of the “long tail” to adapt '\n",
      " 'to a greater range of conditions, factors, and variations in how people '\n",
      " 'learn?\\n'\n",
      " '- To what extent are AI technologies enhancing rather than replacing human '\n",
      " 'control and judgment of student learning?\\n'\n",
      " '- How will users understand the legal and ethical implications of sharing '\n",
      " 'data with AI enabled technologies and how to mitigate privacy risks?\\n'\n",
      " '- To what extent does technology account for the complex social dynamics of '\n",
      " 'how people work and learn together, or is technology leading humans to '\n",
      " 'narrow or oversimplify?\\n'\n",
      " '- How can we more clearly define what we mean by a context-sensitive '\n",
      " 'technology in terms that are both concrete and broad enough? How can we '\n",
      " 'measure it?\\n'\n",
      " '\\n'\n",
      " 'Nentrup, E. (2022). How Policymakers Can Support Educators and Technology '\n",
      " 'Vendors Towards SAFE AI. EdSAFE AI Alliance. '\n",
      " 'https://www.edsafeai.org/post/how-policymakers-can-support-aied\\n'\n",
      " '---\\n'\n",
      " '## To what extent are technical indicators and human observations of bias or '\n",
      " 'unfairness working together with human observations? How can concerns about '\n",
      " 'ethics and equity in AI technologies become actionable both in R&D, and '\n",
      " 'later, when AI is widely used?\\n'\n",
      " '\\n'\n",
      " '## Are we learning for whom and under what conditions AI systems produce '\n",
      " 'desired benefits and impacts and avoid undesirable discrimination, bias, or '\n",
      " 'negative outcomes?\\n'\n",
      " '\\n'\n",
      " '## Desired National R&D Objectives\\n'\n",
      " '\\n'\n",
      " 'Attendees sought immediate progress on some key R&D issues, such as these:\\n'\n",
      " '\\n'\n",
      " 'Clarifying and achieving a consensus on pe terms pat go beyond data privacy '\n",
      " 'and data security, including ideas like human-centered, value-sensitive, '\n",
      " 'responsible, epical, and safe so constituents can advocate for peir needs '\n",
      " 'meaningfully and consistently\\n'\n",
      " 'Creating and studying effective programs for AI literacy for students, '\n",
      " 'teachers, and educational constituents in general, including literacy wip '\n",
      " 'regard to pe epics and equity issues specific to AI in educational settings\\n'\n",
      " 'Advancing research and development to increase fairness, accountability, '\n",
      " 'transparency, and safety in AI systems used in educational settings\\n'\n",
      " 'Defining participatory or co-designed research processes pat include '\n",
      " 'educators in pe development and conduct of research related to pe '\n",
      " 'development, use, and efficacy of AI-enabled systems and tools\\n'\n",
      " 'Highlighting and advancing R&D efforts pat empower pe participation and '\n",
      " 'voices of youp regarding research, data, and design of AI applications for '\n",
      " 'teaching and learning\\n'\n",
      " '\\n'\n",
      " 'Longer term desires for a national R&D program include some of the following '\n",
      " 'objectives:\\n'\n",
      " '\\n'\n",
      " 'Funding sustainable partnerships pat uncover what context means and how it '\n",
      " 'can be addressed over longer periods of time\\n'\n",
      " 'Better connecting goals for “broadening participation” (for example, in STEM '\n",
      " 'learning papways) to strategies for addressing learner variability and '\n",
      " 'diversity\\n'\n",
      " 'Prioritizing research to revitalize support for instructors in light of pe '\n",
      " 'increasingly technological nature of K-12, higher education, and workplace '\n",
      " 'learning settings\\n'\n",
      " 'Creating infrastructure and new ways of working togeper beyond individual '\n",
      " 'field-initiated grants so pat R&D wip big data and leveraging emerging AI '\n",
      " 'capabilities becomes safer and more productive\\n'\n",
      " '---\\n'\n",
      " '## Recommendations\\n'\n",
      " '\\n'\n",
      " 'Earlier, we asked two guiding questions:\\n'\n",
      " '\\n'\n",
      " '1. What is our collective vision of a desirable and achievable educational '\n",
      " 'system that leverages automation while protecting and centering human '\n",
      " 'agency?\\n'\n",
      " '2. On what timeline will we be ready with necessary guidelines and '\n",
      " 'guardrails along with convincing evidence of positive impacts, so that we '\n",
      " 'can ethically and equitably implement this vision widely?\\n'\n",
      " '\\n'\n",
      " 'Answers to the first question are provided throughout the Learning, '\n",
      " 'Teaching, Assessment, and Research sections. This section turns to a call to '\n",
      " 'action to education leaders and to recommendations. Core to the Department’s '\n",
      " 'perspective is that education will need leadership specific to our sector. '\n",
      " 'Leadership should recognize and build on prior accomplishments in edtech '\n",
      " '(such as strong prior work on student privacy and school data security) as '\n",
      " 'well as broad frameworks for safe AI (such as the Blueprint for an AI Bill '\n",
      " 'of Rights). Leadership must also reach beyond these accomplishments and '\n",
      " 'frameworks to address emerging opportunities and risks that are specific to '\n",
      " 'novel capabilities and uses of AI in education.\\n'\n",
      " '\\n'\n",
      " 'Insight: Aligning AI to Policy Objectives\\n'\n",
      " '\\n'\n",
      " 'Individual sections of this policy report provided insights in each of four '\n",
      " 'areas—learning, teaching, assessment, and research. These insights, '\n",
      " 'synthesized from extensive stakeholder consultation and listening sessions, '\n",
      " 'show that the advances in AI can bring opportunities to advance the '\n",
      " 'Department’s policy objectives:\\n'\n",
      " '\\n'\n",
      " '- In support of our objective of attracting and retaining teachers, our '\n",
      " 'nation could focus on AI assistants that make teaching jobs better and '\n",
      " 'provide teachers with the information they need to work closely and '\n",
      " 'empathically with students. An emphasis on teachers in the loop could ensure '\n",
      " 'that AI-enabled classroom technologies keep teachers in the know, in touch '\n",
      " 'with their students, and in control of important instructional decisions. '\n",
      " 'Keeping the teacher in the loop is important to managing risks, as well.\\n'\n",
      " '- In support of equitable learning, especially for those most affected by '\n",
      " 'the pandemic, AI could shift edtech from a current deficit-based model to a '\n",
      " 'strengths-based alternative. In addition to finding student weaknesses and '\n",
      " 'assigning fixes, edtech could make recommendations based on strengths that '\n",
      " 'students bring to learning and how adapting to the whole student—a '\n",
      " 'cognitive, social, and self-regulating person—could enable more powerful '\n",
      " 'learning. Adapting to the whole student should include supporting students '\n",
      " 'with disabilities as well as English learners. With regard to equity, we '\n",
      " 'must remain highly attuned to the challenges of bias (which are inherent to '\n",
      " 'how AI systems are developed) and take firm action to ensure fairness.\\n'\n",
      " '- With regard to growth trajectories to successful careers, AI-enabled '\n",
      " 'assessments could provide students and teachers with formative guidance on a '\n",
      " 'wider range of valuable skills, focusing on providing information that '\n",
      " 'enhances learning. Aligned with the human-centric view, we should take a '\n",
      " 'systems view of assessments where students, teachers, and others remain at '\n",
      " 'the center of instructional decision making.\\n'\n",
      " '---\\n'\n",
      " 'With regard to equity, as research advances and brings more context into AI, '\n",
      " 'we will be better able to use AI to support goals that require customization '\n",
      " 'of learning resources, such as enabling teachers to more easily transform '\n",
      " 'materials to support neurodiverse learners and increase responsiveness to '\n",
      " 'local communities and cultures. Going forward, educational leaders need to '\n",
      " 'bring these and their own policy priorities to the table at every discussion '\n",
      " 'about AI, driving the conversation around human priorities and not only '\n",
      " 'their excitement about what new technology might do. Fundamentally, AI seeks '\n",
      " 'to automate processes that achieve goals, and yet, AI should never set '\n",
      " 'goals. The goals must come from educators’ vision of teaching and learning '\n",
      " 'and educators’ understanding of students’ strengths and needs.\\n'\n",
      " '\\n'\n",
      " 'Calling Education Leaders to Action\\n'\n",
      " '\\n'\n",
      " 'We summarize seven recommendations for policy action. These recommendations '\n",
      " 'are for education leaders. In the introduction, we note the necessity of '\n",
      " 'involving education constituents in determining policies for AI. We also '\n",
      " 'observed throughout our listening sessions that people coming from many '\n",
      " 'different roles in education all have passion, knowledge, and insights to '\n",
      " 'contribute. In our view, all types of constituents can be education leaders. '\n",
      " 'We are reluctant to suggest any constituent role is more important to '\n",
      " 'advance any of the recommendations, but we call out specific needs for '\n",
      " 'action within some of the recommendations where it is warranted.\\n'\n",
      " '\\n'\n",
      " 'Recommendation #1: Emphasize Humans in the Loop\\n'\n",
      " '\\n'\n",
      " 'We start with a central recommendation throughout this report. This '\n",
      " 'recommendation was a clear constituent favorite. Indeed, across more than '\n",
      " '700 attendees in our listening sessions, the predominant discussion tackled '\n",
      " 'how constituents can achieve a consensus vision for AI-enabled edtech where '\n",
      " 'humans are firmly at the center. The Blueprint for an AI Bill of Rights '\n",
      " 'similarly calls for “access to timely human consideration and remedy by a '\n",
      " 'fallback and escalation process if an automated system fails, it produces an '\n",
      " 'error, or you would like to appeal or contest its impacts…” Building on this '\n",
      " 'consensus, we call upon all constituents to adopt “humans in the loop” as a '\n",
      " 'key criterion for educational use of AI.\\n'\n",
      " '\\n'\n",
      " 'We envision a technology-enhanced future more like an electric bike and less '\n",
      " 'like robot vacuums. On an electric bike, the human is fully aware and fully '\n",
      " 'in control, but their burden is less, and their effort is multiplied by a '\n",
      " 'complementary technological enhancement. Robot vacuums do their job, freeing '\n",
      " 'the human from involvement or oversight. Although teachers should not be the '\n",
      " 'only humans involved in loops, Figure 5 provided examples of three types of '\n",
      " 'teacher loops that are central to education and can be used to illustrate '\n",
      " 'what “human in the loop” means. Here, we use the example of an AI chatbot to '\n",
      " 'elaborate on the meaning of the loops. First, as students become involved in '\n",
      " 'extended interactions with AI chatbots, teachers will need to educate '\n",
      " 'students about safe AI use, monitor their use, and provide human recourse '\n",
      " 'when things go astray. Second, teachers are beginning to use chatbots to '\n",
      " 'plan personalized instruction for their students; they will need to be '\n",
      " 'involved in loops with other teachers to understand effective prompts, to '\n",
      " 'know how to analyze AI-generated lesson plans for flaws, and to avoid the '\n",
      " 'human tendency to overly trust AI systems and underapply human judgement. '\n",
      " 'Third, teachers need to be involved in the design and evaluation of AI '\n",
      " 'systems before they are used in classrooms and when needs for improvement '\n",
      " 'are observed. In one example, to design AI-generated homework support for '\n",
      " 'students, teachers’ in-depth understanding of the\\n'\n",
      " '---\\n'\n",
      " 'cognitive, motivational, and social supports their students need will '\n",
      " 'provide much-needed\\n'\n",
      " 'guidance as a homework-support chatbot is designed.\\n'\n",
      " 'In framing AI in education, this report advances a key recommendation of '\n",
      " '“human in the loop”\\n'\n",
      " 'AI because the phrase readily communicates a criterion that everyone can use '\n",
      " 'as they determine\\n'\n",
      " 'which AI-enabled systems and tools are appropriate for use in teaching and '\n",
      " 'learning. In a rather\\n'\n",
      " 'technical field, human in the loop is an approachable and humanistic '\n",
      " 'criterion. Rather than\\n'\n",
      " 'suggesting that AI-enabled systems and tools should replace teachers, this '\n",
      " 'term instead solidifies\\n'\n",
      " 'the central role of educators as instructors and instructional decision '\n",
      " 'makers, while reinforcing\\n'\n",
      " 'the responsibility of teachers to exercise judgement and control over the '\n",
      " 'use of AI in education.\\n'\n",
      " 'It resonates with the important idea of feedback loops, which are highly '\n",
      " 'important to how\\n'\n",
      " 'people teach and learn. It also aligns with the ideas of inspectable, '\n",
      " 'explainable, severable, and\\n'\n",
      " 'overridable AI.\\n'\n",
      " 'The Department agrees with listening session participants who argued that '\n",
      " 'teachers should not\\n'\n",
      " 'be the only humans in the loop and calls upon parents, families, students, '\n",
      " 'policy makers, and\\n'\n",
      " 'system leaders to likewise examine the “loops” for which they are '\n",
      " 'responsible, critically analyze\\n'\n",
      " 'the increasing role of AI in those loops, and determine what they need to do '\n",
      " 'to retain support for\\n'\n",
      " 'the primacy of human judgement in educational systems.\\n'\n",
      " 'Recommendation #2: Align AI Models to a Shared Vision for Education\\n'\n",
      " '“All models are wrong, but some are useful.”\\n'\n",
      " '—George Box, Statistician\\n'\n",
      " 'As we have discussed across every section of this report, AI technologies '\n",
      " 'are grounded in models,\\n'\n",
      " 'and these models are inevitably incomplete in some way. It is up to humans '\n",
      " 'to name educational\\n'\n",
      " 'goals and measure the degree to which models fit and are useful—or don’t fit '\n",
      " 'and might be\\n'\n",
      " 'harmful. Such an assessment of how well certain tools serve educational '\n",
      " 'priorities may seem\\n'\n",
      " 'obvious, but the romance of technology can lead to a “let’s see what the '\n",
      " \"tech can do'' attitude,\\n\"\n",
      " 'which can weaken the focus on goals and cause us to adopt models that fit '\n",
      " 'our priorities poorly.\\n'\n",
      " 'Here we call upon educational policy and decision makers at the local, '\n",
      " 'state, and federal level to\\n'\n",
      " 'use their power to align priorities, educational strategies, and technology '\n",
      " 'adoption decisions to\\n'\n",
      " 'place the educational needs of students ahead of the excitement about '\n",
      " 'emerging AI capabilities.\\n'\n",
      " 'We want to strengthen their attention to existing state, district, and '\n",
      " 'school-level policies that\\n'\n",
      " 'guide edtech adoption and use, such as the four levels of evidence in ESSA, '\n",
      " 'the privacy\\n'\n",
      " 'requirements of FERPA, and enhanced policies to come. Local education '\n",
      " 'leaders know best what\\n'\n",
      " 'their urgent educational priorities are. Every conversation about AI (or any '\n",
      " 'emerging\\n'\n",
      " 'technology) should start with the educational needs and priorities of '\n",
      " 'students front and center\\n'\n",
      " 'and conclude with a discussion about the evaluation of effectiveness '\n",
      " 're-centered on those needs\\n'\n",
      " 'and priorities. Equity, of course, is one of those priorities that requires '\n",
      " 'constant attention,\\n'\n",
      " 'especially given the worrisome consequences of potentially biased AI '\n",
      " 'models.\\n'\n",
      " 'We especially call upon leaders to avoid romancing the magic of AI or only '\n",
      " 'focusing on\\n'\n",
      " 'promising applications or outcomes, but instead to interrogate with a '\n",
      " 'critical eye how AI-enabled\\n'\n",
      " 'systems and tools function in the educational environment. We ask leaders to '\n",
      " 'distrust broad\\n'\n",
      " 'claims and ask six types of questions, listed below. Throughout this report, '\n",
      " 'we elaborated on\\n'\n",
      " '---\\n'\n",
      " 'which characteristics of AI model use in education are most important to '\n",
      " 'evaluate for alignment to intended educational goals. To aid leaders, we '\n",
      " 'summarize our insights about AI models and their use in educational tools '\n",
      " 'and systems in Figure 14.\\n'\n",
      " '\\n'\n",
      " '|Figure 14: Recommendation for desired qualities of AI tools and systems in '\n",
      " 'education| | |\\n'\n",
      " '|---|---|---|\\n'\n",
      " '|Humans in the Loop|Privacy|Data Security|\\n'\n",
      " '|Transparent; Accountable| |Aligned to Our Vision for Learning|\\n'\n",
      " '|Responsible| | |\\n'\n",
      " '|Context-aware| | |\\n'\n",
      " '|Effective Across Contexts|Minimize Bias|Explainable|\\n'\n",
      " '|Students & Teachers| |Overridable|\\n'\n",
      " '| |Promote Fairness| |\\n'\n",
      " '|Within Educational Systems| |Perspective|\\n'\n",
      " '\\n'\n",
      " 'In this figure, we center teaching and learning in all considerations about '\n",
      " 'the suitability of an AI model for an educational use. Humans remain in the '\n",
      " 'loop of defining, refining, and using AI models. We highlight the six '\n",
      " 'desirable characteristics of AI models for education (elaborating from '\n",
      " 'principles in the Blueprint for an AI Bill of Rights to fit the specifics of '\n",
      " 'educational systems):\\n'\n",
      " '\\n'\n",
      " '1. Alignment of the AI Model to Educators’ Vision for Learning: When '\n",
      " 'choosing to use AI in educational systems, decision makers prioritize '\n",
      " 'educational goals, the fit to all we know about how people learn, and '\n",
      " 'alignment to evidence-based best practices in education.\\n'\n",
      " '2. Data Privacy: Ensuring security and privacy of student, teacher, and '\n",
      " 'other human data in AI systems is essential.\\n'\n",
      " '3. Notice and Explanation: Educators can inspect edtech to determine whether '\n",
      " 'and how AI is being incorporated within edtech systems. Educators’ push for '\n",
      " 'AI models can explain the basis for detecting patterns and/or for making '\n",
      " 'recommendations, and people retain control over these suggestions.\\n'\n",
      " '4. Algorithmic Discrimination Protections: Developers and implementers of AI '\n",
      " 'in education take strong steps to minimizing bias and promoting fairness in '\n",
      " 'AI models.\\n'\n",
      " '---\\n'\n",
      " '## Safe and Effective Systems:\\n'\n",
      " '\\n'\n",
      " 'The use of AI models in education is based on evidence of efficacy (using '\n",
      " 'standards already established in education for this purpose) and work for '\n",
      " 'diverse learners and in varied educational settings.\\n'\n",
      " '\\n'\n",
      " '## Human Alternatives, Consideration and Feedback:\\n'\n",
      " '\\n'\n",
      " 'AI models that support transparent, accountable, and responsible use of AI '\n",
      " 'in education by involving humans in the loop to ensure that educational '\n",
      " 'values and principles are prioritized.\\n'\n",
      " '\\n'\n",
      " 'Although we first address our recommendation to interrogate how educational '\n",
      " 'systems use AI models to educational leaders who adopt technologies, other '\n",
      " 'leaders also have integral roles to play. Teachers and students, as well as '\n",
      " 'their families/caregivers, contribute significantly to adoption decisions '\n",
      " 'also. And leaders and parents must support educators when they question or '\n",
      " 'override an AI model based on their professional wisdom. Developers of '\n",
      " 'technologies need to be forthcoming about the models they use, and we may '\n",
      " 'need policymakers to create requirements for disclosure so that the '\n",
      " 'marketplace can function on the basis of information about AI models and not '\n",
      " 'only by the claims of their benefits.\\n'\n",
      " '\\n'\n",
      " 'We also emphasize the need for a government role. AI models are made by '\n",
      " 'people and are only an approximation to reality. Thus, we need policies that '\n",
      " 'require transparency about the AI models that are embedded in educational '\n",
      " 'systems, as well as models that are inspectable, explainable, and '\n",
      " 'overridable. Our listening sessions featured constituent calls for '\n",
      " 'government doing more to hold developers accountable for disclosing the '\n",
      " 'types of AI models they employ in large-scale products and the safeguards '\n",
      " 'included in their systems. Government leaders can make a positive '\n",
      " 'contribution to market conditions that enable building trust as AI systems '\n",
      " 'are procured and implemented in education. We discuss these guidelines more '\n",
      " 'in recommendation #4, which is about building trust.\\n'\n",
      " '\\n'\n",
      " '## Recommendation #3: Design Using Modern Learning Principles\\n'\n",
      " '\\n'\n",
      " 'We call for the R&D sector to ensure that product designs are based on best '\n",
      " 'and most current principles of teaching and learning. The first decade of '\n",
      " 'adaptivity in edtech drew upon many important principles, for example, '\n",
      " 'around how to sequence learning experiences and how to give students '\n",
      " 'feedback. And yet the underlying conception was often deficit-based. The '\n",
      " 'system focused on what was wrong with the student and chose pre-existing '\n",
      " 'learning resources that might fix that weakness. Going forward, we must '\n",
      " 'harness AI’s ability to sense and build upon learner strengths. Likewise, '\n",
      " 'the past decade of approaches was individualistic, and yet we know that '\n",
      " 'humans are fundamentally social and that learning is powerfully social. '\n",
      " 'Going forward, we must build on AI capabilities that connect with principles '\n",
      " 'of collaborative and social learning and which respect the student not just '\n",
      " 'for their cognition but also for the whole human skill set.\\n'\n",
      " '\\n'\n",
      " 'Going forward, we also must seek to create AI systems that are culturally '\n",
      " 'responsive and culturally sustaining, leveraging the growth of published '\n",
      " 'techniques for doing so. Further, most early AI systems had few specific '\n",
      " 'supports for students with disabilities and English learners. Going forward, '\n",
      " 'we must ensure that AI-enabled learning resources are intentionally '\n",
      " 'inclusive of these students. The field has yet to develop edtech that builds '\n",
      " 'upon each student’s ability to make choices and to self-regulate in '\n",
      " 'increasingly complex environments. We have to develop edtech that expands '\n",
      " 'students’ abilities to learn in creative modes and to expand their ability '\n",
      " 'to discuss, write, present, and lead.\\n'\n",
      " '\\n'\n",
      " 'We also call upon educators to reject uses of AI that are based solely on '\n",
      " 'machine learning from data—without triangulation based on learning theory '\n",
      " 'and knowledge from practice. Achieving\\n'\n",
      " '---\\n'\n",
      " 'Effective and equitable educational systems require more than processing '\n",
      " '“big data,” and although we want to harness insights from data, human '\n",
      " 'interpretation of data remains highly important. We reject a technological '\n",
      " 'determinism in which patterns in data, on their own, tell us what to do. '\n",
      " 'Applications of AI in education must be grounded in established, modern '\n",
      " 'learning principles, the wisdom of educational practitioners, and should '\n",
      " 'leverage the expertise in the educational assessment community around '\n",
      " 'detecting bias and improving fairness.\\n'\n",
      " '\\n'\n",
      " 'Recommendation #4: Prioritize Strengthening Trust\\n'\n",
      " '\\n'\n",
      " 'Technology can only help us to achieve educational objectives when we trust '\n",
      " 'it. Yet, our listening sessions revealed the ways in which distrust of '\n",
      " 'edtech and AI is commonplace. Constituents distrust emerging technologies '\n",
      " 'for multiple reasons. They may have experienced privacy violations. The user '\n",
      " 'experience may be more burdensome than anticipated. Promised increases in '\n",
      " 'student learning may not be backed by efficacy research. They may have '\n",
      " 'experienced unanticipated consequences. Unexpected costs may arise. '\n",
      " 'Constituents may distrust complexity. Trust needs to incorporate safety, '\n",
      " 'usability, and efficacy.\\n'\n",
      " '\\n'\n",
      " 'The Department firmly takes the stance that constituents want AI that '\n",
      " 'supports teachers and rejects AI visions that replace teachers. And yet, '\n",
      " 'teachers, students, and their families/caregivers need support to build '\n",
      " 'appropriate levels of trust in systems that affect their work. In the '\n",
      " 'broader ecosystem, trustworthy AI is recognized as a multidimensional '\n",
      " 'problem (including the dimensions of Figure 14, above). If every step '\n",
      " 'forward does not include strong elements of trust building, we worry that '\n",
      " 'distrust will distract from innovation serving the public good that AI could '\n",
      " 'help realize.\\n'\n",
      " '\\n'\n",
      " 'We expect that associations and societies have a key role in strengthening '\n",
      " 'trust. Some important associations like the State Educational Technology '\n",
      " 'Directors Association and the Consortium for School Network work with edtech '\n",
      " 'leaders, and parallel organizations like EDUCAUSE work with postsecondary '\n",
      " 'leaders. Other associations and societies work with teachers, education '\n",
      " 'leaders, and education staff developers. Industry networks, like the EdSAFE '\n",
      " 'AI Alliance, can bring together industry leaders to work together to foster '\n",
      " 'trust. Additional societies bring researchers together. These societies and '\n",
      " 'associations have the reach necessary to bring all parts of the educational '\n",
      " 'ecosystem into discussions about trust and also the ability to represent the '\n",
      " 'views of their constituents in cross-cutting policy discussions.\\n'\n",
      " '\\n'\n",
      " 'Recommendation #5: Inform and Involve Educators\\n'\n",
      " '\\n'\n",
      " 'Our listening sessions also asked for more specific direction on the '\n",
      " 'question of what education leaders should do (see Figure 15). The most '\n",
      " 'frequent responses fit three clusters: the need for guidelines and '\n",
      " 'guardrails, strengthening the role of teachers, and re-focusing research and '\n",
      " 'development. These are activities that constituents are asking for and that '\n",
      " 'could expand trust. The recommendations that follow respond to these '\n",
      " 'requests.\\n'\n",
      " '---\\n'\n",
      " '## Figure 15: Listening session attendees prioritized involving '\n",
      " 'practitioners, research, and evaluation and the need for guidelines and '\n",
      " 'guardrails.\\n'\n",
      " '\\n'\n",
      " '|Involve Practitioners:|Research Evaluation:|Guardrails Guidelines:|\\n'\n",
      " '|---|---|---|\\n'\n",
      " '|Support teacher professional learning opportunities for hands-on '\n",
      " 'experience|Study efficacy - what works for whom under what conditions?|Limit '\n",
      " 'or regulate uses of AI|\\n'\n",
      " '|Teachers and students as co-designers|Define and apply criteria (safe, '\n",
      " 'fair, etc.)|Invest in research and development|\\n'\n",
      " '\\n'\n",
      " 'In particular, one concern that repeatedly arose in our listening sessions '\n",
      " 'was the potential for AI to result in less respect for educators or less '\n",
      " 'value for their skills. Across the nation, we are now responding to '\n",
      " 'decreasing interest in entering or remaining in the teaching profession. Now '\n",
      " 'is the time to show the respect and value we hold for educators by informing '\n",
      " 'and involving them in every step of the process of designing, developing, '\n",
      " 'testing, improving, adopting, and managing AI-enabled edtech. This includes '\n",
      " 'involving educators in reviewing existing AI-enabled systems, tools, and '\n",
      " 'data use in schools, designing new applications of AI based on teacher '\n",
      " 'input, carrying out pilot evaluations of proposed new instructional tools, '\n",
      " 'collaborating with developers to increase the trustworthiness of the '\n",
      " 'deployed system, and raising issues about risks and unexpected consequences '\n",
      " 'as the system is implemented.\\n'\n",
      " '\\n'\n",
      " 'We have already seen educators rise to the challenge of creating overall '\n",
      " 'guidelines, designing specific uses of available AI-enabled systems and '\n",
      " 'tools, and ferreting out concerns. And yet, the influence of educators in '\n",
      " 'the future of AI-enabled products cannot be assumed; instead, constituents '\n",
      " 'need policies that put muscle behind it. Could we create a national corps of '\n",
      " 'leading educators representing every state and region to provide leadership? '\n",
      " 'Could we commit to developing necessary professional development supports? '\n",
      " 'Can we find ways to compensate educators so they can be at the forefront of '\n",
      " 'designing the future of education? Our policies should enable educators to '\n",
      " 'be closely involved in the design of AI-enabled educational systems.\\n'\n",
      " '\\n'\n",
      " 'Although we know that the responsibility for informing and involving '\n",
      " 'educators must be distributed at all levels of national and school '\n",
      " 'governance, the Office of Educational Technology\\n'\n",
      " '---\\n'\n",
      " 'can play a key role in informing and involving educators through its '\n",
      " 'reports, events, outreach, and in a future NETP. Although examples above '\n",
      " 'refer to K-12 teachers, higher education instructors must also be included. '\n",
      " 'We also call on the edtech industry to involve educators throughout their '\n",
      " 'design and development processes. For example, AI-enabled teaching '\n",
      " 'assistants are only likely to help teachers do their job if teachers are '\n",
      " 'thoroughly involved as the assistants are designed. We call upon '\n",
      " 'institutions that prepare teachers to integrate technology more '\n",
      " 'systematically into their programs; for example, the use of technology in '\n",
      " 'teaching and learning should be a core theme across teacher preparation '\n",
      " 'programs, not an issue that arises only in one course.\\n'\n",
      " '\\n'\n",
      " 'Recommendation #6: Focus R&D on Addressing Context and Enhancing Trust and '\n",
      " 'Safety\\n'\n",
      " '\\n'\n",
      " 'Research that focuses on how AI-enabled systems can adapt to context '\n",
      " '(including variability among learners) in instructional approaches and '\n",
      " 'across educational settings is essential to answering the question of, “Do '\n",
      " 'specific applications of AI work in education, and if so, for whom and under '\n",
      " 'what conditions?” The italicized phrase points to variability among learners '\n",
      " 'and diversity in the settings for learning. We call upon innovators in R&D '\n",
      " 'to focus their efforts to advance AI on the long tail of learning '\n",
      " 'variability, where large populations of students would benefit from '\n",
      " 'customization of learning. We also call on R&D to lead by establishing how '\n",
      " 'trust can be strengthened in AI-enabled systems, building on the Blueprint’s '\n",
      " 'call for safe and effective systems yet also including education-specific '\n",
      " 'requirements, such as how teachers can be meaningfully involved in design '\n",
      " 'phases, not only in implementation and evaluation.\\n'\n",
      " '\\n'\n",
      " 'Although many products today are adaptive, some adapt on just one or a few '\n",
      " 'dimensions of variability, such as student’s accuracy in problem solving. As '\n",
      " 'teachers know, there are many more important ways to adapt to students’ '\n",
      " 'strengths and needs. Students are neurodiverse and may have specific '\n",
      " 'disabilities. They bring different assets from their experiences at home, in '\n",
      " 'communities, and in their cultures. They have different interests and '\n",
      " 'motivations. They are in different places in their journeys to master the '\n",
      " 'English language. And they learn in varied settings. Classrooms and schools '\n",
      " 'are different, and at home, students learn in informal settings in ways that '\n",
      " 'could complement school learning. We recommend attention to “context” as a '\n",
      " 'means for expressing the multiple dimensions that must be considered when '\n",
      " 'elaborating the phrase “for whom and under what conditions.” We also '\n",
      " 'acknowledge the role of researchers in conducting evaluations, which must '\n",
      " 'now consider not only efficacy but must also explore where harm may arise '\n",
      " 'and the system problems that can occur through weak trust or over-trust in '\n",
      " 'AI systems.\\n'\n",
      " '\\n'\n",
      " 'R&D must take the lead in making AI models more context-sensitive and '\n",
      " 'ensuring that they are effective, safe, and trustworthy for use with varied '\n",
      " 'learners in diverse settings. Although AI has capabilities to find patterns '\n",
      " 'beyond the limited number of variables that people normally think about, AI '\n",
      " 'is not particularly good at understanding and working with context in the '\n",
      " 'ways people do. Over time, we’ve seen learning sciences grow to be less '\n",
      " 'about individualistic cognitive principles and more encompassing first of '\n",
      " 'social learning and then of the many dimensions of context that matter in '\n",
      " 'learning. Our use of AI needs to follow this trajectory toward context to '\n",
      " 'support educational applications.\\n'\n",
      " '\\n'\n",
      " 'To achieve human-centric vision, listening session attendees argued that '\n",
      " 'teams will need time and freedom to explore how best to manage the tension '\n",
      " 'between the pace of technological\\n'\n",
      " '---\\n'\n",
      " 'advancement and the need for broader contextual insights—for trust and for '\n",
      " 'safety. They will need time and freedom to pioneer new processes that better '\n",
      " 'involve teachers and students as co-designers, with attention to balancing '\n",
      " 'power dynamics. And they will need to shift attention from older ways of '\n",
      " 'framing priorities (such as achievement gaps) to new ways of prioritizing '\n",
      " 'digital equity. We call on R&D funders to focus resources on the long tail '\n",
      " 'of learner variability, the need for AI-enabled systems that better '\n",
      " 'incorporate context, and time required to get contextual considerations '\n",
      " 'right. We call upon researchers and developers to prioritize challenges of '\n",
      " 'context, trust, and safety in their work to advance AI.\\n'\n",
      " '\\n'\n",
      " 'Recommendation #7: Develop Education-Specific Guidelines and Guardrails\\n'\n",
      " '\\n'\n",
      " 'Our final recommendation is central to policymakers. A feature of the '\n",
      " 'American educational system is the emphasis on local decision making. With '\n",
      " 'technology growing in complexity at such a rapid pace, it is becoming '\n",
      " 'difficult for local leaders to make informed decisions about the deployment '\n",
      " 'of artificial intelligence. As we have discussed, the issues are not only '\n",
      " 'data privacy and security but extend to new topics such as bias, '\n",
      " 'transparency, and accountability. It will be harder to evaluate promising '\n",
      " 'edtech platforms that rely on AI systems against this evolving, complex set '\n",
      " 'of criteria.\\n'\n",
      " '\\n'\n",
      " 'Regulations related to key student and family data privacy laws like the '\n",
      " 'Family Educational Rights & Privacy Act (FERPA), the Children’s Internet '\n",
      " 'Privacy Act (CIPA), and the Children’s Online Privacy Protection Act (COPPA) '\n",
      " 'warrant review and further consideration in light of new and emerging '\n",
      " 'technologies in schools. Laws such as the Individuals with Disabilities '\n",
      " 'Education Act (IDEA) may likewise be considered as new situations arise in '\n",
      " 'the use of AI-enabled learning technologies. As discussed throughout this '\n",
      " 'document, the Blueprint for an AI Bill of Rights is an important framework '\n",
      " 'throughout this work.\\n'\n",
      " '\\n'\n",
      " 'The Department encourages parallel work by constituents in all levels of the '\n",
      " 'educational system. In addition to the key federal laws cited immediately '\n",
      " 'above, many states have also passed privacy laws that govern the use of '\n",
      " 'educational technology and edtech platforms in classrooms. Further '\n",
      " 'constituents can expect general frameworks for responsible AI in parallel '\n",
      " 'sectors like health, safety, and consumer products to be informative but not '\n",
      " 'sufficient for education’s specific needs. Leaders at every level need '\n",
      " 'awareness of how this work reaches beyond implications for privacy and '\n",
      " 'security (e.g., to include awareness of potential bias and unfairness), and '\n",
      " 'they need preparation to effectively confront the next level of issues.\\n'\n",
      " '\\n'\n",
      " 'Next Steps\\n'\n",
      " '\\n'\n",
      " 'We are heartened to see intensifying discussions throughout the educational '\n",
      " 'ecosystem about the role of AI. We see progress that we can build upon '\n",
      " 'occurring, as constituents discuss these three types of questions: What are '\n",
      " 'the most significant opportunities and risks? How can we achieve trustworthy '\n",
      " 'educational AI? How can we understand the models at the heart of '\n",
      " 'applications of AI and ensure they have the qualities that align to '\n",
      " 'educational aspirations?\\n'\n",
      " '\\n'\n",
      " 'The Department developed this report with awareness of contributions arising '\n",
      " 'from many types of organizations and collectives. Internationally, we '\n",
      " 'recognize parallel efforts to consider AI in the European Union, at the '\n",
      " 'United Nations, and indeed throughout the world. We are aware of progress '\n",
      " 'being led by organizations such as UNESCO, the EdSAFE AI Alliance, and '\n",
      " 'research\\n'\n",
      " '---\\n'\n",
      " 'Organizations in many countries. We plan to continue cross-agency work, for '\n",
      " 'example, by continuing to coordinate with the Office of Science and '\n",
      " 'Technology Policy and other Federal agencies as agencies implement next '\n",
      " 'steps guided by the Blueprint for an AI Bill of Rights. We see a broad and '\n",
      " 'fertile context for necessary next steps:\\n'\n",
      " '\\n'\n",
      " '- Working within this context and with others, the Department will consider '\n",
      " 'specific policies and regulations so that educators can realize the '\n",
      " 'opportunities of AI in edtech while minimizing risks. For example, the '\n",
      " 'Department is developing a set of AI usage scenarios to strengthen the '\n",
      " 'process of evaluating and enhancing policies and regulations. The principles '\n",
      " 'and practices in the Blueprint for an AI Bill of Rights will be used to '\n",
      " 'ensure the scenarios mitigate important risks and harms.\\n'\n",
      " '- Working with constituents (including education leaders; teachers, faculty, '\n",
      " 'support staff, and other educators; researchers; policymakers; funders; '\n",
      " 'technology developers; community members and organizations; and above all, '\n",
      " 'learners and their families/caregivers), we will develop additional '\n",
      " 'resources and events to increase understanding of AI and to involve those '\n",
      " 'who will be most affected by these new technologies.\\n'\n",
      " '- Working across sectors, such as education, innovation, research, and '\n",
      " 'policy, we will revise and update the NETP to guide all constituents toward '\n",
      " 'safe, equitable, and effective AI in education in the United States, in '\n",
      " 'alignment with our overall educational priorities.\\n'\n",
      " '---\\n'\n",
      " '|AES|Automated Essay Scoring|\\n'\n",
      " '|---|---|\\n'\n",
      " '|AI|Artificial Intelligence|\\n'\n",
      " '|CIPA|Children’s Internet Protection Act|\\n'\n",
      " '|COPPA|Children’s Online Privacy Protection Act|\\n'\n",
      " '|Edtech|Educational Technology|\\n'\n",
      " '|ESEA|Elementary and Secondary Education Act|\\n'\n",
      " '|ESSA|Every Student Succeeds Act|\\n'\n",
      " '|FERPA|Family Educational Rights and Privacy Act|\\n'\n",
      " '|IA|Intelligence Augmentation|\\n'\n",
      " '|IDEA|Individuals with Disabilities Education Act|\\n'\n",
      " '|IEP|Individualized Education Program|\\n'\n",
      " '|ITS|Intelligent Tutoring Systems|\\n'\n",
      " '|NETP|National Education Technology Plan|\\n'\n",
      " '|R&D|Research & Development|\\n'\n",
      " '---\\n'\n",
      " '## Acknowledgements\\n'\n",
      " '\\n'\n",
      " 'Project Team\\n'\n",
      " '\\n'\n",
      " 'Artificial Intelligence and the Future of Teaching and Learning was '\n",
      " 'developed under the leadership\\n'\n",
      " 'and guidance of Roberto J. Rodríguez, Assistant Secretary for the Office of '\n",
      " 'Planning, Evaluation,\\n'\n",
      " 'and Policy Development, Kristina Ishmael, Deputy Director of the Office of '\n",
      " 'Educational\\n'\n",
      " 'Technology, and Bernadette Adams, Senior Policy Advisor for the Office of '\n",
      " 'Educational\\n'\n",
      " 'Technology at the U.S. Department of Education.\\n'\n",
      " '\\n'\n",
      " 'Support for the creation of this document was provided by Digital Promise, '\n",
      " 'led by Jeremy\\n'\n",
      " 'Roschelle with Carly Chillmon, Judi Fusco, Gabrielle Lue, Eric Nentrup, My '\n",
      " 'Nguyen, Pati\\n'\n",
      " 'Ruiz, and Zohal Shah. Special thanks to Center for Integrative Research in '\n",
      " 'Computing and\\n'\n",
      " 'Learning Sciences postdocs Michael Chang and Aditi Mallavarapu.\\n'\n",
      " '\\n'\n",
      " 'Listening Session Panelists and Hosts\\n'\n",
      " '\\n'\n",
      " '|Hal Abelson|Judi Fusco|Aditi Mallavarapu|\\n'\n",
      " '|---|---|---|\\n'\n",
      " '|Ryan Baker|Dragan Gasevic|Ole Molvig|\\n'\n",
      " '|Nancye Blair Black|Kip Glazer|Peter Norvig|\\n'\n",
      " '|Marcelo Aaron Bonilla|Janice Gobert|Thomas Philip Worsley|\\n'\n",
      " '|Sarah Hampton|Vidula Plante| |\\n'\n",
      " '|Michael Chang|Kristina Ishmael|Jeremy Roschelle|\\n'\n",
      " '|Carly Chillmon|Jim Larimore|Pati Ruiz|\\n'\n",
      " '|Sherice Clarke|Nicol Turner Lee|Alina Von Davier|\\n'\n",
      " '|Tammy Clegg|Sherry Loftin|Erin Walker|\\n'\n",
      " '|Sidney d’Mello|Gabrielle Lue|Diego Zapata|\\n'\n",
      " '\\n'\n",
      " 'We also thank 1,075 people who registered for Listening Sessions and 700 who '\n",
      " 'attended.\\n'\n",
      " '---\\n'\n",
      " '## References\\n'\n",
      " '\\n'\n",
      " 'Akgun, S., Greenhow, C. (2022). Artificial intelligence in education: '\n",
      " 'Addressing epical challenges in K-12 settings. AI Epics, 2, 431–440. '\n",
      " 'https://doi.org/10.1007/s43681-021-00096-7\\n'\n",
      " 'Aleven, V., McLaughlin, E. A., Glenn, R. A., & Koedinger, K. R. (2016). '\n",
      " 'Instruction based on adaptive learning technologies. In Mayer, R.E. & '\n",
      " 'Alexander, P.A., Handbook of research on learning and instruction, 522-560. '\n",
      " 'ISBN: 113883176X\\n'\n",
      " 'Baker, R.S., Esbenshade, L., Vitale, J., & Karumbaiah, S. (2022). Using '\n",
      " 'demographic data as predictor variables: A questionable choice. '\n",
      " 'https://doi.org/10.35542/osf.io/y4wvj\\n'\n",
      " 'Black, P. & Wiliam, D. (1998). Inside pe black box: Raising standards prough '\n",
      " 'classroom assessment. Phi Delta Kappan, 92(1), 81-90. '\n",
      " 'https://kappanonline.org/inside-pe-black-box-raising-standards-prough-classroom-assessment/\\n'\n",
      " 'Black, P., & Wiliam, D. (2009). Developing pe peory of formative assessment. '\n",
      " 'Educational Assessment, Evaluation and Accountability, 21(1), 5-31. '\n",
      " 'https://doi.org/10.1007/s11092-008-9068-5\\n'\n",
      " 'Boden, M.A. (2018). Artificial intelligence: A very short introduction. '\n",
      " 'Oxford. ISBN: 978-0199602919\\n'\n",
      " 'Bryant, J., Heitz,C., Sanghvi, S., & Wagle, D. (2020, January 14). How '\n",
      " 'artificial intelligence will impact K-12 teachers. McKinsey. '\n",
      " 'https://www.mckinsey.com/industries/education/our-insights/how-artificial-intelligence-will-impact-k-12-teachers\\n'\n",
      " 'Celik, I., Dindar, M., Muukkonen, H. & Järvelä, S. (2022). The promises and '\n",
      " 'challenges of artificial intelligence for teachers: A systematic review of '\n",
      " 'research. TechTrends, 66, 616–630. '\n",
      " 'https://doi.org/10.1007/s11528-022-00715-y\\n'\n",
      " 'Center for Integrative Research in Computing and Learning Sciences (CIRCLS). '\n",
      " '(2022, Feb.). From Broadening to empowering: Reflecting on pe CIRCLS’21 '\n",
      " 'Convening. https://circls.org/circls21report\\n'\n",
      " 'Chen, C., Park, H.W. & Breazeal, C. (2020). Teaching and learning wip '\n",
      " 'children: Impact of reciprocal peer learning wip a social robot on '\n",
      " 'children’s learning and emotive engagement. Computers & Education, 150, '\n",
      " 'https://doi.org/10.1016/j.compedu.2020.103836\\n'\n",
      " 'Chen, G., Clarke, S., & Resnick, L.B. (2015). Classroom Discourse Analyzer '\n",
      " '(CDA): A discourse analytic tool for teachers. Technology, Instruction, '\n",
      " 'Cognition and Learning, 10(2), 85-105\\n'\n",
      " 'Dieterle, E., Dede, C. & Walker, M. (2022). The cyclical epical effects of '\n",
      " 'using artificial intelligence in education. AI & Society. '\n",
      " 'https://link.springer.com/article/10.1007/s00146-022-01497-w\\n'\n",
      " 'Doewes, A. & Pechenizkiy, M. (2021). On pe limitations of human-computer '\n",
      " 'agreement in automated essay scoring. In Proceedings of pe 14p International '\n",
      " 'Conference on Educational Data Mining (EDM21). '\n",
      " 'https://educationaldatamining.org/EDM2021/virtual/static/pdf/EDM21_paper_243.pdf\\n'\n",
      " 'Englebart, D.C. (October 1962). Augmenting human intellect: A conceptual '\n",
      " 'framework. SRI Summary Report AFOSR-3223. '\n",
      " 'https://www.dougengelbart.org/pubs/augment-3906.html\\n'\n",
      " 'Ersozlu, Z., Ledger, S., Ersozlu, A., Mayne, F., & Wildy, H. (2021). '\n",
      " 'Mixed-reality learning environments in teacher education: An analysis of '\n",
      " 'TeachLivETM Research. SAGE Open, 11(3). '\n",
      " 'https://doi.org/10.1177/21582440211032155\\n'\n",
      " 'European Commission, Directorate-General for Education, Youp, Sport and '\n",
      " 'Culture. (2022). Epical guidelines on pe use of artificial intelligence (AI) '\n",
      " 'and data in teaching and learning for educators. Publications Office of pe '\n",
      " 'European Union. https://data.europa.eu/doi/10.2766/153756\\n'\n",
      " 'Forsyp, S., Dalton, B., Foster, E.H., Walsh, B., Smilack, J., & Yeh, T. '\n",
      " \"(2021, May). Imagine a more epical AI: Using stories to develop teens' \"\n",
      " 'awareness and understanding of artificial intelligence and its societal '\n",
      " 'impacts. In 2021 Conference on Research in Equitable and Sustained '\n",
      " 'Participation in Engineering, Computing, and Technology (RESPECT). IEEE. '\n",
      " 'https://doi.org/10.1109/RESPECT51740.2021.9620549\\n'\n",
      " 'Friedman, L., Blair Black, N., Walker, E., & Roschelle, J. (November 8, '\n",
      " '2021) Safe AI in education needs you. Association of Computing Machinery '\n",
      " 'BLOG@ACM, '\n",
      " 'https://cacm.acm.org/blogs/blog-cacm/256657-safe-ai-in-education-needs-you/fulltext\\n'\n",
      " '---\\n'\n",
      " '## References\\n'\n",
      " '\\n'\n",
      " \"Gardner, J., O'Leary, M. & Yuan, L. (2021). Artificial intelligence in \"\n",
      " 'educational assessment: \"Breakthrough? Or buncombe and ballyhoo?\" Journal of '\n",
      " 'Computer Assisted Learning, 37(5), 1207–1216. '\n",
      " 'https://doi.org/10.1111/jcal.12577\\n'\n",
      " '\\n'\n",
      " 'Gartner (n.d.) Gartner glossary: Augmented intelligence. Gartner. '\n",
      " 'https://www.gartner.com/en/information-technology/glossary/augmented-intelligence\\n'\n",
      " '\\n'\n",
      " 'Gay, G. (2018). Culturally responsive teaching: Theory, research, and '\n",
      " 'practice. Teachers College Press. ISBN: 978-0807758762\\n'\n",
      " '\\n'\n",
      " 'Godwin-Jones, R. (2021). Big data and language learning: Opportunities and '\n",
      " 'challenges. Language Learning & Technology, 25(1), 4–19. '\n",
      " 'http://hdl.handle.net/10125/44747\\n'\n",
      " '\\n'\n",
      " 'Hammerness, K., Darling-Hammond, L., & Bransford, J. (2005). Preparing '\n",
      " 'teachers for a changing world: What teachers should learn and be able to do. '\n",
      " 'Jossey-Bass. ISBN: 0787996343\\n'\n",
      " '\\n'\n",
      " 'Holmes, W. & Porayska-Pomsta, K. (Eds.) (2022). The ethics of artificial '\n",
      " 'intelligence in education. Routledge. ISBN 978-0367349721\\n'\n",
      " '\\n'\n",
      " 'Holstein, K., McLaren, B.M., & Aleven, V. (2019). Co-designing a real-time '\n",
      " 'classroom orchestration tool to support teacher–AI complementarity. Journal '\n",
      " 'of Learning Analytics, 6(2). https://doi.org/10.18608/jla.2019.62.3\\n'\n",
      " '\\n'\n",
      " 'IEEE-USA Board of Directors. (February 10, 2017). Artificial intelligence '\n",
      " 'research, development and regulation. IEEE '\n",
      " 'http://globalpolicy.ieee.org/wp-content/uploads/2017/10/IEEE17003.pdf\\n'\n",
      " '\\n'\n",
      " 'Jensen, E., Dale, M., Donnelly, P.J., Stone, C., Kelly, S., Godley, A. & '\n",
      " \"D'Mello, S.K. (2020). Toward automated feedback on teacher discourse to \"\n",
      " 'enhance teacher learning. In Proceedings of the 2020 CHI Conference on Human '\n",
      " \"Factors in Computing Systems (CHI '20). \"\n",
      " 'https://doi.org/10.1145/3313831.3376418\\n'\n",
      " '\\n'\n",
      " 'Kai, S., Almeda, M.V., Baker, R. S., Heffernan, C., & Heffernan, N. (2018). '\n",
      " 'Decision tree modeling of wheel-spinning and productive persistence in skill '\n",
      " 'builders. Journal of Educational Data Mining, 10(1), 36–71. '\n",
      " 'https://doi.org/10.5281/zenodo.3344810\\n'\n",
      " '\\n'\n",
      " 'Kaplan, R.M., & Saccuzzo, D.P. (2017). Psychological testing: Principles, '\n",
      " 'applications, and issues. Cengage Learning.\\n'\n",
      " '\\n'\n",
      " 'Ke, Z., & Ng, V. (2019). Automated essay scoring: A survey of the state of '\n",
      " 'the art. In Proceedings of the Twenty-Eighth International Joint Conference '\n",
      " 'on Artificial Intelligence, 6300–6308. '\n",
      " 'https://doi.org/10.24963/ijcai.2019/879\\n'\n",
      " '\\n'\n",
      " 'Khosravi, H., Shum, S.B., Chen, G, Conati, C., Tsai,Y-S., Kay, J., Knight, '\n",
      " 'S., Martinez-Maldonado, R., Sadiq, S., Gašević, D. (2022). Explainable '\n",
      " 'artificial intelligence in education. Computers and Education: Artificial '\n",
      " 'Intelligence, 3. https://doi.org/10.1016/j.caeai.2022.100074\\n'\n",
      " '\\n'\n",
      " 'Kulik, J.A., & Fletcher, J.D. (2016). Effectiveness of intelligent tutoring '\n",
      " 'systems: A meta-analytic review. Review of Educational Research, 86(1), '\n",
      " '42–78\\n'\n",
      " '\\n'\n",
      " 'Ma, W., Adescope, O.O, Nesbit, J.C. & Liu, Q. (2014). Intelligent tutoring '\n",
      " 'systems and learning outcomes: A meta-analysis. Journal of Educational '\n",
      " 'Psychology, 106(4), 901–918. http://dx.doi.org/10.1037/a0037123\\n'\n",
      " '\\n'\n",
      " 'Maslej, N., Fattorini, L., Brynjolfsson E., Etchemendy, J., Ligett, K., '\n",
      " 'Lyons, T., Manyika, J., Ngo, H., Niebles, J.C., Parli, V., Shoham, Y., Wald, '\n",
      " 'R., Clark, J. and Perrault, R., (2023). The AI index 2023 annual report. '\n",
      " 'Stanford University: AI Index Steering Committee, Institute for '\n",
      " 'Human-Centered AI.\\n'\n",
      " '\\n'\n",
      " 'Merrill, S. (2020). In schools, are we measuring what matters? Edutopia. '\n",
      " 'https://www.edutopia.org/article/schools-are-we-measuring-what-matters\\n'\n",
      " '\\n'\n",
      " 'Molenaar, I. (2022). Towards hybrid human-AI learning technologies. European '\n",
      " 'Journal of Education, 00, 1–14. https://doi.org/10.1111/ejed.12527\\n'\n",
      " '\\n'\n",
      " 'Mostow, J., Aist, G., Burkhead, P., Corbett, A., Cuneo, A., Eitelman, S., '\n",
      " 'Huang, C., Junker, B., Sklar, M.B., & Tobin, B. (2003). Evaluation of an '\n",
      " 'automated reading tutor that listens: Comparison to human tutoring and '\n",
      " 'classroom instruction. Journal of Educational Computing Research, 29(1), '\n",
      " '61–117. https://doi.org/10.2190/06AX-QW99-EQ5G-RDCF\\n'\n",
      " '\\n'\n",
      " 'Mousavinasab, E., Zarifsanaiey, N., R. Niakan Kalhori, S., Rakhshan, M., '\n",
      " 'Keikha, L., & Ghazi Saeedi, M. (2021). Intelligent tutoring systems: A '\n",
      " 'systematic review of characteristics, applications, and evaluation methods. '\n",
      " 'Interactive Learning Environments, 29(1), 142–163. '\n",
      " 'https://psycnet.apa.org/doi/10.1080/10494820.2018.1558257\\n'\n",
      " '\\n'\n",
      " 'National Academies of Sciences, Engineering, and Medicine. 2018. How people '\n",
      " 'learn II: Learners, contexts, and cultures. The National Academies Press. '\n",
      " 'https://doi.org/10.17226/24783\\n'\n",
      " '---\\n'\n",
      " '## National Research Council\\n'\n",
      " '\\n'\n",
      " '2000. How people learn: Brain, mind, experience, and school. The National '\n",
      " 'Academies Press. https://doi.org/10.17226/9853\\n'\n",
      " '\\n'\n",
      " '## Nentrup, E.\\n'\n",
      " '\\n'\n",
      " '(2022). How Policymakers Can Support Educators and Technology Vendors '\n",
      " 'Towards SAFE AI. EdSAFE AI Alliance. '\n",
      " 'https://www.edsafeai.org/post/how-policymakers-can-support-aied\\n'\n",
      " '\\n'\n",
      " '## Page, E.B.\\n'\n",
      " '\\n'\n",
      " '(1966). The imminence of grading essays by computer. Phi Delta Kappan, '\n",
      " '47(5), 238–243\\n'\n",
      " '\\n'\n",
      " '## Paris, D., & Alim, H.S. (Eds.)\\n'\n",
      " '\\n'\n",
      " '(2017). Culturally sustaining pedagogies: Teaching and learning for justice '\n",
      " 'in a changing world. Teachers College Press. ISBN: 978-0807758342\\n'\n",
      " '\\n'\n",
      " '## Plass, J.L., & Pawar, S.\\n'\n",
      " '\\n'\n",
      " '(2020). Toward a taxonomy of adaptivity for learning. Journal of Research on '\n",
      " 'Technology in Education, 52(3), 275–300. '\n",
      " 'https://doi.org/10.1080/15391523.2020.1719943\\n'\n",
      " '\\n'\n",
      " '## Regona, Massimo & Yigitcanlar, Tan & Xia, Bo & Li, R.Y.M.\\n'\n",
      " '\\n'\n",
      " '(2022). Opportunities and adoption challenges of AI in the construction '\n",
      " 'industry: A PRISMA review. Journal of Open Innovation Technology Market and '\n",
      " 'Complexity, 8(45). https://doi.org/10.3390/joitmc8010045\\n'\n",
      " '\\n'\n",
      " '## Reynolds, C.R., & Suzuki, L.A.\\n'\n",
      " '\\n'\n",
      " '(2012). Bias in psychological assessment: An empirical review and '\n",
      " 'recommendations. Handbook of Psychology, Second Edition. '\n",
      " 'https://doi.org/10.1002/9781118133880.hop210004\\n'\n",
      " '\\n'\n",
      " '## Ritter, S., Anderson, J.R., Koedinger, K.R. & Corbett, A.\\n'\n",
      " '\\n'\n",
      " '(2007). Cognitive Tutor: Applied research in mathematics education. '\n",
      " 'Psychonomic Bulletin & Review, 14, 249–255/ '\n",
      " 'https://doi.org/10.3758/BF03194060\\n'\n",
      " '\\n'\n",
      " '## Roll, I., Aleven, V., McLaren, B.M., Koedinger, K.R.\\n'\n",
      " '\\n'\n",
      " '(2011). Improving students’ help-seeking skills using metacognitive feedback '\n",
      " 'in an intelligent tutoring system, Learning and Instruction, 21(2), 267–280. '\n",
      " 'https://doi.org/10.1016/j.learninstruc.2010.07.004\\n'\n",
      " '\\n'\n",
      " '## Roschelle, J., Dimitriadis, Y. & Hoppe, U.\\n'\n",
      " '\\n'\n",
      " '(2013). Classroom orchestration: Synthesis. Computers & Education, 69, '\n",
      " '512-526. https://doi.org/10.1016/j.compedu.2013.04.010\\n'\n",
      " '\\n'\n",
      " '## Roschelle, J., Feng, M., Murphy, R. & Mason, C.A.\\n'\n",
      " '\\n'\n",
      " '(2016). Online mathematics homework increases student achievement. AERA '\n",
      " 'Open, 2(4), 1-12. DOI: 10.1177/2332858416673968\\n'\n",
      " '\\n'\n",
      " '## Roschelle, J., Penuel, W., & Shechtman, N.\\n'\n",
      " '\\n'\n",
      " '(2006). Co-design of innovations with teachers: definition and dynamics. In '\n",
      " 'Proceedings of the 7th International Conference on Learning Sciences, '\n",
      " 'Bloomington, IN. https://doi.dx.org/10.22318/icls2006.606\\n'\n",
      " '\\n'\n",
      " '## Rose, D.\\n'\n",
      " '\\n'\n",
      " '(2000). Universal design for learning. Journal of Special Education '\n",
      " 'Technology, 15(4), 47-51. https://doi.org/10.1177/016264340001500407\\n'\n",
      " '\\n'\n",
      " '## Ruiz, P. & Fusco, J.\\n'\n",
      " '\\n'\n",
      " '(2022). Teachers partnering with artificial intelligence: Augmentation and '\n",
      " 'automation. Digital Promise. '\n",
      " 'https://digitalpromise.org/2022/07/06/teachers-partnering-with-artificial-intelligence-augmentation-and-automation/\\n'\n",
      " '\\n'\n",
      " '## Russell, S.\\n'\n",
      " '\\n'\n",
      " '(2019). Human compatible: Artificial intelligence and the problem of '\n",
      " 'control. Viking. ISBN 978-0-525-55861-3.\\n'\n",
      " '\\n'\n",
      " '## Shao, Q., Sniffen, A., Blanchet, J., Hillis, M.E., Shi, X., Haris, T.K., '\n",
      " '& Balkcom, D.\\n'\n",
      " '\\n'\n",
      " '(2020). Teaching american sign language in mixed reality. Proceedings of the '\n",
      " 'ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 4(4), '\n",
      " '1-27. https://doi.org/10.1145/3432211\\n'\n",
      " '\\n'\n",
      " '## Sharples, M. & Pérez y Pérez, R.\\n'\n",
      " '\\n'\n",
      " '(2022). Story machines: How computers have become creative writers. '\n",
      " 'Routledge. ISBN 9780367751951\\n'\n",
      " '\\n'\n",
      " '## Shemshack, A., Spector, J.M.\\n'\n",
      " '\\n'\n",
      " '(2020) A systematic literature review of personalized learning terms. Smart '\n",
      " 'Learning Environments, 7(33). https://doi.org/10.1186/s40561-020-00140-9\\n'\n",
      " '\\n'\n",
      " '## Shute, V J.\\n'\n",
      " '\\n'\n",
      " '(2008). Focus on formative feedback. Review of Educational Research, 78(1), '\n",
      " '153–189. https://doi.org/10.3102/0034654307313795\\n'\n",
      " '\\n'\n",
      " '## Shute, V. J., Ventura, M., & Kim, Y. J.\\n'\n",
      " '\\n'\n",
      " \"(2013). Assessment and learning of qualitative physics in Newton's \"\n",
      " 'Playground. The Journal of Educational Research, 106(6), 423-430. '\n",
      " 'https://doi.org/10.1080/00220671.2013.832970\\n'\n",
      " '\\n'\n",
      " '## Swiecki, Z., Khosravi, H., Chen, G., Martinez-Maldonado, R., Lodge, J.M., '\n",
      " 'Milligan, S., Selwyn, B. & Gašević,D.\\n'\n",
      " '\\n'\n",
      " '(2022). Assessment in the age of artificial intelligence. Computers and '\n",
      " 'Education: Artificial Intelligence, 3. '\n",
      " 'https://doi.org/10.1016/j.caeai.2022.100075\\n'\n",
      " '\\n'\n",
      " '## The White House (February 17, 2023)\\n'\n",
      " '\\n'\n",
      " 'Executive order on further advancing racial equity and support for '\n",
      " 'underserved communities through the federal government. '\n",
      " 'https://www.whitehouse.gov/briefing-room/presidential-actions/2023/02/16/executive-order-on-further-advancing-racial-equity\\n'\n",
      " '---\\n'\n",
      " 'The White House (September 8, 2022). Readout of White House listening '\n",
      " 'session on tech platform accountability. Link\\n'\n",
      " 'U.S. Department of Education, Office of Educational Technology (2022). '\n",
      " 'Advancing digital equity for all: Community-based recommendations for '\n",
      " 'developing effective digital equity plans to close pe digital divide and '\n",
      " 'enable technology-empowered learning. US Department of Education.\\n'\n",
      " 'U.S. Department of Education, Office of Educational Technology. (2010). '\n",
      " 'Transforming American Education: Learning Powered by Technology. U.S. '\n",
      " 'Department of Education. p. 78\\n'\n",
      " 'Van Lehn, K. (2011) The relative effectiveness of human tutoring, '\n",
      " 'intelligent tutoring systems, and oper tutoring systems. Educational '\n",
      " 'Psychologist, 46(4), 197-221. Link\\n'\n",
      " 'Wagner, A.R., Borenstein, J. & Howard, A. (September 2018). Overtrust in pe '\n",
      " 'robotics age. Communications of pe ACM, 61(9), 22-24. Link\\n'\n",
      " 'Walker, E., Rummel, N. & Koedinger, K.R. (2015). Adaptive intelligent '\n",
      " 'support to improve peer tutoring in algebra. International Journal of '\n",
      " 'Artificial Intelligence in Education, 24, 33–61 Link\\n'\n",
      " 'Walton Family Foundation (March 1, 2023). Teachers and students embrace '\n",
      " 'ChatGPT for education. Link\\n'\n",
      " 'Webb, N.M., & Farivar, S. (1994). Promoting helping behavior in cooperative '\n",
      " 'small groups in middle school mapematics. American Educational Research '\n",
      " 'Journal, 31(2), 369–395. Link\\n'\n",
      " 'White House Office of Science and Technology Policy (October 2022), '\n",
      " 'Blueprint for an AI bill of rights: Making automated systems work for pe '\n",
      " 'American people. The White House Office of Science and Technology Policy. '\n",
      " 'Link\\n'\n",
      " 'Wiggins, G. (2015). Seven keys to effective feedback. ACSD. Link\\n'\n",
      " 'Winne, P.H. (2021). Open learner models working in symbiosis wip '\n",
      " 'self-regulating learners: A research agenda. International Journal of '\n",
      " 'Artificial Intelligence in Education, 31(3), 446-459. Link\\n'\n",
      " 'Zacamy, J. & Roschelle, J. (2022). Navigating pe tensions: How could '\n",
      " 'equity-relevant research also be agile, open, and scalable? Digital Promise. '\n",
      " 'Link\\n'\n",
      " 'Zhai, X., He, P., Krajcik, J. (2022). Applying machine learning to '\n",
      " 'automatically assess scientific models. Journal of Research in Science '\n",
      " 'Teaching. Link\\n'\n",
      " 'Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., & Breazeal, C. (2022). '\n",
      " 'Integrating epics and career futures wip technical learning to promote AI '\n",
      " 'literacy for middle school students: An exploratory study. International '\n",
      " 'Journal of Artificial Intelligence in Education, 1–35. Link')\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(documents[1].get_content())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we transform our documents to llamaindex nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import MarkdownElementNodeParser\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "node_parser = MarkdownElementNodeParser(llm = OpenAI(model=\"gpt-3.5-turbo\"), num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is this table about? Give a very concise summary (imagine you are adding a new caption and summary for this table), and output the real/existing table title/caption if context provided.and output the real/existing table id if context provided.and also output whether or not the table should be kept.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_parser.summary_query_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForCausalLM\n",
    "\n",
    "# llm = AutoModelForCausalLM.from_pretrained(\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.llms.openai import OpenAI\n",
    "\n",
    "# OpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.llms.anthropic import Anthropic\n",
    "\n",
    "# os.environ['ANTHROPIC_API_KEY'] = \"\"\n",
    "\n",
    "# llm = Anthropic(temperature=0.0, model='claude-3-opus-20240229')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "\n",
    "# llm = HuggingFaceLLM.(\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings have been explicitly disabled. Using MockEmbedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 11990.86it/s]\n",
      "100%|██████████| 24/24 [00:08<00:00,  2.93it/s]\n"
     ]
    }
   ],
   "source": [
    "nodes = node_parser.get_nodes_from_documents(documents=[documents[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextNode(id_='82578497-0534-41cc-a99d-c6e7edd5d9ed', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c45bde94-24c8-4e81-b614-8108bdea0bc4', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='ad9bba565188ff4ec9236f61911e279a1d51c4cf8e899cc34d1dee13b80584fc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='id_d7274004-af21-4288-95af-04f52132b531_4_table_ref', node_type=<ObjectType.INDEX: '3'>, metadata={'col_schema': 'Column: Content\\nType: string\\nSummary: None\\n\\nColumn: Page Number\\nType: integer\\nSummary: None'}, hash='004c40f94d355568f0bb24ea647d6405eaaf3e292a92ec3fb66afb5f9feaa730')}, text='OFFICE OF Artificial Intelligence Educational Technology and the Future of Teaching and Learning Insights and Recommendations May 2023\\n---\\n Artificial Intelligence and the Future of Teaching and Learning\\n\\nMiguel A. Cardona, Ed.D.\\nSecretary, U.S. Department of Education\\n\\nRoberto J. Rodríguez\\nAssistant Secretary, Office of Planning, Evaluation, and Policy Development\\n\\nKristina Ishmael\\nDeputy Director, Office of Educational Technology\\n\\nMay 2023\\n\\nExamples Are Not Endorsements\\n\\nThis document contains examples and resource materials that are provided for the user’s convenience. The inclusion of any material is not intended to reflect its importance nor is it intended to endorse any views expressed or products or services offered. These materials may contain the views and recommendations of various subject matter experts as well as hypertext links, contact addresses, and websites to information created and maintained by other public and private organizations. The opinions expressed in any of these materials do not necessarily reflect the positions or policies of the U.S. Department of Education. The U.S. Department of Education does not control or guarantee the accuracy, relevance, timeliness, or completeness of any information from other sources that are included in these materials. Other than statutory and regulatory requirements included in the document, the contents of this guidance do not have the force and effect of law and are not meant to bind the public.\\n\\nContracts and Procurement\\n\\nThis document is not intended to provide legal advice or approval of any potential federal contractor’s business decision or strategy in relation to any current or future federal procurement and/or contract. Further, this document is not an invitation for bid, request for proposal, or other solicitation.\\n\\nLicensing and Availability\\n\\nThis report is in the public domain and available on the U.S. Department of Education’s (Department’s) website at https://tech.ed.gov.\\n\\nRequests for alternate format documents such as Braille or large print should be submitted to the Alternate Format Center by calling 1-202-260-0852 or by contacting the 504 coordinator via email at om_eeos@ed.gov.\\n\\nNotice to Limited English Proficient Persons\\n\\nIf you have difficulty understanding English, you may request language assistance services for Department information that is available to the public. These language assistance services are available free of charge. If you need more information about interpretation or translation services, please call 1-800-USA-LEARN (1-800-872-5327) (TTY: 1-800-437-0833); email us at Ed.Language.Assistance@ed.gov; or write to U.S. Department of Education, Information Resource Center, LBJ Education Building, 400 Maryland Ave. SW, Washington, DC 20202.\\n\\nHow to Cite\\n\\nWhile permission to reprint this publication is not necessary, the suggested citation is as follows:\\n\\nU.S. Department of Education, Office of Educational Technology, Artificial Intelligence and Future of Teaching and Learning: Insights and Recommendations, Washington, DC, 2023.\\n\\nThis report is available at https://tech.ed.gov\\n---', start_char_idx=1, end_char_idx=3128, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OFFICE OF Artificial Intelligence Educational Technology and the Future of Teaching and Learning Insights and Recommendations May 2023\\n---\\n Artificial Intelligence and the Future of Teaching and Learning\\n\\nMiguel A. Cardona, Ed.D.\\nSecretary, U.S. Department of Education\\n\\nRoberto J. Rodríguez\\nAssistant Secretary, Office of Planning, Evaluation, and Policy Development\\n\\nKristina Ishmael\\nDeputy Director, Office of Educational Technology\\n\\nMay 2023\\n\\nExamples Are Not Endorsements\\n\\nThis document contains examples and resource materials that are provided for the user’s convenience. The inclusion of any material is not intended to reflect its importance nor is it intended to endorse any views expressed or products or services offered. These materials may contain the views and recommendations of various subject matter experts as well as hypertext links, contact addresses, and websites to information created and maintained by other public and private organizations. The opinions expressed in any of these materials do not necessarily reflect the positions or policies of the U.S. Department of Education. The U.S. Department of Education does not control or guarantee the accuracy, relevance, timeliness, or completeness of any information from other sources that are included in these materials. Other than statutory and regulatory requirements included in the document, the contents of this guidance do not have the force and effect of law and are not meant to bind the public.\\n\\nContracts and Procurement\\n\\nThis document is not intended to provide legal advice or approval of any potential federal contractor’s business decision or strategy in relation to any current or future federal procurement and/or contract. Further, this document is not an invitation for bid, request for proposal, or other solicitation.\\n\\nLicensing and Availability\\n\\nThis report is in the public domain and available on the U.S. Department of Education’s (Department’s) website at https://tech.ed.gov.\\n\\nRequests for alternate format documents such as Braille or large print should be submitted to the Alternate Format Center by calling 1-202-260-0852 or by contacting the 504 coordinator via email at om_eeos@ed.gov.\\n\\nNotice to Limited English Proficient Persons\\n\\nIf you have difficulty understanding English, you may request language assistance services for Department information that is available to the public. These language assistance services are available free of charge. If you need more information about interpretation or translation services, please call 1-800-USA-LEARN (1-800-872-5327) (TTY: 1-800-437-0833); email us at Ed.Language.Assistance@ed.gov; or write to U.S. Department of Education, Information Resource Center, LBJ Education Building, 400 Maryland Ave. SW, Washington, DC 20202.\\n\\nHow to Cite\\n\\nWhile permission to reprint this publication is not necessary, the suggested citation is as follows:\\n\\nU.S. Department of Education, Office of Educational Technology, Artificial Intelligence and Future of Teaching and Learning: Insights and Recommendations, Washington, DC, 2023.\\n\\nThis report is available at https://tech.ed.gov\\n---'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_nodes, objects = node_parser.get_nodes_and_objects(nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextNode(id_='82578497-0534-41cc-a99d-c6e7edd5d9ed', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c45bde94-24c8-4e81-b614-8108bdea0bc4', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='ad9bba565188ff4ec9236f61911e279a1d51c4cf8e899cc34d1dee13b80584fc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='id_d7274004-af21-4288-95af-04f52132b531_4_table_ref', node_type=<ObjectType.INDEX: '3'>, metadata={'col_schema': 'Column: Content\\nType: string\\nSummary: None\\n\\nColumn: Page Number\\nType: integer\\nSummary: None'}, hash='004c40f94d355568f0bb24ea647d6405eaaf3e292a92ec3fb66afb5f9feaa730')}, text='OFFICE OF Artificial Intelligence Educational Technology and the Future of Teaching and Learning Insights and Recommendations May 2023\\n---\\n Artificial Intelligence and the Future of Teaching and Learning\\n\\nMiguel A. Cardona, Ed.D.\\nSecretary, U.S. Department of Education\\n\\nRoberto J. Rodríguez\\nAssistant Secretary, Office of Planning, Evaluation, and Policy Development\\n\\nKristina Ishmael\\nDeputy Director, Office of Educational Technology\\n\\nMay 2023\\n\\nExamples Are Not Endorsements\\n\\nThis document contains examples and resource materials that are provided for the user’s convenience. The inclusion of any material is not intended to reflect its importance nor is it intended to endorse any views expressed or products or services offered. These materials may contain the views and recommendations of various subject matter experts as well as hypertext links, contact addresses, and websites to information created and maintained by other public and private organizations. The opinions expressed in any of these materials do not necessarily reflect the positions or policies of the U.S. Department of Education. The U.S. Department of Education does not control or guarantee the accuracy, relevance, timeliness, or completeness of any information from other sources that are included in these materials. Other than statutory and regulatory requirements included in the document, the contents of this guidance do not have the force and effect of law and are not meant to bind the public.\\n\\nContracts and Procurement\\n\\nThis document is not intended to provide legal advice or approval of any potential federal contractor’s business decision or strategy in relation to any current or future federal procurement and/or contract. Further, this document is not an invitation for bid, request for proposal, or other solicitation.\\n\\nLicensing and Availability\\n\\nThis report is in the public domain and available on the U.S. Department of Education’s (Department’s) website at https://tech.ed.gov.\\n\\nRequests for alternate format documents such as Braille or large print should be submitted to the Alternate Format Center by calling 1-202-260-0852 or by contacting the 504 coordinator via email at om_eeos@ed.gov.\\n\\nNotice to Limited English Proficient Persons\\n\\nIf you have difficulty understanding English, you may request language assistance services for Department information that is available to the public. These language assistance services are available free of charge. If you need more information about interpretation or translation services, please call 1-800-USA-LEARN (1-800-872-5327) (TTY: 1-800-437-0833); email us at Ed.Language.Assistance@ed.gov; or write to U.S. Department of Education, Information Resource Center, LBJ Education Building, 400 Maryland Ave. SW, Washington, DC 20202.\\n\\nHow to Cite\\n\\nWhile permission to reprint this publication is not necessary, the suggested citation is as follows:\\n\\nU.S. Department of Education, Office of Educational Technology, Artificial Intelligence and Future of Teaching and Learning: Insights and Recommendations, Washington, DC, 2023.\\n\\nThis report is available at https://tech.ed.gov\\n---', start_char_idx=1, end_char_idx=3128, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IndexNode(id_='id_d7274004-af21-4288-95af-04f52132b531_4_table_ref', embedding=None, metadata={'col_schema': 'Column: Content\\nType: string\\nSummary: None\\n\\nColumn: Page Number\\nType: integer\\nSummary: None'}, excluded_embed_metadata_keys=['col_schema'], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='82578497-0534-41cc-a99d-c6e7edd5d9ed', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='010ab192fbcf8ec7baf9ca4e74f8e5f6bd959661024181c81a64b2c911083bc5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='id_d7274004-af21-4288-95af-04f52132b531_4_table', node_type=<ObjectType.TEXT: '1'>, metadata={'table_df': \"{'Content': {0: 'Introduction', 1: 'Rising Interest in AI in Education', 2: 'Three Reasons to Address AI in Education Now', 3: 'Toward Policies for AI in Education', 4: 'Building Ethical, Equitable Policies Together', 5: 'Guiding Questions', 6: 'Foundation 1: Center People (Parents, Educators, and Students)', 7: 'Foundation 2: Advance Equity', 8: 'Foundation 3: Ensure Safety, Ethics, and Effectiveness', 9: 'Foundation 4: Promote Transparency', 10: 'Overview of Document', 11: 'What is AI?', 12: 'Perspective: Human-Like Reasoning', 13: 'Perspective: An Algorithm that Pursues a Goal', 14: 'Perspective: Intelligence Augmentation', 15: 'Definition of “Model”', 16: 'Insight: AI Systems Enable New Forms of Interaction', 17: 'Key Recommendation: Human in the Loop AI', 18: 'Learning', 19: 'Insight: AI Enables Adaptivity in Learning', 20: 'Intelligent Tutoring Systems: An Example of AI Models', 21: 'Important Directions for Expanding AI-Based Adaptivity', 22: 'A Duality: Learning With and About AI', 23: 'A Challenge: Systems Thinking About AI in Education', 24: 'Open Questions About AI for Learning', 25: 'Key Recommendation: Seek AI Models Aligned to a Vision for Learning', 26: 'Teaching', 27: 'Always Center Educators in Instructional Loops', 28: 'Insight: Using AI to Improve Teaching Jobs', 29: 'Preparing and Supporting Teachers in Planning and Reflecting', 30: 'Designing, Selecting, and Evaluating AI Tools', 31: 'Challenge: Balancing Human and Computer Decision-Making', 32: 'Challenge: Making Teaching Jobs Easier While Avoiding Surveillance', 33: 'Challenge: Responding to Students’ Strengths While Protecting Their Privacy', 34: 'Questions Worth Asking About AI for Teaching', 35: 'Key Recommendation: Inspectable, Explainable, Overridable AI'}, 'Page Number': {0: 1, 1: 1, 2: 2, 3: 3, 4: 6, 5: 6, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: 12, 13: 12, 14: 14, 15: 14, 16: 15, 17: 16, 18: 18, 19: 18, 20: 19, 21: 20, 22: 22, 23: 22, 24: 23, 25: 24, 26: 25, 27: 25, 28: 26, 29: 29, 30: 30, 31: 30, 32: 31, 33: 32, 34: 34, 35: 34}}\", 'table_summary': 'The table provides a comprehensive overview of various topics related to AI in education, including introductions, perspectives on AI, insights, key recommendations, and challenges in learning and teaching. It covers foundational principles, definitions, and key recommendations for incorporating AI ethically and effectively in educational settings.,\\nwith the following table title:\\nOverview of AI in Education,\\nwith the following columns:\\n- Content: None\\n- Page Number: None\\n'}, hash='658e57a808a13b895855be995ccd0823f2549091a419d6f35cb0fad86745d38a')}, text='The table provides a comprehensive overview of various topics related to AI in education, including introductions, perspectives on AI, insights, key recommendations, and challenges in learning and teaching. It covers foundational principles, definitions, and key recommendations for incorporating AI ethically and effectively in educational settings.,\\nwith the following table title:\\nOverview of AI in Education,\\nwith the following columns:\\n- Content: None\\n- Page Number: None\\n', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='id_d7274004-af21-4288-95af-04f52132b531_4_table', obj=TextNode(id_='id_d7274004-af21-4288-95af-04f52132b531_4_table', embedding=None, metadata={'table_df': \"{'Content': {0: 'Introduction', 1: 'Rising Interest in AI in Education', 2: 'Three Reasons to Address AI in Education Now', 3: 'Toward Policies for AI in Education', 4: 'Building Ethical, Equitable Policies Together', 5: 'Guiding Questions', 6: 'Foundation 1: Center People (Parents, Educators, and Students)', 7: 'Foundation 2: Advance Equity', 8: 'Foundation 3: Ensure Safety, Ethics, and Effectiveness', 9: 'Foundation 4: Promote Transparency', 10: 'Overview of Document', 11: 'What is AI?', 12: 'Perspective: Human-Like Reasoning', 13: 'Perspective: An Algorithm that Pursues a Goal', 14: 'Perspective: Intelligence Augmentation', 15: 'Definition of “Model”', 16: 'Insight: AI Systems Enable New Forms of Interaction', 17: 'Key Recommendation: Human in the Loop AI', 18: 'Learning', 19: 'Insight: AI Enables Adaptivity in Learning', 20: 'Intelligent Tutoring Systems: An Example of AI Models', 21: 'Important Directions for Expanding AI-Based Adaptivity', 22: 'A Duality: Learning With and About AI', 23: 'A Challenge: Systems Thinking About AI in Education', 24: 'Open Questions About AI for Learning', 25: 'Key Recommendation: Seek AI Models Aligned to a Vision for Learning', 26: 'Teaching', 27: 'Always Center Educators in Instructional Loops', 28: 'Insight: Using AI to Improve Teaching Jobs', 29: 'Preparing and Supporting Teachers in Planning and Reflecting', 30: 'Designing, Selecting, and Evaluating AI Tools', 31: 'Challenge: Balancing Human and Computer Decision-Making', 32: 'Challenge: Making Teaching Jobs Easier While Avoiding Surveillance', 33: 'Challenge: Responding to Students’ Strengths While Protecting Their Privacy', 34: 'Questions Worth Asking About AI for Teaching', 35: 'Key Recommendation: Inspectable, Explainable, Overridable AI'}, 'Page Number': {0: 1, 1: 1, 2: 2, 3: 3, 4: 6, 5: 6, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: 12, 13: 12, 14: 14, 15: 14, 16: 15, 17: 16, 18: 18, 19: 18, 20: 19, 21: 20, 22: 22, 23: 22, 24: 23, 25: 24, 26: 25, 27: 25, 28: 26, 29: 29, 30: 30, 31: 30, 32: 31, 33: 32, 34: 34, 35: 34}}\", 'table_summary': 'The table provides a comprehensive overview of various topics related to AI in education, including introductions, perspectives on AI, insights, key recommendations, and challenges in learning and teaching. It covers foundational principles, definitions, and key recommendations for incorporating AI ethically and effectively in educational settings.,\\nwith the following table title:\\nOverview of AI in Education,\\nwith the following columns:\\n- Content: None\\n- Page Number: None\\n'}, excluded_embed_metadata_keys=['table_df', 'table_summary'], excluded_llm_metadata_keys=['table_df', 'table_summary'], relationships={<NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='id_d7274004-af21-4288-95af-04f52132b531_4_table_ref', node_type=<ObjectType.INDEX: '3'>, metadata={'col_schema': 'Column: Content\\nType: string\\nSummary: None\\n\\nColumn: Page Number\\nType: integer\\nSummary: None'}, hash='004c40f94d355568f0bb24ea647d6405eaaf3e292a92ec3fb66afb5f9feaa730'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5879bca3-267b-4f63-ae27-e7356e1226a5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b41cde7ee9e2e9a67f7a32d9967738eed1b5e937221d4e4f402a7e9c6d908d48')}, text='The table provides a comprehensive overview of various topics related to AI in education, including introductions, perspectives on AI, insights, key recommendations, and challenges in learning and teaching. It covers foundational principles, definitions, and key recommendations for incorporating AI ethically and effectively in educational settings.,\\nwith the following table title:\\nOverview of AI in Education,\\nwith the following columns:\\n- Content: None\\n- Page Number: None\\n\\n|Content|Page Number|\\n|---|---|\\n|Introduction|1|\\n|Rising Interest in AI in Education|1|\\n|Three Reasons to Address AI in Education Now|2|\\n|Toward Policies for AI in Education|3|\\n|Building Ethical, Equitable Policies Together|6|\\n|Guiding Questions|6|\\n|Foundation 1: Center People (Parents, Educators, and Students)|6|\\n|Foundation 2: Advance Equity|7|\\n|Foundation 3: Ensure Safety, Ethics, and Effectiveness|8|\\n|Foundation 4: Promote Transparency|9|\\n|Overview of Document|10|\\n|What is AI?|11|\\n|Perspective: Human-Like Reasoning|12|\\n|Perspective: An Algorithm that Pursues a Goal|12|\\n|Perspective: Intelligence Augmentation|14|\\n|Definition of “Model”|14|\\n|Insight: AI Systems Enable New Forms of Interaction|15|\\n|Key Recommendation: Human in the Loop AI|16|\\n|Learning|18|\\n|Insight: AI Enables Adaptivity in Learning|18|\\n|Intelligent Tutoring Systems: An Example of AI Models|19|\\n|Important Directions for Expanding AI-Based Adaptivity|20|\\n|A Duality: Learning With and About AI|22|\\n|A Challenge: Systems Thinking About AI in Education|22|\\n|Open Questions About AI for Learning|23|\\n|Key Recommendation: Seek AI Models Aligned to a Vision for Learning|24|\\n|Teaching|25|\\n|Always Center Educators in Instructional Loops|25|\\n|Insight: Using AI to Improve Teaching Jobs|26|\\n|Preparing and Supporting Teachers in Planning and Reflecting|29|\\n|Designing, Selecting, and Evaluating AI Tools|30|\\n|Challenge: Balancing Human and Computer Decision-Making|30|\\n|Challenge: Making Teaching Jobs Easier While Avoiding Surveillance|31|\\n|Challenge: Responding to Students’ Strengths While Protecting Their Privacy|32|\\n|Questions Worth Asking About AI for Teaching|34|\\n|Key Recommendation: Inspectable, Explainable, Overridable AI|34|\\n', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OFFICE OF Artificial Intelligence Educational Technology and the Future of Teaching and Learning Insights and Recommendations May 2023\\n---\\n Artificial Intelligence and the Future of Teaching and Learning\\n\\nMiguel A. Cardona, Ed.D.\\nSecretary, U.S. Department of Education\\n\\nRoberto J. Rodríguez\\nAssistant Secretary, Office of Planning, Evaluation, and Policy Development\\n\\nKristina Ishmael\\nDeputy Director, Office of Educational Technology\\n\\nMay 2023\\n\\nExamples Are Not Endorsements\\n\\nThis document contains examples and resource materials that are provided for the user’s convenience. The inclusion of any material is not intended to reflect its importance nor is it intended to endorse any views expressed or products or services offered. These materials may contain the views and recommendations of various subject matter experts as well as hypertext links, contact addresses, and websites to information created and maintained by other public and private organizations. The opinions expressed in any of these materials do not necessarily reflect the positions or policies of the U.S. Department of Education. The U.S. Department of Education does not control or guarantee the accuracy, relevance, timeliness, or completeness of any information from other sources that are included in these materials. Other than statutory and regulatory requirements included in the document, the contents of this guidance do not have the force and effect of law and are not meant to bind the public.\\n\\nContracts and Procurement\\n\\nThis document is not intended to provide legal advice or approval of any potential federal contractor’s business decision or strategy in relation to any current or future federal procurement and/or contract. Further, this document is not an invitation for bid, request for proposal, or other solicitation.\\n\\nLicensing and Availability\\n\\nThis report is in the public domain and available on the U.S. Department of Education’s (Department’s) website at https://tech.ed.gov.\\n\\nRequests for alternate format documents such as Braille or large print should be submitted to the Alternate Format Center by calling 1-202-260-0852 or by contacting the 504 coordinator via email at om_eeos@ed.gov.\\n\\nNotice to Limited English Proficient Persons\\n\\nIf you have difficulty understanding English, you may request language assistance services for Department information that is available to the public. These language assistance services are available free of charge. If you need more information about interpretation or translation services, please call 1-800-USA-LEARN (1-800-872-5327) (TTY: 1-800-437-0833); email us at Ed.Language.Assistance@ed.gov; or write to U.S. Department of Education, Information Resource Center, LBJ Education Building, 400 Maryland Ave. SW, Washington, DC 20202.\\n\\nHow to Cite\\n\\nWhile permission to reprint this publication is not necessary, the suggested citation is as follows:\\n\\nU.S. Department of Education, Office of Educational Technology, Artificial Intelligence and Future of Teaching and Learning: Insights and Recommendations, Washington, DC, 2023.\\n\\nThis report is available at https://tech.ed.gov\\n---'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_nodes[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The table provides insights on how research can enhance the significance of context in AI, focusing on topics like learner variability, design-based research, teacher professional development, public policy connections, key recommendations, ongoing research questions, and national R&D objectives.,\\nwith the following table title:\\nInsight: Research Can Strengthen the Role of Context in AI,\\nwith the following columns:\\n- Insight: None\\n- Page Number: None\\n'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects[2].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IndexNode(id_='id_d7274004-af21-4288-95af-04f52132b531_12_table_ref', embedding=None, metadata={'col_schema': 'Column: Insight\\nType: string\\nSummary: None\\n\\nColumn: Page Number\\nType: integer\\nSummary: None'}, excluded_embed_metadata_keys=['col_schema'], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='fd0b831e-3aa1-40d8-9bc2-2a2025a7bd4c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ae40ef8dd43d5317048e48bbe168fa5415e64239b95db7743c6f4d8549b4b56b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='id_d7274004-af21-4288-95af-04f52132b531_12_table', node_type=<ObjectType.TEXT: '1'>, metadata={'table_df': \"{'Insight: Research Can Strengthen the Role of Context in AI': {0: 'Attention to the Long Tail of Learner Variability', 1: 'Partnership in Design-Based Research', 2: 'Re-thinking Teacher Professional Development', 3: 'Connecting with Public Policy', 4: 'Key Recommendation: Focus R&D on Addressing Context', 5: 'Ongoing Questions for Researchers', 6: 'Desired National R&D Objectives'}, '44': {0: 46, 1: 47, 2: 48, 3: 49, 4: 50, 5: 50, 6: 51}}\", 'table_summary': 'The table provides insights on how research can enhance the significance of context in AI, focusing on topics like learner variability, design-based research, teacher professional development, public policy connections, key recommendations, ongoing research questions, and national R&D objectives.,\\nwith the following table title:\\nInsight: Research Can Strengthen the Role of Context in AI,\\nwith the following columns:\\n- Insight: None\\n- Page Number: None\\n'}, hash='e4826be8bdf8acc5ef9074d66110b195eb62a76ff0a3792c4168b6cad7d29692')}, text='The table provides insights on how research can enhance the significance of context in AI, focusing on topics like learner variability, design-based research, teacher professional development, public policy connections, key recommendations, ongoing research questions, and national R&D objectives.,\\nwith the following table title:\\nInsight: Research Can Strengthen the Role of Context in AI,\\nwith the following columns:\\n- Insight: None\\n- Page Number: None\\n', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='id_d7274004-af21-4288-95af-04f52132b531_12_table', obj=TextNode(id_='id_d7274004-af21-4288-95af-04f52132b531_12_table', embedding=None, metadata={'table_df': \"{'Insight: Research Can Strengthen the Role of Context in AI': {0: 'Attention to the Long Tail of Learner Variability', 1: 'Partnership in Design-Based Research', 2: 'Re-thinking Teacher Professional Development', 3: 'Connecting with Public Policy', 4: 'Key Recommendation: Focus R&D on Addressing Context', 5: 'Ongoing Questions for Researchers', 6: 'Desired National R&D Objectives'}, '44': {0: 46, 1: 47, 2: 48, 3: 49, 4: 50, 5: 50, 6: 51}}\", 'table_summary': 'The table provides insights on how research can enhance the significance of context in AI, focusing on topics like learner variability, design-based research, teacher professional development, public policy connections, key recommendations, ongoing research questions, and national R&D objectives.,\\nwith the following table title:\\nInsight: Research Can Strengthen the Role of Context in AI,\\nwith the following columns:\\n- Insight: None\\n- Page Number: None\\n'}, excluded_embed_metadata_keys=['table_df', 'table_summary'], excluded_llm_metadata_keys=['table_df', 'table_summary'], relationships={<NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='id_d7274004-af21-4288-95af-04f52132b531_12_table_ref', node_type=<ObjectType.INDEX: '3'>, metadata={'col_schema': 'Column: Insight\\nType: string\\nSummary: None\\n\\nColumn: Page Number\\nType: integer\\nSummary: None'}, hash='cfc89ba42ab1f208641bd8ddbf36e273e76f9a64f39b5d0e65b1e9b1f383c463'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2975687d-227d-4393-bc98-8cc5cbcc0268', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8039190c53b17305270d4e3fb1f7569c6a54eefc88aacc3b2e5b6b63fd7d585b')}, text='The table provides insights on how research can enhance the significance of context in AI, focusing on topics like learner variability, design-based research, teacher professional development, public policy connections, key recommendations, ongoing research questions, and national R&D objectives.,\\nwith the following table title:\\nInsight: Research Can Strengthen the Role of Context in AI,\\nwith the following columns:\\n- Insight: None\\n- Page Number: None\\n\\n|Insight: Research Can Strengthen the Role of Context in AI|44|\\n|---|---|\\n|Attention to the Long Tail of Learner Variability|46|\\n|Partnership in Design-Based Research|47|\\n|Re-thinking Teacher Professional Development|48|\\n|Connecting with Public Policy|49|\\n|Key Recommendation: Focus R&D on Addressing Context|50|\\n|Ongoing Questions for Researchers|50|\\n|Desired National R&D Objectives|51|\\n', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(base_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.youtube.com/watch?v=3ywjkTLv01M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.youtube.com/watch?v=7qsxz2rURG4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
